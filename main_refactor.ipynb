{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Required standard libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import selenium\n",
    "import html5lib\n",
    "#import nltk\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "# Extractors \n",
    "import extract\n",
    "\n",
    "# Cleansers (cluster specific)\n",
    "import cleanse\n",
    "\n",
    "# Normalizer (generalised across all clusters)\n",
    "from normalize import scaler\n",
    "\n",
    "# Utils\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export path for all data exports\n",
    "from pathlib import Path\n",
    "\n",
    "# Current working directory\n",
    "cwd = Path('.')\n",
    "\n",
    "# Folder with data-in artifacts, quired to run this script\n",
    "data_in = cwd / 'data_in'\n",
    "\n",
    "# Folder containing manually extracted raw data, ready to be put in the loop\n",
    "data_sources_staged_raw = cwd / 'data_out' / 'data_staged_raw'\n",
    "data_sources_staged_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export raw data\n",
    "data_sources_raw = cwd / 'data_out' / 'data_raw'\n",
    "data_sources_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export cleansed data\n",
    "data_sources_cleansed = cwd / 'data_out' / 'data_cleansed'\n",
    "data_sources_cleansed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export normalized data\n",
    "data_sources_normalized = cwd / 'data_out' / 'data_normalized'\n",
    "data_sources_normalized.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load country list and mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Create a version of the list with unique ISO2 and ISO3 codes\n",
    "country_iso_list = country_full_list.drop_duplicates(subset = 'COUNTRY_ISO_2')\n",
    "\n",
    "# Country CRBA list, this is the list of the countries that should be in the final CRBA indicator list\n",
    "country_crba_list = pd.read_excel(\n",
    "    data_in / 'crba_country_list.xlsx',\n",
    "    header = None,\n",
    "    usecols = [0, 1], \n",
    "    names = ['COUNTRY_ISO_3', 'COUNTRY_NAME']).merge(\n",
    "        right = country_iso_list[['COUNTRY_ISO_2', 'COUNTRY_ISO_3']],\n",
    "        how = 'left',\n",
    "        on='COUNTRY_ISO_3',\n",
    "        validate = 'one_to_one')\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'column_mapping.py') as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'value_mapping.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources sheet\n",
    "crba_data_dictionary_source = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Source\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# snapshot sheet\n",
    "crba_data_dictionary_snapshot = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Snapshot\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# indicator sheet\n",
    "crba_data_dictionary_indicator = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Indicator\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Input lists\n",
    "crba_data_dictionary_input_list = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Input_Lists\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Add 2-digit shortcodes of index, issue and category to indicators sheet\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.merge(\n",
    "    right=crba_data_dictionary_input_list[['INDEX', 'INDEX_CODE']],\n",
    "    left_on='INDEX',\n",
    "    right_on='INDEX'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['ISSUE', 'ISSUE_CODE']],\n",
    "    left_on='ISSUE',\n",
    "    right_on='ISSUE'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['CATEGORY', 'CATEGORY_CODE']],\n",
    "    left_on='CATEGORY',\n",
    "    right_on='CATEGORY'\n",
    ")\n",
    "\n",
    "# Create indicator code prefix (INDEX-ISSUE_CAEGORY CODE)\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE_PREFIX = crba_data_dictionary_indicator.INDEX_CODE +\n",
    "    \"_\" +\n",
    "    crba_data_dictionary_indicator.ISSUE_CODE+\n",
    "    \"_\"+\n",
    "    crba_data_dictionary_indicator.CATEGORY_CODE+\n",
    "    \"_\")\n",
    "\n",
    "# Create indicator code\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE = crba_data_dictionary_indicator.INDICATOR_CODE_PREFIX + crba_data_dictionary_indicator.INDICATOR_NAME.apply(\n",
    "    lambda x: utils.create_ind_code(x)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, inspect\n",
    "\n",
    "extractors = { \n",
    "    cls.type: cls for name, cls in inspect.getmembers(\n",
    "        importlib.import_module(\"extract\"), \n",
    "        inspect.isclass\n",
    "    ) if hasattr(cls, 'type')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging (pre-processing) to create exceptional indicatorsÂ´ raw data \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 98 unique values.\n",
      "The column geoAreaName has 98 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 599 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 95 unique values.\n",
      "The column geoAreaName has 95 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 84 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 87 unique values.\n",
      "The column geoAreaName has 87 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 88 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 110 unique values.\n",
      "The column geoAreaName has 110 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 79 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 183 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column ENVCAUSE has 1 unique values.\n",
      "The column Display Value has 374 unique values.\n",
      "The column Numeric has 547 unique values.\n",
      "The column Low has 547 unique values.\n",
      "The column High has 547 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column REF_AREA:Geographic area has 202 unique values.\n",
      "The column INDICATOR:Indicator has 1 unique values.\n",
      "The column RESIDENCE:Residence has 1 unique values.\n",
      "The column SEX:Sex has 1 unique values.\n",
      "The column AGE:Current age has 1 unique values.\n",
      "The column TIME_PERIOD:Time period has 1 unique values.\n",
      "The column OBS_VALUE:Observation Value has 185 unique values.\n",
      "The column UNIT_MEASURE:Unit of measure has 1 unique values.\n",
      "The column UNIT_MULTIPLIER:Unit multiplier has 1 unique values.\n",
      "The column SOURCE_LINK:Citation of or link to the data source has 1 unique values.\n",
      "The column SERIES_FOOTNOTE:Series footnote has 1 unique values.\n",
      "The column OBS_STATUS:Observation Status has 1 unique values.\n",
      "The column OBS_CONF:Observation confidentaility has 1 unique values.\n",
      "The column DATA_SOURCE:Data Source has 1 unique values.\n",
      "The column COVERAGE_TIME:The period of time for which data are provided has 1 unique values.\n",
      "The column FREQ_COLL:Time interval at which the source data are collected has 1 unique values.\n",
      "The column TIME_PERIOD_METHOD:Time period activity related to when the data are collected has 1 unique values.\n",
      "The column OBS_FOOTNOTE:Observation footnote has 1 unique values.\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing of exceptional indicators, which require extra transformation\n",
    "# Important: File requires having filepaths from above defined and pandas already imported\n",
    "with open(data_in / 'staging_create_raw_data.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract - Transform - Load Loop\n",
    "## API sources\n",
    "### CSV API sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-155 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column CountryISO has 81 unique values.\n",
      "The column Country has 83 unique values.\n",
      "The column Sector has 2 unique values.\n",
      "The column Region has 7 unique values.\n",
      "The column ElementNumber has 205 unique values.\n",
      "The column ElementType has 8 unique values.\n",
      "The column ElementName has 205 unique values.\n",
      "The column Score has 102 unique values.\n",
      "There was a problem with extraction of source S-155 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-155 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "      COUNTRY_NAME DIM_SECTOR  TIME_PERIOD  \\\n",
      "0      Afghanistan     Mining         2017   \n",
      "1      Afghanistan     Mining         2017   \n",
      "2      Afghanistan     Mining         2017   \n",
      "3      Afghanistan     Mining         2017   \n",
      "4      Afghanistan     Mining         2017   \n",
      "...            ...        ...          ...   \n",
      "18240     Zimbabwe     Mining         2017   \n",
      "18241     Zimbabwe     Mining         2017   \n",
      "18242     Zimbabwe     Mining         2017   \n",
      "18243     Zimbabwe     Mining         2017   \n",
      "18244     Zimbabwe     Mining         2017   \n",
      "\n",
      "                                   DIM_ELEMENT_TYPE RAW_OBS_VALUE  \\\n",
      "0                    2017 RESOURCE GOVERNANCE INDEX            34   \n",
      "1                                 VALUE REALIZATION            58   \n",
      "2                                         LICENSING            46   \n",
      "3                               RESERVES DISCLOSURE            57   \n",
      "4                        Reserves volume disclosure           100   \n",
      "...                                             ...           ...   \n",
      "18240   POLITICAL STABILITY AND ABSENCE OF VIOLENCE            49   \n",
      "18241                                     OPEN DATA             8   \n",
      "18242                           OPEN DATA INVENTORY            20   \n",
      "18243                           OPEN DATA BAROMETER             4   \n",
      "18244                               OPEN DATA INDEX             2   \n",
      "\n",
      "      COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0                AF           AFG  \n",
      "1                AF           AFG  \n",
      "2                AF           AFG  \n",
      "3                AF           AFG  \n",
      "4                AF           AFG  \n",
      "...             ...           ...  \n",
      "18240            ZW           ZWE  \n",
      "18241            ZW           ZWE  \n",
      "18242            ZW           ZWE  \n",
      "18243            ZW           ZWE  \n",
      "18244            ZW           ZWE  \n",
      "\n",
      "[18245 rows x 7 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 17950 rows in the dataframe and 0.64% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    17950.000000\n",
      "mean      2017.019220\n",
      "std          0.239362\n",
      "min       2017.000000\n",
      "25%       2017.000000\n",
      "50%       2017.000000\n",
      "75%       2017.000000\n",
      "max       2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-156 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column CountryISO has 81 unique values.\n",
      "The column Country has 83 unique values.\n",
      "The column Sector has 2 unique values.\n",
      "The column Region has 7 unique values.\n",
      "The column ElementNumber has 205 unique values.\n",
      "The column ElementType has 8 unique values.\n",
      "The column ElementName has 205 unique values.\n",
      "The column Score has 102 unique values.\n",
      "There was a problem with extraction of source S-156 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-156 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "      COUNTRY_NAME DIM_SECTOR  TIME_PERIOD  \\\n",
      "0      Afghanistan     Mining         2017   \n",
      "1      Afghanistan     Mining         2017   \n",
      "2      Afghanistan     Mining         2017   \n",
      "3      Afghanistan     Mining         2017   \n",
      "4      Afghanistan     Mining         2017   \n",
      "...            ...        ...          ...   \n",
      "18240     Zimbabwe     Mining         2017   \n",
      "18241     Zimbabwe     Mining         2017   \n",
      "18242     Zimbabwe     Mining         2017   \n",
      "18243     Zimbabwe     Mining         2017   \n",
      "18244     Zimbabwe     Mining         2017   \n",
      "\n",
      "                                   DIM_ELEMENT_TYPE RAW_OBS_VALUE  \\\n",
      "0                    2017 RESOURCE GOVERNANCE INDEX            34   \n",
      "1                                 VALUE REALIZATION            58   \n",
      "2                                         LICENSING            46   \n",
      "3                               RESERVES DISCLOSURE            57   \n",
      "4                        Reserves volume disclosure           100   \n",
      "...                                             ...           ...   \n",
      "18240   POLITICAL STABILITY AND ABSENCE OF VIOLENCE            49   \n",
      "18241                                     OPEN DATA             8   \n",
      "18242                           OPEN DATA INVENTORY            20   \n",
      "18243                           OPEN DATA BAROMETER             4   \n",
      "18244                               OPEN DATA INDEX             2   \n",
      "\n",
      "      COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0                AF           AFG  \n",
      "1                AF           AFG  \n",
      "2                AF           AFG  \n",
      "3                AF           AFG  \n",
      "4                AF           AFG  \n",
      "...             ...           ...  \n",
      "18240            ZW           ZWE  \n",
      "18241            ZW           ZWE  \n",
      "18242            ZW           ZWE  \n",
      "18243            ZW           ZWE  \n",
      "18244            ZW           ZWE  \n",
      "\n",
      "[18245 rows x 7 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 17950 rows in the dataframe and 0.64% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    17950.000000\n",
      "mean      2017.019220\n",
      "std          0.239362\n",
      "min       2017.000000\n",
      "25%       2017.000000\n",
      "50%       2017.000000\n",
      "75%       2017.000000\n",
      "max       2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CSV sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    #(crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (ILO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNESCO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WHO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNICEF)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (NRGI)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "# Delete again (only for temporary debugging 12.11.20)\n",
    "# # # # # # # # # # # # \n",
    "api_sources = api_sources[(api_sources[\"SOURCE_ID\"] == 'S-155') | \n",
    "(api_sources[\"SOURCE_ID\"] == 'S-156')]\n",
    "#api_sources = api_sources[(api_sources[\"SOURCE_ID\"] == 'S-97')]\n",
    "\n",
    "# define emty dataframe\n",
    "combined_cleansed_csv = pd.DataFrame()\n",
    "combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Extraction section\n",
    "    # try:\n",
    "        # Extract data\n",
    "    # print(row[\"ENDPOINT_URL\"]+\"continue here\")\n",
    "    dataframe = extract.CSVExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "    \n",
    "    # Save raw data\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\"\n",
    "        )\n",
    "    \n",
    "    # except:\n",
    "    print(\"There was a problem with extraction of source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().extract_year_from_timeperiod(\n",
    "        dataframe=dataframe,\n",
    "        year_col=\"TIME_PERIOD\",\n",
    "        time_cov_col=\"COVERAGE_TIME\"\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON API sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-23 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 3190 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 51 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Activity has 3 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-23 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 747 rows in the dataframe and 16.87% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     747.00000\n",
      "mean     2016.26506\n",
      "std         3.17993\n",
      "min      2004.00000\n",
      "25%      2014.00000\n",
      "50%      2017.00000\n",
      "75%      2018.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-23 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 3190 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 51 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Activity has 3 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-23 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 747 rows in the dataframe and 16.87% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     747.00000\n",
      "mean     2016.26506\n",
      "std         3.17993\n",
      "min      2004.00000\n",
      "25%      2014.00000\n",
      "50%      2017.00000\n",
      "75%      2018.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-24 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 83 unique values.\n",
      "The column geoAreaName has 83 unique values.\n",
      "The column timePeriodStart has 10 unique values.\n",
      "The column value has 215 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 4 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 5 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-24 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 361 rows in the dataframe and 31.02% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     361.000000\n",
      "mean     2015.927978\n",
      "std         3.379730\n",
      "min      2010.000000\n",
      "25%      2013.000000\n",
      "50%      2016.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-61 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 142 unique values.\n",
      "The column geoAreaName has 142 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 375 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-61 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 27.69% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.743590\n",
      "std         2.798361\n",
      "min      2008.000000\n",
      "25%      2016.000000\n",
      "50%      2017.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-62 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 208 unique values.\n",
      "The column geoAreaName has 208 unique values.\n",
      "The column timePeriodStart has 29 unique values.\n",
      "The column value has 86 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 11 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-62 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 15.9% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.271795\n",
      "std         4.545642\n",
      "min      1992.000000\n",
      "25%      2014.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-71 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 113 unique values.\n",
      "The column geoAreaName has 113 unique values.\n",
      "The column timePeriodStart has 4 unique values.\n",
      "The column value has 66 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-71 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 60.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2018.594872\n",
      "std         1.843063\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-78 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-78 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-79 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-79 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-80 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-80 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-81 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-81 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-125 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 58 unique values.\n",
      "The column geoAreaName has 58 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 62 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 13 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 2 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-125 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 206 rows in the dataframe and 69.42% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     206.000000\n",
      "mean     2018.315534\n",
      "std         3.078240\n",
      "min      2005.000000\n",
      "25%      2017.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-160 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 211 unique values.\n",
      "The column geoAreaName has 211 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 107 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-160 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 6.15% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.246154\n",
      "std         0.963736\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-161 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 294 unique values.\n",
      "The column geoAreaName has 294 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 51 unique values.\n",
      "The column valueType has 2 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 111 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-161 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 0.51% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.000000\n",
      "mean     2015.025510\n",
      "std         0.357143\n",
      "min      2015.000000\n",
      "25%      2015.000000\n",
      "50%      2015.000000\n",
      "75%      2015.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-166 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 191 unique values.\n",
      "The column date has 17 unique values.\n",
      "The column value has 76 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 191 unique values.\n",
      "The column country.value has 213 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-166 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 217 rows in the dataframe and 5.07% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     217.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "WARNING: There are 8 duplicate rows in the cleansed dataframe. Apart from soure S-166, this should not be the case. Check if you have mapped all columns (specifically the dimensions) and values. Now dropping duplicate rows and returning dataframe without duplicates.\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-183 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 82 unique values.\n",
      "The column geoAreaName has 82 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 90 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-183 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 359 rows in the dataframe and 31.48% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     359.000000\n",
      "mean     2018.679666\n",
      "std         1.126325\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-184 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 1193 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-184 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     469.000000\n",
      "mean     2017.147122\n",
      "std         2.662195\n",
      "min      2007.000000\n",
      "25%      2016.000000\n",
      "50%      2018.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-198 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 181 unique values.\n",
      "The column geoAreaName has 181 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 2025 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-198 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 10.77% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.589744\n",
      "std         4.092475\n",
      "min      2000.000000\n",
      "25%      2015.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-202 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-202 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-203 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 65 unique values.\n",
      "The column geoAreaName has 65 unique values.\n",
      "The column timePeriodStart has 19 unique values.\n",
      "The column value has 3381 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 46 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 128 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Type of occupation has 24 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-203 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "\n",
      " Successfully mapped values of column: DIM_OCU_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 2294 rows in the dataframe and 5.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    2294.000000\n",
      "mean     2013.275065\n",
      "std         4.840024\n",
      "min      2001.000000\n",
      "25%      2006.000000\n",
      "50%      2014.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-204 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 127 unique values.\n",
      "The column geoAreaName has 127 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 748 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 3 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-204 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 1075 rows in the dataframe and 7.91% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    1075.000000\n",
      "mean     2014.181395\n",
      "std         3.646843\n",
      "min      2003.000000\n",
      "25%      2012.000000\n",
      "50%      2015.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-212 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 142 unique values.\n",
      "The column date has 67 unique values.\n",
      "The column value has 1088 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 146 unique values.\n",
      "The column country.value has 150 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-212 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 100.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2054.871795\n",
      "std        39.772017\n",
      "min      2020.000000\n",
      "25%      2020.000000\n",
      "50%      2020.000000\n",
      "75%      2100.000000\n",
      "max      2100.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-214 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 196 unique values.\n",
      "The column geoAreaName has 196 unique values.\n",
      "The column timePeriodStart has 13 unique values.\n",
      "The column value has 119 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 45 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 35 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 5 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-214 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 10.26% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.917949\n",
      "std         3.259156\n",
      "min      2006.000000\n",
      "25%      2013.500000\n",
      "50%      2015.000000\n",
      "75%      2017.500000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-216 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 81 unique values.\n",
      "The column geoAreaName has 81 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 17 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Policy instruments has 5 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-216 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Successfully mapped values of column: DIM_POLICY_TYPE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 280 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     280.000000\n",
      "mean     2019.432143\n",
      "std         0.496261\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-217 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 2 unique values.\n",
      "The column indicator has 2 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 83 unique values.\n",
      "The column geoAreaName has 83 unique values.\n",
      "The column timePeriodStart has 10 unique values.\n",
      "The column value has 660 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-217 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 265 rows in the dataframe and 47.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     265.000000\n",
      "mean     2019.441509\n",
      "std         0.581740\n",
      "min      2017.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-218 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 8 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-218 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.594872\n",
      "std         0.492180\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-219 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4166 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-219 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-220 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4232 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-220 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-222 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 292 unique values.\n",
      "The column geoAreaName has 292 unique values.\n",
      "The column timePeriodStart has 6 unique values.\n",
      "The column value has 1725 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1725 unique values.\n",
      "The column lowerBound has 1725 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 7 unique values.\n",
      "The column attributes.Nature has 4 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column attributes.Observation Status has 3 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-222 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 586 rows in the dataframe and 0.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     586.000000\n",
      "mean     2018.013652\n",
      "std         0.130028\n",
      "min      2018.000000\n",
      "25%      2018.000000\n",
      "50%      2018.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-223 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4244 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-223 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-224 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 222 unique values.\n",
      "The column geoAreaName has 222 unique values.\n",
      "The column timePeriodStart has 2 unique values.\n",
      "The column value has 61 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-224 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 4.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.00000\n",
      "mean     2019.94898\n",
      "std         0.50378\n",
      "min      2015.00000\n",
      "25%      2020.00000\n",
      "50%      2020.00000\n",
      "75%      2020.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-225 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 226 unique values.\n",
      "The column geoAreaName has 226 unique values.\n",
      "The column timePeriodStart has 2 unique values.\n",
      "The column value has 69 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-225 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 4.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.000000\n",
      "mean     2019.846939\n",
      "std         0.863529\n",
      "min      2015.000000\n",
      "25%      2020.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-226 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4139 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-226 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-227 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 93 unique values.\n",
      "The column geoAreaName has 93 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 40 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-227 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 381 rows in the dataframe and 26.77% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     381.000000\n",
      "mean     2018.622047\n",
      "std         1.087700\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "WARNING: There are 186 duplicate rows in the cleansed dataframe. Apart from soure S-166, this should not be the case. Check if you have mapped all columns (specifically the dimensions) and values. Now dropping duplicate rows and returning dataframe without duplicates.\n"
     ]
    }
   ],
   "source": [
    "# JSON sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (SDG)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WB)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "# Delete again (only for temporary debugging 12.11.20)\n",
    "# # # # # # # # # # # # \n",
    "\"\"\"\n",
    "api_sources = api_sources[\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-222') | \n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-223') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-224') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-225') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-226')\n",
    "]\n",
    "\"\"\"\n",
    "#combined_cleansed_csv = pd.DataFrame()\n",
    "#combined_normalized_csv = pd.DataFrame()\n",
    "##############################################\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    #try:\n",
    "    # Extract data \n",
    "    dataframe = extract.JSONExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "    # except:\n",
    "        #print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing in \n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    # print(dataframe)\n",
    "\n",
    "    dataframe = cleanse.Cleanser().extract_year_from_timeperiod(\n",
    "        dataframe=dataframe,\n",
    "        year_col=\"TIME_PERIOD\",\n",
    "        time_cov_col=\"COVERAGE_TIME\"\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "\n",
    "    # print(dataframe)\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"],\n",
    "        na_encodings = row[\"NA_ENCODING\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Sources\n",
    "### UN Treaty Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Germany'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# \n",
    "test_string = \"New Zealand 45, 46, 47, 48, 49\"\n",
    "test_string_2 = \"Netherlands 44\"\n",
    "test_string_3 = \"Germany 24, 25, 26\"\n",
    "\n",
    "re.sub('\\s\\d+,\\s\\d+,', '', test_string)\n",
    "re.sub('\\s\\d+.*', '', test_string_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-4 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 35 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a), Succession(d) has 172 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-4 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          15 Aug 2014 a            AF   \n",
      "1                               Albania            21 Aug 2002            AL   \n",
      "2                               Algeria             9 Mar 2004            DZ   \n",
      "3                                Angola          19 Sep 2014 a            AO   \n",
      "4                   Antigua and Barbuda            17 Feb 2010            AG   \n",
      "..                                  ...                    ...           ...   \n",
      "175                          Uzbekistan            12 Aug 2008            UZ   \n",
      "176  Venezuela (Bolivarian Republic of)            13 May 2002            VE   \n",
      "177                            Viet Nam           8 Jun 2012 a            VN   \n",
      "178                              Zambia          24 Apr 2005 a            ZM   \n",
      "179                            Zimbabwe          13 Dec 2013 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AGO  \n",
      "4             ATG  \n",
      "..            ...  \n",
      "175           UZB  \n",
      "176           VEN  \n",
      "177           VNM  \n",
      "178           ZMB  \n",
      "179           ZWE  \n",
      "\n",
      "[180 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-31 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 68 unique values.\n",
      "The column Signature, Succession to signature(d) has 35 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 55 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-31 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                          COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                              Albania           5 Jun 2007 a            AL   \n",
      "1                              Algeria          21 Apr 2005 a            DZ   \n",
      "2                            Argentina            23 Feb 2007            AR   \n",
      "3                              Armenia                    NaN            AM   \n",
      "4                           Azerbaijan          11 Jan 1999 a            AZ   \n",
      "..                                 ...                    ...           ...   \n",
      "63                                Togo                    NaN            TG   \n",
      "64                              Turkey            27 Sep 2004            TR   \n",
      "65                              Uganda          14 Nov 1995 a            UG   \n",
      "66                             Uruguay          15 Feb 2001 a            UY   \n",
      "67  Venezuela (Bolivarian Republic of)            25 Oct 2016            VE   \n",
      "\n",
      "   COUNTRY_ISO_3  \n",
      "0            ALB  \n",
      "1            DZA  \n",
      "2            ARG  \n",
      "3            ARM  \n",
      "4            AZE  \n",
      "..           ...  \n",
      "63           TGO  \n",
      "64           TUR  \n",
      "65           UGA  \n",
      "66           URY  \n",
      "67           VEN  \n",
      "\n",
      "[68 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-84 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 188 unique values.\n",
      "The column Signature has 80 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Formal confirmation(c), Accession(a), Succession(d) has 158 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-84 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan            13 Aug 2010            AF   \n",
      "1                               Albania            26 Apr 2006            AL   \n",
      "2                               Algeria            30 Jun 2006            DZ   \n",
      "3                               Andorra          11 May 2020 a            AD   \n",
      "4                                Angola            20 Sep 2007            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "183  Venezuela (Bolivarian Republic of)            27 Jun 2006            VE   \n",
      "184                            Viet Nam            17 Dec 2004            VN   \n",
      "185                               Yemen            22 Feb 2007            YE   \n",
      "186                              Zambia          23 May 2008 a            ZM   \n",
      "187                            Zimbabwe           4 Dec 2014 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "183           VEN  \n",
      "184           VNM  \n",
      "185           YEM  \n",
      "186           ZMB  \n",
      "187           ZWE  \n",
      "\n",
      "[188 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-105 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2, 3, 4 has 193 unique values.\n",
      "The column Signature has 4 unique values.\n",
      "The column Definitive signature(s), Acceptance(A) has 177 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-105 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          19 Apr 1948 A            AF   \n",
      "1                               Albania          26 May 1947 A            AL   \n",
      "2                               Algeria           8 Nov 1962 A            DZ   \n",
      "3                               Andorra          15 Jan 1997 A            AD   \n",
      "4                                Angola          15 May 1976 A            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "188  Venezuela (Bolivarian Republic of)           7 Jul 1948 A            VE   \n",
      "189                            Viet Nam          17 May 1950 A            VN   \n",
      "190                               Yemen           6 May 1968 A            YE   \n",
      "191                              Zambia           2 Feb 1965 s            ZM   \n",
      "192                            Zimbabwe          16 May 1980 A            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "188           VEN  \n",
      "189           VNM  \n",
      "190           YEM  \n",
      "191           ZMB  \n",
      "192           ZWE  \n",
      "\n",
      "[193 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-115 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 185 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 173 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-115 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          19 Sep 2002 a            AF   \n",
      "1                               Albania           5 Feb 2008 a            AL   \n",
      "2                               Algeria          27 Dec 2006 a            DZ   \n",
      "3                               Andorra            30 Apr 2001            AD   \n",
      "4                                Angola          24 Mar 2005 a            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "180  Venezuela (Bolivarian Republic of)             8 May 2002            VE   \n",
      "181                            Viet Nam            20 Dec 2001            VN   \n",
      "182                               Yemen          15 Dec 2004 a            YE   \n",
      "183                              Zambia                    NaN            ZM   \n",
      "184                            Zimbabwe          14 Feb 2012 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "180           VEN  \n",
      "181           VNM  \n",
      "182           YEM  \n",
      "183           ZMB  \n",
      "184           ZWE  \n",
      "\n",
      "[185 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-141 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 21 unique values.\n",
      "The column Approval(AA), Acceptance(A), Accession(a), Succession(d), Ratification has 180 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-141 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan            19 Sep 2002            AF   \n",
      "1                               Albania           3 Oct 1994 a            AL   \n",
      "2                               Algeria             9 Jun 1993            DZ   \n",
      "3                               Andorra           2 Mar 2011 a            AD   \n",
      "4                                Angola            17 May 2000            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "192  Venezuela (Bolivarian Republic of)            28 Dec 1994            VE   \n",
      "193                            Viet Nam            16 Nov 1994            VN   \n",
      "194                               Yemen            21 Feb 1996            YE   \n",
      "195                              Zambia            28 May 1993            ZM   \n",
      "196                            Zimbabwe             3 Nov 1992            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "192           VEN  \n",
      "193           VNM  \n",
      "194           YEM  \n",
      "195           ZMB  \n",
      "196           ZWE  \n",
      "\n",
      "[197 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-142 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 17 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 116 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-142 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan            15 Feb 2017            AF   \n",
      "1                               Albania            21 Sep 2016            AL   \n",
      "2                               Algeria            20 Oct 2016            DZ   \n",
      "3                               Andorra            24 Mar 2017            AD   \n",
      "4                                Angola            16 Nov 2020            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "192  Venezuela (Bolivarian Republic of)            21 Jul 2017            VE   \n",
      "193                            Viet Nam          3 Nov 2016 AA            VN   \n",
      "194                               Yemen                    NaN            YE   \n",
      "195                              Zambia             9 Dec 2016            ZM   \n",
      "196                            Zimbabwe             7 Aug 2017            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "192           VEN  \n",
      "193           VNM  \n",
      "194           YEM  \n",
      "195           ZMB  \n",
      "196           ZWE  \n",
      "\n",
      "[197 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-143 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature has 13 unique values.\n",
      "The column Approval(AA), Formal confirmation(c), Acceptance(A), Accession(a), Succession(d), Ratification has 184 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-143 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan            25 Mar 2013            AF   \n",
      "1                               Albania          29 Jun 1999 a            AL   \n",
      "2                               Algeria          15 Sep 1998 a            DZ   \n",
      "3                               Andorra          23 Jul 1999 a            AD   \n",
      "4                                Angola           6 Feb 2017 a            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "185  Venezuela (Bolivarian Republic of)             3 Mar 1998            VE   \n",
      "186                            Viet Nam          13 Mar 1995 a            VN   \n",
      "187                               Yemen          21 Feb 1996 a            YE   \n",
      "188                              Zambia          15 Nov 1994 a            ZM   \n",
      "189                            Zimbabwe           1 Mar 2012 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "185           VEN  \n",
      "186           VNM  \n",
      "187           YEM  \n",
      "188           ZMB  \n",
      "189           ZWE  \n",
      "\n",
      "[190 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-144 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature, Succession to signature(d) has 42 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 180 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-144 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          20 Feb 2013 a            AF   \n",
      "1                               Albania             4 Oct 2004            AL   \n",
      "2                               Algeria            22 Sep 2006            DZ   \n",
      "3                                Angola          23 Oct 2006 a            AO   \n",
      "4                   Antigua and Barbuda            10 Sep 2003            AG   \n",
      "..                                  ...                    ...           ...   \n",
      "185  Venezuela (Bolivarian Republic of)            19 Apr 2005            VE   \n",
      "186                            Viet Nam            22 Jul 2002            VN   \n",
      "187                               Yemen             9 Jan 2004            YE   \n",
      "188                              Zambia             7 Jul 2006            ZM   \n",
      "189                            Zimbabwe             1 Mar 2012            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AGO  \n",
      "4             ATG  \n",
      "..            ...  \n",
      "185           VEN  \n",
      "186           VNM  \n",
      "187           YEM  \n",
      "188           ZMB  \n",
      "189           ZWE  \n",
      "\n",
      "[190 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-145 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature has 5 unique values.\n",
      "The column Ratification, Accession(a), Acceptance(A), Approval(AA) has 45 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-145 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                                         COUNTRY_NAME ATTR_RATIFICATION_DATE  \\\n",
      "0                                             Albania             5 Jan 1994   \n",
      "1                                             Austria            25 Jul 1996   \n",
      "2                                          Azerbaijan           3 Aug 2000 a   \n",
      "3                                             Belarus          29 May 2003 a   \n",
      "4                                             Belgium             8 Nov 2000   \n",
      "5                              Bosnia and Herzegovina           3 Dec 2009 a   \n",
      "6                                            Bulgaria            28 Oct 2003   \n",
      "7                                                Chad          22 Feb 2018 a   \n",
      "8                                             Croatia           8 Jul 1996 a   \n",
      "9                                      Czech Republic          12 Jun 2000 a   \n",
      "10                                            Denmark         28 May 1997 AA   \n",
      "11                                            Estonia            16 Jun 1995   \n",
      "12                                     European Union         14 Sep 1995 AA   \n",
      "13                                            Finland          21 Feb 1996 A   \n",
      "14                                             France         30 Jun 1998 AA   \n",
      "15                                            Germany            30 Jan 1995   \n",
      "16                                              Ghana          22 Jun 2020 a   \n",
      "17                                             Greece             6 Sep 1996   \n",
      "18                                            Hungary          2 Sep 1994 AA   \n",
      "19                                              Italy            23 May 1996   \n",
      "20                                         Kazakhstan          11 Jan 2001 a   \n",
      "21                                             Latvia            10 Dec 1996   \n",
      "22                                      Liechtenstein          19 Nov 1997 a   \n",
      "23                                          Lithuania            28 Apr 2000   \n",
      "24                                         Luxembourg             7 Jun 1994   \n",
      "25                                         Montenegro          23 Jun 2014 a   \n",
      "26                                        Netherlands          14 Mar 1995 A   \n",
      "27                                    North Macedonia          28 Jul 2015 a   \n",
      "28                                             Norway          1 Apr 1993 AA   \n",
      "29                                             Poland            15 Mar 2000   \n",
      "30                                           Portugal             9 Dec 1994   \n",
      "31                                Republic of Moldova           4 Jan 1994 a   \n",
      "32                                            Romania            31 May 1995   \n",
      "33                                 Russian Federation           2 Nov 1993 A   \n",
      "34                                            Senegal          31 Aug 2018 a   \n",
      "35                                             Serbia          27 Aug 2010 a   \n",
      "36                                           Slovakia           7 Jul 1999 a   \n",
      "37                                           Slovenia          13 Apr 1999 a   \n",
      "38                                              Spain            16 Feb 2000   \n",
      "39                                             Sweden             5 Aug 1993   \n",
      "40                                        Switzerland            23 May 1995   \n",
      "41                                       Turkmenistan          29 Aug 2012 a   \n",
      "42                                            Ukraine           8 Oct 1999 a   \n",
      "43  United Kingdom of Great Britain and Northern I...                    NaN   \n",
      "44                                         Uzbekistan           4 Sep 2007 a   \n",
      "\n",
      "   COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0             AL           ALB  \n",
      "1             AT           AUT  \n",
      "2             AZ           AZE  \n",
      "3             BY           BLR  \n",
      "4             BE           BEL  \n",
      "5             BA           BIH  \n",
      "6             BG           BGR  \n",
      "7             TD           TCD  \n",
      "8             HR           HRV  \n",
      "9             CZ           CZE  \n",
      "10            DK           DNK  \n",
      "11            EE           EST  \n",
      "12           NaN           NaN  \n",
      "13            FI           FIN  \n",
      "14            FR           FRA  \n",
      "15            DE           DEU  \n",
      "16            GH           GHA  \n",
      "17            GR           GRC  \n",
      "18            HU           HUN  \n",
      "19            IT           ITA  \n",
      "20            KZ           KAZ  \n",
      "21            LV           LVA  \n",
      "22            LI           LIE  \n",
      "23            LT           LTU  \n",
      "24            LU           LUX  \n",
      "25            ME           MNE  \n",
      "26            NL           NLD  \n",
      "27            MK           MKD  \n",
      "28            NO           NOR  \n",
      "29            PL           POL  \n",
      "30            PT           PRT  \n",
      "31            MD           MDA  \n",
      "32            RO           ROU  \n",
      "33            RU           RUS  \n",
      "34            SN           SEN  \n",
      "35            RS           SRB  \n",
      "36            SK           SVK  \n",
      "37            SI           SVN  \n",
      "38            ES           ESP  \n",
      "39            SE           SWE  \n",
      "40            CH           CHE  \n",
      "41            TM           TKM  \n",
      "42            UA           UKR  \n",
      "43            GB           GBR  \n",
      "44            UZ           UZB  \n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-162 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2 has 175 unique values.\n",
      "The column Signature has 64 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 170 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-162 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          24 Jan 1983 a            AF   \n",
      "1                               Albania           4 Oct 1991 a            AL   \n",
      "2                               Algeria            12 Sep 1989            DZ   \n",
      "3                                Angola          10 Jan 1992 a            AO   \n",
      "4                   Antigua and Barbuda           3 Jul 2019 a            AG   \n",
      "..                                  ...                    ...           ...   \n",
      "170  Venezuela (Bolivarian Republic of)            10 May 1978            VE   \n",
      "171                            Viet Nam          24 Sep 1982 a            VN   \n",
      "172                               Yemen           9 Feb 1987 a            YE   \n",
      "173                              Zambia          10 Apr 1984 a            ZM   \n",
      "174                            Zimbabwe          13 May 1991 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AGO  \n",
      "4             ATG  \n",
      "..            ...  \n",
      "170           VEN  \n",
      "171           VNM  \n",
      "172           YEM  \n",
      "173           ZMB  \n",
      "174           ZWE  \n",
      "\n",
      "[175 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-171 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature, Succession to signature(d) has 17 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 37 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-171 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                          COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                               Angola                    NaN            AO   \n",
      "1                           Azerbaijan           4 Dec 1997 a            AZ   \n",
      "2                             Barbados          10 Jul 1992 a            BB   \n",
      "3                              Belarus            28 May 1997            BY   \n",
      "4                              Belgium          31 May 2002 a            BE   \n",
      "5                             Cameroon            26 Jan 1996            CM   \n",
      "6                                Congo                    NaN            CG   \n",
      "7                           Costa Rica          20 Sep 2001 a            CR   \n",
      "8                              Croatia          27 Mar 2000 a            HR   \n",
      "9                                 Cuba           9 Feb 2007 a            CU   \n",
      "10                              Cyprus           8 Jul 1993 a            CY   \n",
      "11    Democratic Republic of the Congo                    NaN            CD   \n",
      "12                             Ecuador           7 Dec 2016 a            EC   \n",
      "13                   Equatorial Guinea          21 Jan 2019 a            GQ   \n",
      "14                             Georgia           8 Jun 1995 a            GE   \n",
      "15                             Germany                    NaN            DE   \n",
      "16                              Guinea          18 Jul 2003 a            GN   \n",
      "17                            Honduras           1 Apr 2008 a            HN   \n",
      "18                               Italy            21 Aug 1995            IT   \n",
      "19                             Liberia          16 Sep 2005 a            LR   \n",
      "20                               Libya          22 Sep 2000 a            LY   \n",
      "21                            Maldives            11 Sep 1991            MV   \n",
      "22                                Mali          12 Apr 2002 a            ML   \n",
      "23                          Mauritania           9 Feb 1998 a            MR   \n",
      "24                          Montenegro                    NaN            ME   \n",
      "25                             Morocco                    NaN            MA   \n",
      "26                         New Zealand          22 Sep 2004 a            NZ   \n",
      "27                             Nigeria                    NaN            NG   \n",
      "28                                Peru          23 Mar 2007 a            PE   \n",
      "29                              Poland                    NaN            PL   \n",
      "30                               Qatar          26 Mar 1999 a            QA   \n",
      "31                 Republic of Moldova          28 Feb 2006 a            MD   \n",
      "32                             Romania                    NaN            RO   \n",
      "33                        Saudi Arabia          14 Apr 1997 a            SA   \n",
      "34                             Senegal           9 Jun 1999 a            SN   \n",
      "35                              Serbia            14 Jan 2016            RS   \n",
      "36                          Seychelles          12 Mar 1990 a            SC   \n",
      "37                            Suriname            10 Aug 1990            SR   \n",
      "38                Syrian Arab Republic          23 Oct 2008 a            SY   \n",
      "39                                Togo          25 Feb 1991 a            TG   \n",
      "40                        Turkmenistan          18 Sep 1996 a            TM   \n",
      "41                             Ukraine            13 Sep 1993            UA   \n",
      "42                             Uruguay            14 Jul 1999            UY   \n",
      "43                          Uzbekistan          19 Jan 1998 a            UZ   \n",
      "44  Venezuela (Bolivarian Republic of)          12 Nov 2013 a            VE   \n",
      "\n",
      "   COUNTRY_ISO_3  \n",
      "0            AGO  \n",
      "1            AZE  \n",
      "2            BRB  \n",
      "3            BLR  \n",
      "4            BEL  \n",
      "5            CMR  \n",
      "6            COG  \n",
      "7            CRI  \n",
      "8            HRV  \n",
      "9            CUB  \n",
      "10           CYP  \n",
      "11           COD  \n",
      "12           ECU  \n",
      "13           GNQ  \n",
      "14           GEO  \n",
      "15           DEU  \n",
      "16           GIN  \n",
      "17           HND  \n",
      "18           ITA  \n",
      "19           LBR  \n",
      "20           LBY  \n",
      "21           MDV  \n",
      "22           MLI  \n",
      "23           MRT  \n",
      "24           MNE  \n",
      "25           MAR  \n",
      "26           NZL  \n",
      "27           NGA  \n",
      "28           PER  \n",
      "29           POL  \n",
      "30           QAT  \n",
      "31           MDA  \n",
      "32           ROU  \n",
      "33           SAU  \n",
      "34           SEN  \n",
      "35           SRB  \n",
      "36           SYC  \n",
      "37           SUR  \n",
      "38           SYR  \n",
      "39           TGO  \n",
      "40           TKM  \n",
      "41           UKR  \n",
      "42           URY  \n",
      "43           UZB  \n",
      "44           VEN  \n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-173 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 62 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 162 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-173 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          24 Sep 2003 a            AF   \n",
      "1                               Albania           9 Dec 2008 a            AL   \n",
      "2                               Algeria           6 May 2009 a            DZ   \n",
      "3                               Andorra            30 Apr 2001            AD   \n",
      "4                                Angola          11 Oct 2007 a            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "175  Venezuela (Bolivarian Republic of)            23 Sep 2003            VE   \n",
      "176                            Viet Nam            20 Dec 2001            VN   \n",
      "177                               Yemen           2 Mar 2007 a            YE   \n",
      "178                              Zambia                    NaN            ZM   \n",
      "179                            Zimbabwe          22 May 2013 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "175           VEN  \n",
      "176           VNM  \n",
      "177           YEM  \n",
      "178           ZMB  \n",
      "179           ZWE  \n",
      "\n",
      "[180 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-3 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 185 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 173 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-3 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan          19 Sep 2002 a            AF   \n",
      "1                               Albania           5 Feb 2008 a            AL   \n",
      "2                               Algeria          27 Dec 2006 a            DZ   \n",
      "3                               Andorra            30 Apr 2001            AD   \n",
      "4                                Angola          24 Mar 2005 a            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "180  Venezuela (Bolivarian Republic of)             8 May 2002            VE   \n",
      "181                            Viet Nam            20 Dec 2001            VN   \n",
      "182                               Yemen          15 Dec 2004 a            YE   \n",
      "183                              Zambia                    NaN            ZM   \n",
      "184                            Zimbabwe          14 Feb 2012 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "180           VEN  \n",
      "181           VNM  \n",
      "182           YEM  \n",
      "183           ZMB  \n",
      "184           ZWE  \n",
      "\n",
      "[185 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-59 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 191 unique values.\n",
      "The column Signature has 44 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 186 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-59 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan             5 Mar 2003            AF   \n",
      "1                               Albania          11 May 1994 a            AL   \n",
      "2                               Algeria          22 May 1996 a            DZ   \n",
      "3                               Andorra          15 Jan 1997 a            AD   \n",
      "4                                Angola          17 Sep 1986 a            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "186  Venezuela (Bolivarian Republic of)             2 May 1983            VE   \n",
      "187                            Viet Nam            17 Feb 1982            VN   \n",
      "188                               Yemen          30 May 1984 a            YE   \n",
      "189                              Zambia            21 Jun 1985            ZM   \n",
      "190                            Zimbabwe          13 May 1991 a            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "186           VEN  \n",
      "187           VNM  \n",
      "188           YEM  \n",
      "189           ZMB  \n",
      "190           ZWE  \n",
      "\n",
      "[191 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-182 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 80 unique values.\n",
      "The column Signature has 36 unique values.\n",
      "The column Definitive signature(s), Ratification, Acceptance(A), Approval(AA), Accession(a) has 50 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-182 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                                         COUNTRY_NAME ATTR_RATIFICATION_DATE  \\\n",
      "0                                             Albania           3 Sep 2014 a   \n",
      "1                                           Argentina             5 Jul 2007   \n",
      "2                                             Armenia          25 Mar 2008 a   \n",
      "3                                            Barbados          25 Jul 2003 a   \n",
      "4                                             Belgium           2 Jul 2010 a   \n",
      "..                                                ...                    ...   \n",
      "75  United Kingdom of Great Britain and Northern I...          18 Jun 2003 s   \n",
      "76                           United States of America                    NaN   \n",
      "77                                            Uruguay            19 Apr 2012   \n",
      "78                                         Uzbekistan                    NaN   \n",
      "79                 Venezuela (Bolivarian Republic of)            13 May 2005   \n",
      "\n",
      "   COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0             AL           ALB  \n",
      "1             AR           ARG  \n",
      "2             AM           ARM  \n",
      "3             BB           BRB  \n",
      "4             BE           BEL  \n",
      "..           ...           ...  \n",
      "75            GB           GBR  \n",
      "76            US           USA  \n",
      "77            UY           URY  \n",
      "78            UZ           UZB  \n",
      "79            VE           VEN  \n",
      "\n",
      "[80 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-191 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Acceptance(A), Accession(a), Succession(d) has 185 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-191 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "                           COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2  \\\n",
      "0                           Afghanistan            28 Mar 1994            AF   \n",
      "1                               Albania            27 Feb 1992            AL   \n",
      "2                               Algeria            16 Apr 1993            DZ   \n",
      "3                               Andorra             2 Jan 1996            AD   \n",
      "4                                Angola             5 Dec 1990            AO   \n",
      "..                                  ...                    ...           ...   \n",
      "192  Venezuela (Bolivarian Republic of)            13 Sep 1990            VE   \n",
      "193                            Viet Nam            28 Feb 1990            VN   \n",
      "194                               Yemen             1 May 1991            YE   \n",
      "195                              Zambia             6 Dec 1991            ZM   \n",
      "196                            Zimbabwe            11 Sep 1990            ZW   \n",
      "\n",
      "    COUNTRY_ISO_3  \n",
      "0             AFG  \n",
      "1             ALB  \n",
      "2             DZA  \n",
      "3             AND  \n",
      "4             AGO  \n",
      "..            ...  \n",
      "192           VEN  \n",
      "193           VNM  \n",
      "194           YEM  \n",
      "195           ZMB  \n",
      "196           ZWE  \n",
      "\n",
      "[197 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-192 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 64 unique values.\n",
      "The column Signature has 24 unique values.\n",
      "The column Accession(a), Ratification has 46 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-192 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "   COUNTRY_NAME ATTR_RATIFICATION_DATE COUNTRY_ISO_2 COUNTRY_ISO_3\n",
      "0       Albania            29 May 2013            AL           ALB\n",
      "1       Andorra            25 Sep 2014            AD           AND\n",
      "2     Argentina            14 Apr 2015            AR           ARG\n",
      "3       Armenia                    NaN            AM           ARM\n",
      "4       Austria                    NaN            AT           AUT\n",
      "..          ...                    ...           ...           ...\n",
      "59     Thailand            25 Sep 2012            TH           THA\n",
      "60      Tunisia          14 Dec 2018 a            TN           TUN\n",
      "61       Turkey            26 Dec 2017            TR           TUR\n",
      "62      Ukraine             2 Sep 2016            UA           UKR\n",
      "63      Uruguay            23 Feb 2015            UY           URY\n",
      "\n",
      "[64 rows x 4 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# UN Treaty HTML sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"UN Treaties\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    dataframe = extract.HTMLExtractor().extract(url = row[\"ADDRESS\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Cleansing\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    # UN Treaty data specific: Sometimes, countries have footnotes (numbers). These must be purged for the rest of the code to work properly\n",
    "    dataframe['COUNTRY_NAME'] = dataframe['COUNTRY_NAME'].apply(lambda x: re.sub('\\s\\d+.*', '', x)) # deleted everything after number (and the leading whitespace)\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_ilo_un_treaty_data(\n",
    "        dataframe = dataframe,\n",
    "        treaty_source_body = row[\"SOURCE_BODY\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Other sources\n",
    "### WPA sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-8 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  admiss_age  TIME_PERIOD\n",
      "0   AFG         5.0         2019\n",
      "1   ALB         5.0         2019\n",
      "2   DZA         5.0         2019\n",
      "3   AND         5.0         2019\n",
      "4   AGO         5.0         2019\n",
      "5   ATG         3.0         2019\n",
      "6   ARG         5.0         2019\n",
      "7   ARM         5.0         2019\n",
      "8   AUS         4.0         2019\n",
      "9   AUT         4.0         2019\n",
      "10  AZE         4.0         2019\n",
      "11  BHS         5.0         2019\n",
      "12  BHR         4.0         2019\n",
      "13  BGD         3.0         2019\n",
      "14  BRB         5.0         2019\n",
      "15  BLR         5.0         2019\n",
      "16  BEL         4.0         2019\n",
      "17  BLZ         3.0         2019\n",
      "18  BEN         3.0         2019\n",
      "19  BTN         2.0         2019\n",
      "20  BOL         3.0         2019\n",
      "21  BIH         4.0         2019\n",
      "22  BWA         4.0         2019\n",
      "23  BRA         5.0         2019\n",
      "24  BRN         5.0         2019\n",
      "25  BGR         5.0         2019\n",
      "26  BFA         5.0         2019\n",
      "27  BDI         5.0         2019\n",
      "28  KHM         4.0         2019\n",
      "29  CMR         3.0         2019\n",
      "There was an issue with source S-8\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-8 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-8 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4.  2.  1. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-9 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  light_age  TIME_PERIOD\n",
      "0   AFG        5.0         2019\n",
      "1   ALB        5.0         2019\n",
      "2   DZA        3.0         2019\n",
      "3   AND        4.0         2019\n",
      "4   AGO        4.0         2019\n",
      "5   ATG        1.0         2019\n",
      "6   ARG        4.0         2019\n",
      "7   ARM        4.0         2019\n",
      "8   AUS        3.0         2019\n",
      "9   AUT        3.0         2019\n",
      "10  AZE        4.0         2019\n",
      "11  BHS        1.0         2019\n",
      "12  BHR        5.0         2019\n",
      "13  BGD        2.0         2019\n",
      "14  BRB        5.0         2019\n",
      "15  BLR        4.0         2019\n",
      "16  BEL        5.0         2019\n",
      "17  BLZ        2.0         2019\n",
      "18  BEN        2.0         2019\n",
      "19  BTN        3.0         2019\n",
      "20  BOL        2.0         2019\n",
      "21  BIH        5.0         2019\n",
      "22  BWA        4.0         2019\n",
      "23  BRA        5.0         2019\n",
      "24  BRN        4.0         2019\n",
      "25  BGR        5.0         2019\n",
      "26  BFA        3.0         2019\n",
      "27  BDI        2.0         2019\n",
      "28  KHM        2.0         2019\n",
      "29  CMR        4.0         2019\n",
      "There was an issue with source S-9\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-9 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-9 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4.  1.  2. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-10 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  edu_comp_begsec  TIME_PERIOD\n",
      "0   AFG              5.0         2014\n",
      "1   ALB              5.0         2014\n",
      "2   DZA              5.0         2014\n",
      "3   AND              5.0         2014\n",
      "4   AGO              1.0         2014\n",
      "5   ATG              NaN         2014\n",
      "6   ARG              5.0         2014\n",
      "7   ARM              5.0         2014\n",
      "8   AUS              5.0         2014\n",
      "9   AUT              5.0         2014\n",
      "10  AZE              5.0         2014\n",
      "11  BHS              NaN         2014\n",
      "12  BHR              5.0         2014\n",
      "13  BGD              1.0         2014\n",
      "14  BRB              5.0         2014\n",
      "15  BLR              5.0         2014\n",
      "16  BEL              5.0         2014\n",
      "17  BLZ              5.0         2014\n",
      "18  BEN              1.0         2014\n",
      "19  BTN              1.0         2014\n",
      "20  BOL              5.0         2014\n",
      "21  BIH              5.0         2014\n",
      "22  BWA              1.0         2014\n",
      "23  BRA              5.0         2014\n",
      "24  BRN              5.0         2014\n",
      "25  BGR              5.0         2014\n",
      "26  BFA              5.0         2014\n",
      "27  BDI              1.0         2014\n",
      "28  KHM              5.0         2014\n",
      "29  CMR              1.0         2014\n",
      "There was an issue with source S-10\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-10 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-10 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-13 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  cl_haz_minage  TIME_PERIOD\n",
      "0   AFG           18.0         2014\n",
      "1   ALB           18.0         2014\n",
      "2   DZA           18.0         2014\n",
      "3   AND           18.0         2014\n",
      "4   AGO            NaN         2014\n",
      "5   ATG           16.0         2014\n",
      "6   ARG           18.0         2014\n",
      "7   ARM           18.0         2014\n",
      "8   AUS            0.0         2014\n",
      "9   AUT           18.0         2014\n",
      "10  AZE           18.0         2014\n",
      "11  BHS           18.0         2014\n",
      "12  BHR           16.0         2014\n",
      "13  BGD           18.0         2014\n",
      "14  BRB           16.0         2014\n",
      "15  BLR           18.0         2014\n",
      "16  BEL           18.0         2014\n",
      "17  BLZ           15.0         2014\n",
      "18  BEN           18.0         2014\n",
      "19  BTN           18.0         2014\n",
      "20  BOL           18.0         2014\n",
      "21  BIH           18.0         2014\n",
      "22  BWA           18.0         2014\n",
      "23  BRA           18.0         2014\n",
      "24  BRN           18.0         2014\n",
      "25  BGR           18.0         2014\n",
      "26  BFA           18.0         2014\n",
      "27  BDI           16.0         2014\n",
      "28  KHM           18.0         2014\n",
      "29  CMR           18.0         2014\n",
      "There was an issue with source S-13\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-13 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-13 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[18. nan 16.  0. 15. 17. 14.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-36 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  minwage_leg  TIME_PERIOD\n",
      "0   AFG          5.0         2014\n",
      "1   ALB          5.0         2014\n",
      "2   DZA          5.0         2014\n",
      "3   AND          5.0         2014\n",
      "4   AGO          5.0         2014\n",
      "5   ATG          5.0         2014\n",
      "6   ARG          5.0         2014\n",
      "7   ARM          5.0         2014\n",
      "8   AUS          5.0         2014\n",
      "9   AUT          5.0         2014\n",
      "10  AZE          5.0         2014\n",
      "11  BHS          5.0         2014\n",
      "12  BHR          1.0         2014\n",
      "13  BGD          5.0         2014\n",
      "14  BRB          5.0         2014\n",
      "15  BLR          5.0         2014\n",
      "16  BEL          3.0         2014\n",
      "17  BLZ          5.0         2014\n",
      "18  BEN          5.0         2014\n",
      "19  BTN          5.0         2014\n",
      "20  BOL          5.0         2014\n",
      "21  BIH          3.0         2014\n",
      "22  BWA          5.0         2014\n",
      "23  BRA          5.0         2014\n",
      "24  BRN          1.0         2014\n",
      "25  BGR          5.0         2014\n",
      "26  BFA          5.0         2014\n",
      "27  BDI          5.0         2014\n",
      "28  KHM          5.0         2014\n",
      "29  CMR          5.0         2014\n",
      "There was an issue with source S-36\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-36 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-36 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-40 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  paid_anlv  TIME_PERIOD\n",
      "0   AFG        5.0         2019\n",
      "1   ALB        5.0         2019\n",
      "2   DZA        5.0         2019\n",
      "3   AND        5.0         2019\n",
      "4   AGO        5.0         2019\n",
      "5   ATG        3.0         2019\n",
      "6   ARG        3.0         2019\n",
      "7   ARM        5.0         2019\n",
      "8   AUS        5.0         2019\n",
      "9   AUT        5.0         2019\n",
      "10  AZE        5.0         2019\n",
      "11  BHS        3.0         2019\n",
      "12  BHR        5.0         2019\n",
      "13  BGD        3.0         2019\n",
      "14  BRB        4.0         2019\n",
      "15  BLR        5.0         2019\n",
      "16  BEL        5.0         2019\n",
      "17  BLZ        3.0         2019\n",
      "18  BEN        5.0         2019\n",
      "19  BTN        4.0         2019\n",
      "20  BOL        NaN         2019\n",
      "21  BIH        4.0         2019\n",
      "22  BWA        4.0         2019\n",
      "23  BRA        5.0         2019\n",
      "24  BRN        2.0         2019\n",
      "25  BGR        5.0         2019\n",
      "26  BFA        5.0         2019\n",
      "27  BDI        4.0         2019\n",
      "28  KHM        4.0         2019\n",
      "29  CMR        4.0         2019\n",
      "There was an issue with source S-40\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-40 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-40 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4. nan  2.  1.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-41 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  sickleave_duration  TIME_PERIOD\n",
      "0   AFG                 2.0         2019\n",
      "1   ALB                 5.0         2019\n",
      "2   DZA                 5.0         2019\n",
      "3   AND                 5.0         2019\n",
      "4   AGO                 1.0         2019\n",
      "5   ATG                 5.0         2019\n",
      "6   ARG                 4.0         2019\n",
      "7   ARM                 5.0         2019\n",
      "8   AUS                 5.0         2019\n",
      "9   AUT                 5.0         2019\n",
      "10  AZE                 5.0         2019\n",
      "11  BHS                 5.0         2019\n",
      "12  BHR                 3.0         2019\n",
      "13  BGD                 2.0         2019\n",
      "14  BRB                 5.0         2019\n",
      "15  BLR                 NaN         2019\n",
      "16  BEL                 5.0         2019\n",
      "17  BLZ                 5.0         2019\n",
      "18  BEN                 5.0         2019\n",
      "19  BTN                 2.0         2019\n",
      "20  BOL                 5.0         2019\n",
      "21  BIH                 5.0         2019\n",
      "22  BWA                 2.0         2019\n",
      "23  BRA                 5.0         2019\n",
      "24  BRN                 3.0         2019\n",
      "25  BGR                 5.0         2019\n",
      "26  BFA                 4.0         2019\n",
      "27  BDI                 4.0         2019\n",
      "28  KHM                 NaN         2019\n",
      "29  CMR                 3.0         2019\n",
      "There was an issue with source S-41\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-41 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-41 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  5.  1.  4.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-42 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  promdemo_sex  TIME_PERIOD\n",
      "0   AFG             1         2020\n",
      "1   ALB             5         2020\n",
      "2   DZA             4         2020\n",
      "3   AND             5         2020\n",
      "4   AGO             5         2020\n",
      "5   ATG             5         2020\n",
      "6   ARG             5         2020\n",
      "7   ARM             4         2020\n",
      "8   AUS             5         2020\n",
      "9   AUT             5         2020\n",
      "10  AZE             5         2020\n",
      "11  BHS             5         2020\n",
      "12  BHR             4         2020\n",
      "13  BGD             1         2020\n",
      "14  BRB             1         2020\n",
      "15  BLR             4         2020\n",
      "16  BEL             5         2020\n",
      "17  BLZ             5         2020\n",
      "18  BEN             5         2020\n",
      "19  BTN             5         2020\n",
      "20  BOL             5         2020\n",
      "21  BIH             5         2020\n",
      "22  BWA             1         2020\n",
      "23  BRA             5         2020\n",
      "24  BRN             1         2020\n",
      "25  BGR             5         2020\n",
      "26  BFA             4         2020\n",
      "27  BDI             5         2020\n",
      "28  KHM             5         2020\n",
      "29  CMR             1         2020\n",
      "There was an issue with source S-42\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-42 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-42 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[1 5 4]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-43 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  pay_sex  TIME_PERIOD\n",
      "0   AFG        2         2020\n",
      "1   ALB        5         2020\n",
      "2   DZA        5         2020\n",
      "3   AND        4         2020\n",
      "4   AGO        5         2020\n",
      "5   ATG        4         2020\n",
      "6   ARG        5         2020\n",
      "7   ARM        5         2020\n",
      "8   AUS        3         2020\n",
      "9   AUT        5         2020\n",
      "10  AZE        5         2020\n",
      "11  BHS        5         2020\n",
      "12  BHR        4         2020\n",
      "13  BGD        5         2020\n",
      "14  BRB        1         2020\n",
      "15  BLR        3         2020\n",
      "16  BEL        5         2020\n",
      "17  BLZ        1         2020\n",
      "18  BEN        5         2020\n",
      "19  BTN        5         2020\n",
      "20  BOL        4         2020\n",
      "21  BIH        5         2020\n",
      "22  BWA        1         2020\n",
      "23  BRA        5         2020\n",
      "24  BRN        1         2020\n",
      "25  BGR        5         2020\n",
      "26  BFA        5         2020\n",
      "27  BDI        4         2020\n",
      "28  KHM        5         2020\n",
      "29  CMR        4         2020\n",
      "There was an issue with source S-43\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-43 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-43 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 4 3 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-44 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  sh_covered  TIME_PERIOD\n",
      "0   AFG         NaN         2020\n",
      "1   ALB         5.0         2020\n",
      "2   DZA         5.0         2020\n",
      "3   AND         5.0         2020\n",
      "4   AGO         5.0         2020\n",
      "5   ATG         1.0         2020\n",
      "6   ARG         5.0         2020\n",
      "7   ARM         5.0         2020\n",
      "8   AUS         5.0         2020\n",
      "9   AUT         5.0         2020\n",
      "10  AZE         5.0         2020\n",
      "11  BHS         5.0         2020\n",
      "12  BHR         1.0         2020\n",
      "13  BGD         3.0         2020\n",
      "14  BRB         1.0         2020\n",
      "15  BLR         1.0         2020\n",
      "16  BEL         5.0         2020\n",
      "17  BLZ         5.0         2020\n",
      "18  BEN         5.0         2020\n",
      "19  BTN         5.0         2020\n",
      "20  BOL         5.0         2020\n",
      "21  BIH         5.0         2020\n",
      "22  BWA         1.0         2020\n",
      "23  BRA         5.0         2020\n",
      "24  BRN         1.0         2020\n",
      "25  BGR         5.0         2020\n",
      "26  BFA         5.0         2020\n",
      "27  BDI         5.0         2020\n",
      "28  KHM         5.0         2020\n",
      "29  CMR         5.0         2020\n",
      "There was an issue with source S-44\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-44 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-44 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[nan  5.  1.  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-45 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  fb_ccschsupp  TIME_PERIOD\n",
      "0   AFG           1.0         2014\n",
      "1   ALB           NaN         2014\n",
      "2   DZA           4.0         2014\n",
      "3   AND           1.0         2014\n",
      "4   AGO           1.0         2014\n",
      "5   ATG           1.0         2014\n",
      "6   ARG           3.0         2014\n",
      "7   ARM           1.0         2014\n",
      "8   AUS           4.0         2014\n",
      "9   AUT           3.0         2014\n",
      "10  AZE           4.0         2014\n",
      "11  BHS           1.0         2014\n",
      "12  BHR           1.0         2014\n",
      "13  BGD           1.0         2014\n",
      "14  BRB           1.0         2014\n",
      "15  BLR           1.0         2014\n",
      "16  BEL           1.0         2014\n",
      "17  BLZ           1.0         2014\n",
      "18  BEN           NaN         2014\n",
      "19  BTN           1.0         2014\n",
      "20  BOL           1.0         2014\n",
      "21  BIH           1.0         2014\n",
      "22  BWA           1.0         2014\n",
      "23  BRA           1.0         2014\n",
      "24  BRN           1.0         2014\n",
      "25  BGR           4.0         2014\n",
      "26  BFA           1.0         2014\n",
      "27  BDI           1.0         2014\n",
      "28  KHM           1.0         2014\n",
      "29  CMR           1.0         2014\n",
      "There was an issue with source S-45\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-45 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-45 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 1. nan  4.  3.  5.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-49 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  minwage_ppp  TIME_PERIOD\n",
      "0   AFG          4.0         2014\n",
      "1   ALB          5.0         2014\n",
      "2   DZA          5.0         2014\n",
      "3   AND          NaN         2014\n",
      "4   AGO          3.0         2014\n",
      "5   ATG          5.0         2014\n",
      "6   ARG          5.0         2014\n",
      "7   ARM          4.0         2014\n",
      "8   AUS          5.0         2014\n",
      "9   AUT          5.0         2014\n",
      "10  AZE          4.0         2014\n",
      "11  BHS          5.0         2014\n",
      "12  BHR          1.0         2014\n",
      "13  BGD          2.0         2014\n",
      "14  BRB          5.0         2014\n",
      "15  BLR          5.0         2014\n",
      "16  BEL          5.0         2014\n",
      "17  BLZ          5.0         2014\n",
      "18  BEN          3.0         2014\n",
      "19  BTN          4.0         2014\n",
      "20  BOL          4.0         2014\n",
      "21  BIH          5.0         2014\n",
      "22  BWA          4.0         2014\n",
      "23  BRA          5.0         2014\n",
      "24  BRN          1.0         2014\n",
      "25  BGR          5.0         2014\n",
      "26  BFA          3.0         2014\n",
      "27  BDI          2.0         2014\n",
      "28  KHM          2.0         2014\n",
      "29  CMR          3.0         2014\n",
      "There was an issue with source S-49\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-49 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-49 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[  4.   5.  nan   3.   1.   2. 999.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-63 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  mtlv_job_protect  TIME_PERIOD\n",
      "0   AFG                 2         2019\n",
      "1   ALB                 5         2019\n",
      "2   DZA                 2         2019\n",
      "3   AND                 5         2019\n",
      "4   AGO                 5         2019\n",
      "5   ATG                 2         2019\n",
      "6   ARG                 5         2019\n",
      "7   ARM                 3         2019\n",
      "8   AUS                 5         2019\n",
      "9   AUT                 5         2019\n",
      "10  AZE                 2         2019\n",
      "11  BHS                 5         2019\n",
      "12  BHR                 5         2019\n",
      "13  BGD                 2         2019\n",
      "14  BRB                 5         2019\n",
      "15  BLR                 2         2019\n",
      "16  BEL                 5         2019\n",
      "17  BLZ                 5         2019\n",
      "18  BEN                 5         2019\n",
      "19  BTN                 2         2019\n",
      "20  BOL                 2         2019\n",
      "21  BIH                 5         2019\n",
      "22  BWA                 5         2019\n",
      "23  BRA                 5         2019\n",
      "24  BRN                 5         2019\n",
      "25  BGR                 5         2019\n",
      "26  BFA                 5         2019\n",
      "27  BDI                 5         2019\n",
      "28  KHM                 5         2019\n",
      "29  CMR                 5         2019\n",
      "There was an issue with source S-63\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-63 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-63 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 3 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-64 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  ptlv_job_protect  TIME_PERIOD\n",
      "0   AFG               2.0         2019\n",
      "1   ALB               1.0         2019\n",
      "2   DZA               2.0         2019\n",
      "3   AND               5.0         2019\n",
      "4   AGO               5.0         2019\n",
      "5   ATG               1.0         2019\n",
      "6   ARG               2.0         2019\n",
      "7   ARM               2.0         2019\n",
      "8   AUS               3.0         2019\n",
      "9   AUT               5.0         2019\n",
      "10  AZE               2.0         2019\n",
      "11  BHS               1.0         2019\n",
      "12  BHR               2.0         2019\n",
      "13  BGD               1.0         2019\n",
      "14  BRB               1.0         2019\n",
      "15  BLR               2.0         2019\n",
      "16  BEL               5.0         2019\n",
      "17  BLZ               1.0         2019\n",
      "18  BEN               2.0         2019\n",
      "19  BTN               2.0         2019\n",
      "20  BOL               2.0         2019\n",
      "21  BIH               2.0         2019\n",
      "22  BWA               1.0         2019\n",
      "23  BRA               5.0         2019\n",
      "24  BRN               1.0         2019\n",
      "25  BGR               5.0         2019\n",
      "26  BFA               1.0         2019\n",
      "27  BDI               2.0         2019\n",
      "28  KHM               1.0         2019\n",
      "29  CMR               1.0         2019\n",
      "There was an issue with source S-64\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-64 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-64 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  1.  5.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-65 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  maternal_leave  TIME_PERIOD\n",
      "0   AFG               2         2019\n",
      "1   ALB               5         2019\n",
      "2   DZA               3         2019\n",
      "3   AND               3         2019\n",
      "4   AGO               2         2019\n",
      "5   ATG               2         2019\n",
      "6   ARG               2         2019\n",
      "7   ARM               5         2019\n",
      "8   AUS               3         2019\n",
      "9   AUT               5         2019\n",
      "10  AZE               5         2019\n",
      "11  BHS               2         2019\n",
      "12  BHR               2         2019\n",
      "13  BGD               3         2019\n",
      "14  BRB               2         2019\n",
      "15  BLR               5         2019\n",
      "16  BEL               4         2019\n",
      "17  BLZ               3         2019\n",
      "18  BEN               3         2019\n",
      "19  BTN               2         2019\n",
      "20  BOL               2         2019\n",
      "21  BIH               5         2019\n",
      "22  BWA               2         2019\n",
      "23  BRA               3         2019\n",
      "24  BRN               2         2019\n",
      "25  BGR               5         2019\n",
      "26  BFA               3         2019\n",
      "27  BDI               2         2019\n",
      "28  KHM               2         2019\n",
      "29  CMR               3         2019\n",
      "There was an issue with source S-65\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-65 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-65 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 3 4 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-66 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  maternal_min_wrr_ilo  TIME_PERIOD\n",
      "0   AFG                     5         2019\n",
      "1   ALB                     3         2019\n",
      "2   DZA                     5         2019\n",
      "3   AND                     5         2019\n",
      "4   AGO                     5         2019\n",
      "5   ATG                     3         2019\n",
      "6   ARG                     5         2019\n",
      "7   ARM                     2         2019\n",
      "8   AUS                     2         2019\n",
      "9   AUT                     2         2019\n",
      "10  AZE                     2         2019\n",
      "11  BHS                     5         2019\n",
      "12  BHR                     5         2019\n",
      "13  BGD                     5         2019\n",
      "14  BRB                     5         2019\n",
      "15  BLR                     3         2019\n",
      "16  BEL                     2         2019\n",
      "17  BLZ                     5         2019\n",
      "18  BEN                     5         2019\n",
      "19  BTN                     5         2019\n",
      "20  BOL                     2         2019\n",
      "21  BIH                     3         2019\n",
      "22  BWA                     3         2019\n",
      "23  BRA                     5         2019\n",
      "24  BRN                     5         2019\n",
      "25  BGR                     5         2019\n",
      "26  BFA                     5         2019\n",
      "27  BDI                     5         2019\n",
      "28  KHM                     3         2019\n",
      "29  CMR                     5         2019\n",
      "There was an issue with source S-66\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-66 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-66 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[5 3 2 4 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-67 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  paternal_leave  TIME_PERIOD\n",
      "0   AFG             2.0         2019\n",
      "1   ALB             1.0         2019\n",
      "2   DZA             2.0         2019\n",
      "3   AND             3.0         2019\n",
      "4   AGO             2.0         2019\n",
      "5   ATG             1.0         2019\n",
      "6   ARG             2.0         2019\n",
      "7   ARM             5.0         2019\n",
      "8   AUS             5.0         2019\n",
      "9   AUT             5.0         2019\n",
      "10  AZE             5.0         2019\n",
      "11  BHS             1.0         2019\n",
      "12  BHR             2.0         2019\n",
      "13  BGD             1.0         2019\n",
      "14  BRB             1.0         2019\n",
      "15  BLR             5.0         2019\n",
      "16  BEL             5.0         2019\n",
      "17  BLZ             1.0         2019\n",
      "18  BEN             2.0         2019\n",
      "19  BTN             2.0         2019\n",
      "20  BOL             2.0         2019\n",
      "21  BIH             2.0         2019\n",
      "22  BWA             1.0         2019\n",
      "23  BRA             2.0         2019\n",
      "24  BRN             1.0         2019\n",
      "25  BGR             5.0         2019\n",
      "26  BFA             1.0         2019\n",
      "27  BDI             2.0         2019\n",
      "28  KHM             1.0         2019\n",
      "29  CMR             1.0         2019\n",
      "There was an issue with source S-67\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-67 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-67 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  1.  3.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-68 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  breastfeed_duration  TIME_PERIOD\n",
      "0   AFG                  5.0         2019\n",
      "1   ALB                  5.0         2019\n",
      "2   DZA                  1.0         2019\n",
      "3   AND                  5.0         2019\n",
      "4   AGO                  5.0         2019\n",
      "5   ATG                  1.0         2019\n",
      "6   ARG                  5.0         2019\n",
      "7   ARM                  5.0         2019\n",
      "8   AUS                  1.0         2019\n",
      "9   AUT                  5.0         2019\n",
      "10  AZE                  5.0         2019\n",
      "11  BHS                  1.0         2019\n",
      "12  BHR                  5.0         2019\n",
      "13  BGD                  1.0         2019\n",
      "14  BRB                  1.0         2019\n",
      "15  BLR                  5.0         2019\n",
      "16  BEL                  5.0         2019\n",
      "17  BLZ                  1.0         2019\n",
      "18  BEN                  5.0         2019\n",
      "19  BTN                  2.0         2019\n",
      "20  BOL                  5.0         2019\n",
      "21  BIH                  5.0         2019\n",
      "22  BWA                  5.0         2019\n",
      "23  BRA                  5.0         2019\n",
      "24  BRN                  1.0         2019\n",
      "25  BGR                  5.0         2019\n",
      "26  BFA                  5.0         2019\n",
      "27  BDI                  5.0         2019\n",
      "28  KHM                  5.0         2019\n",
      "29  CMR                  5.0         2019\n",
      "There was an issue with source S-68\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-68 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-68 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1.  2.  4. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a flat file of all WPA sources\n",
    "# Read and join all world policy analysis centre data\n",
    "wpa_child_labor = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_8, S_9' / 'WORLD_child_labor.xls'\n",
    ")\n",
    "\n",
    "wpa_childhood = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_10, S_13, S_36, S_45, S_49' / 'WORLD_Dataset_Childhood_4.16.15.xls'\n",
    ")\n",
    "\n",
    "wpa_adult_labor = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_40, S_41, S_63, S_64, S_65, S_66, S_67, S_68' / 'WORLD_Dataset_Adult_Labor_9.17.2018.xls'\n",
    ")\n",
    "\n",
    "wpa_discrimination = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_42, S_43, S_44' / 'WORLD_discrimination_at_work.xls'\n",
    ")\n",
    "\n",
    "# Create list to write a loop\n",
    "wpa_combined_list=[\n",
    "    wpa_childhood,\n",
    "    wpa_adult_labor,\n",
    "    wpa_discrimination\n",
    " ]\n",
    "\n",
    "# Loop to join all dataframes\n",
    "wpa_combined = wpa_child_labor\n",
    "\n",
    "for df in wpa_combined_list:\n",
    "    wpa_combined = wpa_combined.merge(\n",
    "        right=df,\n",
    "        on=['iso2', 'iso3']\n",
    "    )\n",
    "\n",
    "# 2. Loop\n",
    "wpa_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"World Policy Analysis Centre\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # \n",
    "# combined_cleansed_csv = pd.DataFrame()\n",
    "# combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in wpa_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    #try:\n",
    "    # Extract data \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n Extracting data and store it as raw data\")\n",
    "\n",
    "    dataframe = wpa_combined[['iso3', row['WPA_OBS_RAW_COL']]] \n",
    "    dataframe['TIME_PERIOD'] = row['WPA_YEAR_COL'] \n",
    "\n",
    "    print(dataframe.head(30))\n",
    "\n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "    #except:\n",
    "    print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing \n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    print(dataframe['RAW_OBS_VALUE'].unique())\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Normalizing\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "\n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export concatented dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # CLEANSED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_cleansed_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_cleansed_csv[available_dim_cols] = combined_cleansed_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_cleansed_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_cleansed.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# # # # # NORMALIZED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_normalized_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_normalized_csv[available_dim_cols] = combined_normalized_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# S-101 has one duplicate row for country TON, drop that\n",
    "# This command should commented out when checking for other duplicat\n",
    "combined_normalized_csv = combined_normalized_csv.drop_duplicates()\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_normalized_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "### Some Exploratory data analysis on final dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1243, 41)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 390.429545 248.518125\" width=\"390.429545pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-13T12:39:02.894121</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 390.429545 248.518125 \nL 390.429545 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \nL 374.45 7.2 \nL 39.65 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 54.868182 224.64 \nL 65.013636 224.64 \nL 65.013636 224.603165 \nL 54.868182 224.603165 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 65.013636 224.64 \nL 75.159091 224.64 \nL 75.159091 224.64 \nL 65.013636 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 75.159091 224.64 \nL 85.304545 224.64 \nL 85.304545 224.64 \nL 75.159091 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 85.304545 224.64 \nL 95.45 224.64 \nL 95.45 224.529495 \nL 85.304545 224.529495 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 95.45 224.64 \nL 105.595455 224.64 \nL 105.595455 224.56633 \nL 95.45 224.56633 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 105.595455 224.64 \nL 115.740909 224.64 \nL 115.740909 224.529495 \nL 105.595455 224.529495 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 115.740909 224.64 \nL 125.886364 224.64 \nL 125.886364 224.455826 \nL 115.740909 224.455826 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 125.886364 224.64 \nL 136.031818 224.64 \nL 136.031818 224.234816 \nL 125.886364 224.234816 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 136.031818 224.64 \nL 146.177273 224.64 \nL 146.177273 224.050642 \nL 136.031818 224.050642 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 146.177273 224.64 \nL 156.322727 224.64 \nL 156.322727 224.64 \nL 146.177273 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 156.322727 224.64 \nL 166.468182 224.64 \nL 166.468182 224.308486 \nL 156.322727 224.308486 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 166.468182 224.64 \nL 176.613636 224.64 \nL 176.613636 221.877384 \nL 166.468182 221.877384 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 176.613636 224.64 \nL 186.759091 224.64 \nL 186.759091 223.0561 \nL 176.613636 223.0561 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 186.759091 224.64 \nL 196.904545 224.64 \nL 196.904545 222.429907 \nL 186.759091 222.429907 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 196.904545 224.64 \nL 207.05 224.64 \nL 207.05 222.245733 \nL 196.904545 222.245733 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 207.05 224.64 \nL 217.195455 224.64 \nL 217.195455 203.496777 \nL 207.05 203.496777 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 217.195455 224.64 \nL 227.340909 224.64 \nL 227.340909 220.735502 \nL 217.195455 220.735502 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 227.340909 224.64 \nL 237.486364 224.64 \nL 237.486364 221.693209 \nL 227.340909 221.693209 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 237.486364 224.64 \nL 247.631818 224.64 \nL 247.631818 218.193895 \nL 237.486364 218.193895 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 247.631818 224.64 \nL 257.777273 224.64 \nL 257.777273 224.64 \nL 247.631818 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 257.777273 224.64 \nL 267.922727 224.64 \nL 267.922727 208.764165 \nL 257.777273 208.764165 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 267.922727 224.64 \nL 278.068182 224.64 \nL 278.068182 214.289398 \nL 267.922727 214.289398 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 278.068182 224.64 \nL 288.213636 224.64 \nL 288.213636 210.163891 \nL 278.068182 210.163891 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 288.213636 224.64 \nL 298.359091 224.64 \nL 298.359091 192.777826 \nL 288.213636 192.777826 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 298.359091 224.64 \nL 308.504545 224.64 \nL 308.504545 103.895252 \nL 298.359091 103.895252 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 308.504545 224.64 \nL 318.65 224.64 \nL 318.65 195.098424 \nL 308.504545 195.098424 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 318.65 224.64 \nL 328.795455 224.64 \nL 328.795455 17.554286 \nL 318.65 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 328.795455 224.64 \nL 338.940909 224.64 \nL 338.940909 169.27717 \nL 328.795455 169.27717 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 338.940909 224.64 \nL 349.086364 224.64 \nL 349.086364 144.671468 \nL 338.940909 144.671468 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 349.086364 224.64 \nL 359.231818 224.64 \nL 359.231818 29.267779 \nL 349.086364 29.267779 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 88.686364 224.64 \nL 88.686364 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7ef56a6a2d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.686364\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1995 -->\n      <g transform=\"translate(75.961364 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 145.05 224.64 \nL 145.05 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.05\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(132.325 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 201.413636 224.64 \nL 201.413636 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.413636\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2005 -->\n      <g transform=\"translate(188.688636 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 257.777273 224.64 \nL 257.777273 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"257.777273\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2010 -->\n      <g transform=\"translate(245.052273 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 314.140909 224.64 \nL 314.140909 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.140909\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2015 -->\n      <g transform=\"translate(301.415909 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 370.504545 224.64 \nL 370.504545 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.504545\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2020 -->\n      <g transform=\"translate(357.779545 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 224.64 \nL 374.45 224.64 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1961d7a887\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 187.805117 \nL 374.45 187.805117 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"187.805117\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 191.604335)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 150.970233 \nL 374.45 150.970233 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"150.970233\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 154.769452)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 114.13535 \nL 374.45 114.13535 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"114.13535\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3000 -->\n      <g transform=\"translate(7.2 117.934569)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 77.300467 \nL 374.45 77.300467 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"77.300467\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4000 -->\n      <g transform=\"translate(7.2 81.099685)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 40.465583 \nL 374.45 40.465583 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"40.465583\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5000 -->\n      <g transform=\"translate(7.2 44.264802)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 39.65 224.64 \nL 39.65 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 374.45 224.64 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 39.65 7.2 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p24850146a1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Print number of observations older than 2010\n",
    "old_data = combined_normalized_csv[combined_normalized_csv['TIME_PERIOD']<2010] \n",
    "print(old_data.shape)\n",
    "\n",
    "# Visualize distribution of age of observations\n",
    "combined_normalized_csv.loc[(combined_normalized_csv['TIME_PERIOD']>1990) & (combined_normalized_csv['TIME_PERIOD']<2020), 'TIME_PERIOD'].hist(bins = 30)\n",
    "\n",
    "# Number of observations older than 2010\n",
    "old_data_grouped = old_data.groupby('INDICATOR_NAME').count()\n",
    "\n",
    "# Retrieve total number of observations\n",
    "combined_normalized_csv_grouped = combined_normalized_csv.groupby('INDICATOR_NAME').count()\n",
    "\n",
    "# Compare the number of rows older 2010 and total number of rows per indicators\n",
    "old_data_analysis = old_data_grouped[['COUNTRY_ISO_3']].merge(\n",
    "    right = combined_normalized_csv_grouped[['COUNTRY_ISO_3']],\n",
    "    on = 'INDICATOR_NAME'\n",
    ")\n",
    "\n",
    "# Add column indicating % of obs older\n",
    "old_data_analysis['OBS_PERCENT_OLDER_2010'] = round((old_data_analysis[\"COUNTRY_ISO_3_x\"] / old_data_analysis[\"COUNTRY_ISO_3_y\"]) * 100, 1) \n",
    "\n",
    "\n",
    "old_data_analysis.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'percentage_old_data_per_indicator.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "## Create aggregated scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined dataframe\n",
    "combined_normalized_csv = pd.read_csv(\n",
    "    cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# # # # # # # \n",
    "# Index score\n",
    "index_score = combined_normalized_csv.loc[:, ['INDICATOR_INDEX','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_INDEX','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column \n",
    "index_score = index_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_INDEX_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "index_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=index_score,\n",
    "    on=['INDICATOR_INDEX','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# # # # # # # \n",
    "# Issue score\n",
    "issue_score = combined_normalized_csv.loc[:, ['INDICATOR_ISSUE','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_ISSUE','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column\n",
    "issue_score = issue_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_ISSUE_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "issue_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'issue_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=issue_score,\n",
    "    on=['INDICATOR_ISSUE','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# # # # # # # # \n",
    "# Caregory score\n",
    "category_score = combined_normalized_csv.loc[:, ['INDICATOR_CATEGORY','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_CATEGORY','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column\n",
    "category_score = category_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_CATEGORY_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "category_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'category_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=category_score,\n",
    "    on=['INDICATOR_CATEGORY','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# Save combined dataframe \n",
    "combined_normalized_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "### Temp to export the results "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined dataframe\n",
    "index_score_csv = pd.read_csv(\n",
    "    cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "index_score_csv = index_score_csv.merge(\n",
    "    right=country_crba_list,\n",
    "    how='left',\n",
    "    on='COUNTRY_ISO_3'\n",
    ")\n",
    "\n",
    "index_score_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOPMENT AND TRASH AREA"
   ]
  },
  {
   "source": [
    "### UNCTAD sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Country             Title of Legislation/Draft Legislation  \\\n",
       "72       Iraq              Draft Data Protection and Privacy Law   \n",
       "111  Pakistan  Electronic Data Protection Act 2005 - Draft (i...   \n",
       "159  Zimbabwe                    Draft Data Protection Bill 2016   \n",
       "\n",
       "                                         Links to Laws RAW_OBS_VALUE  \n",
       "72                                                 NaN             2  \n",
       "111  http://media.mofo.com/docs/mofoprivacy/PAKISTA...             2  \n",
       "159  http://www.techzim.co.zw/wp-content/uploads/20...             2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Title of Legislation/Draft Legislation</th>\n      <th>Links to Laws</th>\n      <th>RAW_OBS_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72</th>\n      <td>Iraq</td>\n      <td>Draft Data Protection and Privacy Law</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>Pakistan</td>\n      <td>Electronic Data Protection Act 2005 - Draft (i...</td>\n      <td>http://media.mofo.com/docs/mofoprivacy/PAKISTA...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>Zimbabwe</td>\n      <td>Draft Data Protection Bill 2016</td>\n      <td>http://www.techzim.co.zw/wp-content/uploads/20...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "s_121 = pd.read_excel(    \n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-121_CC.xlsx\")\n",
    "\n",
    "s_121['RAW_OBS_VALUE'] = s_121['Title of Legislation/Draft Legislation'].apply(lambda x: '2' if re.search('Draft', x) else '3')\n",
    "\n",
    "# re.search(\"Draft\", s_121.iloc[242, 1])\n",
    "\n",
    "s_121[s_121['RAW_OBS_VALUE'] == '2']\n",
    "\n",
    "\n",
    "# # # # # # \n",
    "\n",
    "s_122 = pd.read_excel(    \n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-122_DP.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s_122['RAW_OBS_VALUE'] = s_122['Title of Legislation/Draft Legislation'].apply(lambda x: '2' if re.search('Draft', x) else '3')\n",
    "\n",
    "# re.search(\"Draft\", s_121.iloc[242, 1])\n",
    "\n",
    "s_122[s_122['RAW_OBS_VALUE'] == '2']\n",
    "\n",
    "# s_122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# S-11: Legal framework\\ns_11_raw = S_11_S120_s_124_s_134[[\\'Score.2\\', \\'Unnamed: 29\\']]\\n\\n# Rename columns\\ns_11_raw = s_11_raw.rename(\\n    columns = {\\n        \\'Score.2\\': \\'RAW_OBS_VALUE\\',\\n        \\'Unnamed: 29\\': \\'COUNTRY_NAME\\'\\n    }\\n)\\n\\n# Add year column\\ns_11_raw[\\'TIME_PERIOD\\'] = 2019\\n\\n# Save\\ns_11_raw.to_csv(data_sources_staged_raw / \"S-11_staged_raw.csv\", sep=\";\")\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "### IDMC\n",
    "S_180_S181_s_189 = pd.read_excel(\n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-180, S-181, S-189 idmc_displacement_all_dataset.xlsx\",\n",
    ")\n",
    "\n",
    "# Define list to extract the relevant columns and save them as raw data csv\n",
    "eit_list = [\n",
    "    [\"S-11_staged_raw.csv\", [\n",
    "        'Score.2',\n",
    "        'Unnamed: 29'\n",
    "        ]\n",
    "    ],\n",
    "    [\"S-124_staged_raw.csv\", [\n",
    "        'Score.1',\n",
    "        'Unnamed: 20'\n",
    "        ]\n",
    "    ],\n",
    "    [\"S-134_staged_raw.csv\", [\n",
    "        'Score.3',\n",
    "        'Unnamed: 38'\n",
    "        ]\n",
    "    ], # To do: Currently waiting to hear back from Alex concerning soure S-120\n",
    "    [\"S-11_staged_raw.csv\", [\n",
    "        'Score.2',\n",
    "        'Unnamed: 29'\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Loop through list\n",
    "for element in eit_list:\n",
    "    # Extract right columns\n",
    "    dataframe = S_11_S120_s_124_s_134[element[1]]\n",
    "\n",
    "    # Rename clumns\n",
    "    dataframe = dataframe.rename(\n",
    "        columns = {\n",
    "            element[1][0]: 'RAW_OBS_VALUE',\n",
    "            element[1][1]: 'COUNTRY_NAME'\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Add year column\n",
    "    dataframe['TIME_PERIOD'] = 2019\n",
    "\n",
    "    # Save data\n",
    "    dataframe.to_csv(data_sources_staged_raw / element[0], sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract selenium sources --> This code is stable as of 06.11.20, TO DO is to put this into a loop (which must be done in container, so I can only do it once James has looked at the issue with Chrome driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\envs\\unicef-test\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "      <th>ATTR_TREATY_STATUS</th>\n",
       "      <th>ATTR_FOOTNOTE_OF_SOURCE</th>\n",
       "      <th>COUNTRY_ISO_2</th>\n",
       "      <th>COUNTRY_ISO_3</th>\n",
       "      <th>_merge</th>\n",
       "      <th>RAW_OBS_VALUE</th>\n",
       "      <th>ATTR_ENCODING_LABELS</th>\n",
       "      <th>SCALED_OBS_VALUE</th>\n",
       "      <th>OBS_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>In Force</td>\n",
       "      <td>Excluding Article 11 by virtue of the ratifica...</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>AR</td>\n",
       "      <td>ARG</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>In Force</td>\n",
       "      <td>Excluding Article 11 by virtue of the ratifica...</td>\n",
       "      <td>AM</td>\n",
       "      <td>ARM</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UZB</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VUT</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VNM</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    COUNTRY_NAME ATTR_TREATY_STATUS  \\\n",
       "0    Afghanistan           In Force   \n",
       "1        Albania           In Force   \n",
       "2        Algeria           In Force   \n",
       "3      Argentina           In Force   \n",
       "4        Armenia           In Force   \n",
       "..           ...                ...   \n",
       "192          NaN                NaN   \n",
       "193          NaN                NaN   \n",
       "194          NaN                NaN   \n",
       "195          NaN                NaN   \n",
       "196          NaN                NaN   \n",
       "\n",
       "                               ATTR_FOOTNOTE_OF_SOURCE COUNTRY_ISO_2  \\\n",
       "0                                                                 AF   \n",
       "1    Excluding Article 11 by virtue of the ratifica...            AL   \n",
       "2                                                                 DZ   \n",
       "3                                                                 AR   \n",
       "4    Excluding Article 11 by virtue of the ratifica...            AM   \n",
       "..                                                 ...           ...   \n",
       "192                                                NaN           NaN   \n",
       "193                                                NaN           NaN   \n",
       "194                                                NaN           NaN   \n",
       "195                                                NaN           NaN   \n",
       "196                                                NaN           NaN   \n",
       "\n",
       "    COUNTRY_ISO_3      _merge RAW_OBS_VALUE  \\\n",
       "0             AFG        both             2   \n",
       "1             ALB        both             2   \n",
       "2             DZA        both             2   \n",
       "3             ARG        both             2   \n",
       "4             ARM        both             2   \n",
       "..            ...         ...           ...   \n",
       "192           USA  right_only             1   \n",
       "193           UZB  right_only             1   \n",
       "194           VUT  right_only             1   \n",
       "195           VNM  right_only             1   \n",
       "196           ZWE  right_only             1   \n",
       "\n",
       "                                  ATTR_ENCODING_LABELS  SCALED_OBS_VALUE  \\\n",
       "0    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "1    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "2    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "3    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "4    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "..                                                 ...               ...   \n",
       "192  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "193  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "194  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "195  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "196  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "\n",
       "    OBS_STATUS  \n",
       "0          nan  \n",
       "1          nan  \n",
       "2          nan  \n",
       "3          nan  \n",
       "4          nan  \n",
       "..         ...  \n",
       "192        nan  \n",
       "193        nan  \n",
       "194        nan  \n",
       "195        nan  \n",
       "196        nan  \n",
       "\n",
       "[197 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Specify location of chromedriver\n",
    "cwd = os.getcwd()\n",
    "driver_location = cwd + '\\\\chromedriver.exe'\n",
    "\n",
    "# Add option to make it headless (so that it doesn't open an actual chrome window)\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(driver_location, chrome_options=options)\n",
    "\n",
    "# Get HTTP response\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312256:NO\")\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO::P11300_INSTRUMENT_ID:312283\")\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312328:NO\")\n",
    "response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312240:NO\")\n",
    "\n",
    "# Get response\n",
    "# response = driver.get(html_url)\n",
    "\n",
    "# Retrieve the actual html\n",
    "html = driver.page_source\n",
    "\n",
    "# Soupify\n",
    "soup = bs.BeautifulSoup(html)\n",
    "\n",
    "# Extract the target table as attribute\n",
    "target_table = str(\n",
    "    soup.find_all(\"table\", {\"cellspacing\": \"0\", \"class\": \"horizontalLine\"})\n",
    ")\n",
    "\n",
    "# Create dataframe with the data\n",
    "raw_data = pd.read_html(io=target_table, header=0)[\n",
    "    0\n",
    "]  # return is a list of DFs, specify [0] to get actual DF\n",
    "\n",
    "# Cleansing\n",
    "dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "    raw_data=raw_data,\n",
    "    mapping_dictionary=mapping_dict,\n",
    "    final_sdmx_col_list=sdmx_df_columns_all\n",
    ")\n",
    "\n",
    "dataframe = cleanse.Cleanser().decompose_country_footnote_ilo_normlex(\n",
    "    dataframe = dataframe,\n",
    "    country_name_list = country_full_list.COUNTRY_NAME\n",
    ")\n",
    "\n",
    "dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "    grouped_data=dataframe,\n",
    "    crba_country_list=country_crba_list,\n",
    "    country_list_full = country_full_list\n",
    ")\n",
    "\n",
    "dataframe_cleansed = cleanse.Cleanser().encode_ilo_un_treaty_data(\n",
    "    dataframe = dataframe,\n",
    "    treaty_source_body='ILO NORMLEX'\n",
    ")\n",
    "\n",
    "# Normalizing section\n",
    "dataframe_normalized = scaler.normalizer(\n",
    "    cleansed_data = dataframe_cleansed,\n",
    "    sql_subset_query_string=None\n",
    ")\n",
    "\n",
    "dataframe_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"][5]\n",
    "       \n",
    "# Speifically for ILO NORMLEX - extract country name if additonal info is given\n",
    "#dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"] = dataframe[\"COUNTRY_NAME\"]\n",
    "#dataframe[\"COUNTRY_NAME\"] = dataframe[\"COUNTRY_NAME\"].apply(extract_country_name)\n",
    "#dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"] = dataframe.apply(lambda x: re.sub(x['COUNTRY_NAME'], \"\", x[\"ATTR_FOOTNOTE_OF_SOURCE\"]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import os\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "\n",
    "# cwd = Path('.')\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Current working directory\n",
    "driver_location = cwd + '\\\\geckodriver.exe'\n",
    "\n",
    "print(driver_location)\n",
    "\n",
    "# Open the targete html. Must be done with selenium, because it doesnt work with normal URL request\n",
    "#driver = webdriver.Firefox(executable_path=\"D:/Documents/2020/28_UNICEF/10_working_repo/data-etl/geckodriver.exe\")\n",
    "driver = webdriver.Firefox(executable_path=driver_location)\n",
    "\n",
    "# Get HTTP response\n",
    "response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312256:NO\")\n"
   ]
  },
  {
   "source": [
    "## GHG\n",
    "\n",
    "problem: \n",
    "\n",
    "* Cannot use pd_json_normalize --> It won't unnest it becaust he years and actual values are given in [] rather than {}\n",
    "* Stopped here: Must replace the character (but for that it is necessary to convert json to string and back)\n",
    "* Next challnge: Get all data (and not only page 1) --> Main problem is that the API is not working, i.e. can't specify paramters\n",
    "\n",
    "Stopped here 10.11.20 --> Need to get rid of \"[]\" signgs for "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_json = requests.get(\"https://www.climatewatchdata.org/api/v1/data/historical_emissions\").text\n",
    "\n",
    "dataframe_json_cleansed = dataframe_json.replace('[', '{').replace(']','}')\n",
    "json_file = json.dumps(dataframe_json_cleansed)\n",
    "# some_var = json.loads(dataframe_json_cleansed)\n",
    "# type(some_var)\n",
    "# pd.json_normalize(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'indicator': {'id': 'RL.EST', 'value': 'Rule of Law: Estimate'}, 'country': {'id': 'AF', 'value': 'Afghanistan'}, 'countryiso3code': 'AFG', 'date': '2017', 'value': -1.569692, 'unit': '', 'obs_status': '', 'decimal': 0}\n"
     ]
    }
   ],
   "source": [
    "temp = pd.json_normalize(requests.get(\"https://api.worldbank.org/v2/country/all/indicator/EL.EST?format=json&per_page=10000\").json()[1])\n",
    "\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_pos in len(range(dataframe_json['data'])):\n",
    "    for         \n",
    "    dataframe_json['data'][index_pos]['emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36mConvert\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}\n",
    "    return res_dct\n",
    "\n",
    "print(Convert(dataframe_json['data'][3]['emissions']))\n",
    "\n",
    "dataframe_json['data'][3]['emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # TEMP DELETE THIS\n",
    "# temp = extract.JSONExtractor.extract(url = \"https://api.worldbank.org/v2/country/all/indicator/VA.EST?format=json&per_page=10000\")\n",
    "\n",
    "temp = pd.json_normalize(requests.get(\"https://api.worldbank.org/v2/country/all/indicator/EL.EST?format=json&per_page=10000\").json()[1])\n",
    "\n",
    "\n",
    "# https://api.worldbank.org/v2/country/all/indicator/UIS.XPUBP.0?format=json&per_page=10000\n",
    "\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    year  value\n",
       "0   1990    NaN\n",
       "1   1991    NaN\n",
       "2   1992    NaN\n",
       "3   1993    NaN\n",
       "4   1994    NaN\n",
       "5   1995    NaN\n",
       "6   1996    NaN\n",
       "7   1997    NaN\n",
       "8   1998    NaN\n",
       "9   1999    NaN\n",
       "10  2000    NaN\n",
       "11  2001    NaN\n",
       "12  2002    NaN\n",
       "13  2003    NaN\n",
       "14  2004    NaN\n",
       "15  2005  15.11\n",
       "16  2006    NaN\n",
       "17  2007    NaN\n",
       "18  2008    NaN\n",
       "19  2009    NaN\n",
       "20  2010    NaN\n",
       "21  2011    NaN\n",
       "22  2012    NaN\n",
       "23  2013  32.74\n",
       "24  2014    NaN\n",
       "25  2015    NaN\n",
       "26  2016    NaN\n",
       "27  2017    NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1990</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1993</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1994</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1995</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1996</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1997</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1998</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1999</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2004</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2005</td>\n      <td>15.11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2006</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2007</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2008</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2009</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2010</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2011</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2012</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2013</td>\n      <td>32.74</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2014</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2015</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2016</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2017</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#dataframe = extract.CSVExtractor.extract(url = \"https://www.climatewatchdata.org/api/v1/data/historical_emissions\")\n",
    "\n",
    "dataframe_json = requests.get(\"https://www.climatewatchdata.org/api/v1/data/historical_emissions\").json()\n",
    "\n",
    "cleaned_json = dataframe_json['data']# .replace('[', '{').replace\n",
    "print(type(cleaned_json))\n",
    "\"\"\"\n",
    "# with open(dataframe_json, 'r') as file:\n",
    "    content = file.read()\n",
    "    clean = content.replace(']', '}')  # cleanup here\n",
    "    json_data = json.loads(clean)\n",
    "\"\"\"\n",
    "\n",
    "# dataframe_2 = pd.json_normalize(dataframe_json['data'], max_level=5)\n",
    "\n",
    "# dataframe_3 = pd.json_normalize(dataframe_json['data)\n",
    "\n",
    "\n",
    "#dataframe_3\n",
    "\n",
    "df = pd.json_normalize(cleaned_json)\n",
    "df_2 = pd.json_normalize(df.loc[5, 'emissions'])\n",
    "\n",
    "df_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}