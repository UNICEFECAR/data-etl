{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "source": [
    "# Preliminaries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Required standard libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import selenium\n",
    "import html5lib\n",
    "import nltk\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "# Extractors \n",
    "import extract\n",
    "\n",
    "# Cleansers (cluster specific)\n",
    "import cleanse\n",
    "\n",
    "# Normalizer (generalised across all clusters)\n",
    "from normalize import scaler\n",
    "\n",
    "# Utils\n",
    "from utils import utils"
   ]
  },
  {
   "source": [
    "## Define filepaths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export path for all data exports\n",
    "from pathlib import Path\n",
    "\n",
    "# Current working directory\n",
    "cwd = Path('.')\n",
    "\n",
    "# Folder with data-in artifacts, quired to run this script\n",
    "data_in = cwd / 'data_in'\n",
    "\n",
    "# Folder to export raw data\n",
    "data_sources_raw = cwd / 'data_out' / 'data_raw'\n",
    "data_sources_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export cleansed data\n",
    "data_sources_cleansed = cwd / 'data_out' / 'data_cleansed'\n",
    "data_sources_cleansed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export normalized data\n",
    "data_sources_normalized = cwd / 'data_out' / 'data_normalized'\n",
    "data_sources_normalized.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "source": [
    "## Load country list and mapping dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Create a version of the list with unique ISO2 and ISO3 codes\n",
    "country_iso_list = country_full_list.drop_duplicates(subset = 'COUNTRY_ISO_2')\n",
    "\n",
    "# Country CRBA list, this is the list of the countries that should be in the final CRBA indicator list\n",
    "country_crba_list = pd.read_excel(\n",
    "    data_in / 'crba_country_list.xlsx',\n",
    "    header = None,\n",
    "    usecols = [0, 1], \n",
    "    names = ['COUNTRY_ISO_3', 'COUNTRY_NAME']).merge(\n",
    "        right = country_iso_list[['COUNTRY_ISO_2', 'COUNTRY_ISO_3']],\n",
    "        how = 'left',\n",
    "        on='COUNTRY_ISO_3',\n",
    "        validate = 'one_to_one')\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'column_mapping.py') as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'value_mapping.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "source": [
    "## Read data dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources sheet\n",
    "crba_data_dictionary_source = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Source\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# snapshot sheet\n",
    "crba_data_dictionary_snapshot = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Snapshot\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# indicator sheet\n",
    "crba_data_dictionary_indicator = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Indicator\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Input lists\n",
    "crba_data_dictionary_input_list = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Input_Lists\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Add 2-digit shortcodes of index, issue and category to indicators sheet\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.merge(\n",
    "    right=crba_data_dictionary_input_list[['INDEX', 'INDEX_CODE']],\n",
    "    left_on='INDEX',\n",
    "    right_on='INDEX'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['ISSUE', 'ISSUE_CODE']],\n",
    "    left_on='ISSUE',\n",
    "    right_on='ISSUE'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['CATEGORY', 'CATEGORY_CODE']],\n",
    "    left_on='CATEGORY',\n",
    "    right_on='CATEGORY'\n",
    ")\n",
    "\n",
    "# Create indicator code prefix (INDEX-ISSUE_CAEGORY CODE)\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE_PREFIX = crba_data_dictionary_indicator.INDEX_CODE +\n",
    "    \"_\" +\n",
    "    crba_data_dictionary_indicator.ISSUE_CODE+\n",
    "    \"_\"+\n",
    "    crba_data_dictionary_indicator.CATEGORY_CODE+\n",
    "    \"_\")\n",
    "\n",
    "# Create indicator code\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE = crba_data_dictionary_indicator.INDICATOR_CODE_PREFIX + crba_data_dictionary_indicator.INDICATOR_NAME.apply(\n",
    "    lambda x: utils.create_ind_code(x)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, inspect\n",
    "\n",
    "extractors = { \n",
    "    cls.type: cls for name, cls in inspect.getmembers(\n",
    "        importlib.import_module(\"extract\"), \n",
    "        inspect.isclass\n",
    "    ) if hasattr(cls, 'type')\n",
    "}"
   ]
  },
  {
   "source": [
    "# Staging (pre-processing) to create exceptional indicatorsÂ´ raw data \n",
    "\n",
    "#"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process S-180 and S-181\n",
    "# Important: File requires having filepaths from above defined and pandas already imported\n",
    "\n",
    "with open(data_in / 'staging_create_raw_data.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "source": [
    "# Extract - Transform - Load Loop\n",
    "## API sources\n",
    "### CSV API sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-51 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column COLLECTION has 1 unique values.\n",
      "The column REF_AREA has 113 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column MEASURE has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 766 unique values.\n",
      "The column OBS_STATUS has 2 unique values.\n",
      "The column UNIT_MEASURE_TYPE has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column SOURCE_NOTE has 43 unique values.\n",
      "The column INDICATOR_NOTE has 50 unique values.\n",
      "The column CLASSIFICATION_NOTE has 1 unique values.\n",
      "The column CURRENCY_NOTE has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The column UPPER_BOUND has 1 unique values.\n",
      "The column LOWER_BOUND has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-51 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 415 rows in the dataframe and 20.48% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     415.000000\n",
      "mean     2017.101205\n",
      "std         2.387442\n",
      "min      2012.000000\n",
      "25%      2015.000000\n",
      "50%      2018.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-52 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 1 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column EDU_FIELD has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column TEACH_EXPERIENCE has 1 unique values.\n",
      "The column CONTRACT_TYPE has 1 unique values.\n",
      "The column COUNTRY_ORIGIN has 1 unique values.\n",
      "The column REGION_DEST has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 332 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 6701 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-52 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "\n",
      " Successfully mapped values of column: DIM_EDU_LEVEL\n",
      "\n",
      " Successfully mapped values of column: DIM_AGE\n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 541 rows in the dataframe and 4.07% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     541.000000\n",
      "mean     2016.916821\n",
      "std         1.902852\n",
      "min      2010.000000\n",
      "25%      2017.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-53 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column COLLECTION has 1 unique values.\n",
      "The column REF_AREA has 171 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column MEASURE has 1 unique values.\n",
      "The column OCU has 2 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 1283 unique values.\n",
      "The column OBS_STATUS has 1 unique values.\n",
      "The column UNIT_MEASURE_TYPE has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column SOURCE_NOTE has 90 unique values.\n",
      "The column INDICATOR_NOTE has 7 unique values.\n",
      "The column CLASSIFICATION_NOTE has 1 unique values.\n",
      "The column CURRENCY_NOTE has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The column UPPER_BOUND has 1 unique values.\n",
      "The column LOWER_BOUND has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-53 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_MANAGEMENT_LEVEL\n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 299 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     299.000000\n",
      "mean     2017.602007\n",
      "std         2.479201\n",
      "min      2010.000000\n",
      "25%      2017.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-55 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 1 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 260 unique values.\n",
      "The column TIME_PERIOD has 2 unique values.\n",
      "The column OBS_VALUE has 1167 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-55 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "\n",
      " Successfully mapped values of column: DIM_EDU_LEVEL\n",
      "\n",
      " Successfully mapped values of column: DIM_AGE\n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 379 rows in the dataframe and 22.16% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     379.000000\n",
      "mean     2018.092348\n",
      "std         1.110041\n",
      "min      2017.000000\n",
      "25%      2017.000000\n",
      "50%      2018.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-56 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 1 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 264 unique values.\n",
      "The column TIME_PERIOD has 2 unique values.\n",
      "The column OBS_VALUE has 1210 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-56 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "\n",
      " Successfully mapped values of column: DIM_EDU_LEVEL\n",
      "\n",
      " Successfully mapped values of column: DIM_AGE\n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 409 rows in the dataframe and 19.32% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     409.000000\n",
      "mean     2017.992665\n",
      "std         1.081232\n",
      "min      2017.000000\n",
      "25%      2017.000000\n",
      "50%      2018.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-82 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 132 unique values.\n",
      "The column Display Value has 3 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-82 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count           195\n",
      "unique            2\n",
      "top       2012-2014\n",
      "freq            131\n",
      "Name: TIME_PERIOD, dtype: object\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-83 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 132 unique values.\n",
      "The column Display Value has 4 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-83 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count           195\n",
      "unique            2\n",
      "top       2012-2014\n",
      "freq            131\n",
      "Name: TIME_PERIOD, dtype: object\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-88 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 3 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 6 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 5 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-88 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.015385\n",
      "std         0.123394\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-91 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 7 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 195 unique values.\n",
      "The column Display Value has 4 unique values.\n",
      "The column Numeric has 4 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-91 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2018.020513\n",
      "std         0.202025\n",
      "min      2018.000000\n",
      "25%      2018.000000\n",
      "50%      2018.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-95 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 3 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-95 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.061538\n",
      "std         0.493575\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-100 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column DATASOURCE has 70 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 15 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 70 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column Display Value has 215 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-100 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 331 rows in the dataframe and 38.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     331.000000\n",
      "mean     2015.141994\n",
      "std         4.950766\n",
      "min      2003.000000\n",
      "25%      2012.000000\n",
      "50%      2016.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-101 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column DATASOURCE has 641 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 95 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 153 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column Display Value has 224 unique values.\n",
      "The column Numeric has 224 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-101 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 471 rows in the dataframe and 8.92% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count      471\n",
      "unique      43\n",
      "top       2012\n",
      "freq        52\n",
      "Name: TIME_PERIOD, dtype: object\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-103 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 42 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 196 unique values.\n",
      "The column AGEGROUP has 3 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column Display Value has 51011 unique values.\n",
      "The column Numeric has 683 unique values.\n",
      "The column Low has 573 unique values.\n",
      "The column High has 778 unique values.\n",
      "The column Comments has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-103 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 1731 rows in the dataframe and 2.25% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    1731.000000\n",
      "mean     2016.006932\n",
      "std         0.166426\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-104 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 36 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 154 unique values.\n",
      "The column Display Value has 370 unique values.\n",
      "The column Numeric has 476 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 6 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-104 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 21.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count      195\n",
      "unique      23\n",
      "top       2020\n",
      "freq        41\n",
      "Name: TIME_PERIOD, dtype: int64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-112 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 11 unique values.\n",
      "The column REGION has 7 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 35 unique values.\n",
      "The column Numeric has 35 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-112 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 2.05% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2010.184615\n",
      "std         1.452608\n",
      "min      2006.000000\n",
      "25%      2010.000000\n",
      "50%      2010.000000\n",
      "75%      2010.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-113 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 5 unique values.\n",
      "The column REGION has 7 unique values.\n",
      "The column COUNTRY has 184 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column Display Value has 86 unique values.\n",
      "The column Numeric has 2835 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-113 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 561 rows in the dataframe and 2.14% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     561.000000\n",
      "mean     2016.085561\n",
      "std         0.579244\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-135 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 4 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 6 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 6 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-135 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.015385\n",
      "std         0.123394\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-136 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 4 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 6 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 6 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-136 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.015385\n",
      "std         0.123394\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-137 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 4 unique values.\n",
      "The column REGION has 7 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 6 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 6 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-137 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.015385\n",
      "std         0.123394\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-157 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 2 unique values.\n",
      "The column COUNTRY has 173 unique values.\n",
      "The column Display Value has 90 unique values.\n",
      "The column Numeric has 157 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-157 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 11.28% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2005.805128\n",
      "std         5.075002\n",
      "min      2004.000000\n",
      "25%      2004.000000\n",
      "50%      2004.000000\n",
      "75%      2004.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-158 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column UNREGION has 26 unique values.\n",
      "The column COUNTRY has 195 unique values.\n",
      "The column RESIDENCEAREATYPE has 3 unique values.\n",
      "The column Display Value has 618 unique values.\n",
      "The column Numeric has 628 unique values.\n",
      "The column Low has 570 unique values.\n",
      "The column High has 570 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-158 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AREA_TYPE\n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 577 rows in the dataframe and 0.52% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     577.000000\n",
      "mean     2016.020797\n",
      "std         0.287924\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-199 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 18 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 191 unique values.\n",
      "The column Display Value has 3165 unique values.\n",
      "The column Numeric has 3563 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-199 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 3.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2017.025641\n",
      "std         0.827591\n",
      "min      2011.000000\n",
      "25%      2017.000000\n",
      "50%      2017.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-200 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 132 unique values.\n",
      "The column Display Value has 3 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-200 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count           195\n",
      "unique            2\n",
      "top       2012-2014\n",
      "freq            131\n",
      "Name: TIME_PERIOD, dtype: object\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-201 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 132 unique values.\n",
      "The column Display Value has 4 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-201 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count           195\n",
      "unique            2\n",
      "top       2012-2014\n",
      "freq            131\n",
      "Name: TIME_PERIOD, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# CSV sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (ILO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNESCO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WHO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNICEF)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# define emty dataframe\n",
    "combined_cleansed_csv = pd.DataFrame()\n",
    "combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Extraction section\n",
    "    try:\n",
    "        # Extract data\n",
    "        dataframe = extract.CSVExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        \n",
    "        # Save raw data\n",
    "        dataframe.to_csv(\n",
    "            data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "            sep = \";\"\n",
    "            )\n",
    "    \n",
    "    except:\n",
    "       print(\"There was a problem with extraction of source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "source": [
    "### JSON API sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-23 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 3190 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 51 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Activity has 3 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-23 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 747 rows in the dataframe and 16.87% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     747.00000\n",
      "mean     2016.26506\n",
      "std         3.17993\n",
      "min      2004.00000\n",
      "25%      2014.00000\n",
      "50%      2017.00000\n",
      "75%      2018.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-24 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 91 unique values.\n",
      "The column geoAreaName has 91 unique values.\n",
      "The column timePeriodStart has 10 unique values.\n",
      "The column value has 228 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 3 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 5 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-24 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 377 rows in the dataframe and 27.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     377.000000\n",
      "mean     2015.694960\n",
      "std         3.327801\n",
      "min      2010.000000\n",
      "25%      2013.000000\n",
      "50%      2015.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-61 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 142 unique values.\n",
      "The column geoAreaName has 142 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 375 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-61 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 27.69% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.743590\n",
      "std         2.798361\n",
      "min      2008.000000\n",
      "25%      2016.000000\n",
      "50%      2017.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-62 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 208 unique values.\n",
      "The column geoAreaName has 208 unique values.\n",
      "The column timePeriodStart has 29 unique values.\n",
      "The column value has 86 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 11 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-62 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 15.9% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.271795\n",
      "std         4.545642\n",
      "min      1992.000000\n",
      "25%      2014.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-71 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 113 unique values.\n",
      "The column geoAreaName has 113 unique values.\n",
      "The column timePeriodStart has 4 unique values.\n",
      "The column value has 66 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-71 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 60.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2018.594872\n",
      "std         1.843063\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-78 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-78 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-79 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-79 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-80 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-80 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-81 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-81 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-125 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 58 unique values.\n",
      "The column geoAreaName has 58 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 62 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 13 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 2 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-125 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 206 rows in the dataframe and 69.42% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     206.000000\n",
      "mean     2018.315534\n",
      "std         3.078240\n",
      "min      2005.000000\n",
      "25%      2017.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-160 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 211 unique values.\n",
      "The column geoAreaName has 211 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 107 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-160 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 6.15% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.246154\n",
      "std         0.963736\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-161 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 294 unique values.\n",
      "The column geoAreaName has 294 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 51 unique values.\n",
      "The column valueType has 2 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 111 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-161 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 0.51% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.000000\n",
      "mean     2015.025510\n",
      "std         0.357143\n",
      "min      2015.000000\n",
      "25%      2015.000000\n",
      "50%      2015.000000\n",
      "75%      2015.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-183 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 82 unique values.\n",
      "The column geoAreaName has 82 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 90 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-183 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 359 rows in the dataframe and 31.48% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     359.000000\n",
      "mean     2018.679666\n",
      "std         1.126325\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-184 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 1193 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-184 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     469.000000\n",
      "mean     2017.147122\n",
      "std         2.662195\n",
      "min      2007.000000\n",
      "25%      2016.000000\n",
      "50%      2018.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-185 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 98 unique values.\n",
      "The column geoAreaName has 98 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 599 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-185 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 391 rows in the dataframe and 24.81% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     391.000000\n",
      "mean     2017.092072\n",
      "std         3.225971\n",
      "min      2007.000000\n",
      "25%      2016.000000\n",
      "50%      2018.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-186 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 95 unique values.\n",
      "The column geoAreaName has 95 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 84 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-186 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 51.79% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2017.984615\n",
      "std         3.107153\n",
      "min      2005.000000\n",
      "25%      2017.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-187 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 87 unique values.\n",
      "The column geoAreaName has 87 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 88 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-187 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 55.9% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2017.974359\n",
      "std         3.135161\n",
      "min      2007.000000\n",
      "25%      2017.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-188 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 110 unique values.\n",
      "The column geoAreaName has 110 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 79 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-188 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 43.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2018.974359\n",
      "std         1.123488\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-198 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 181 unique values.\n",
      "The column geoAreaName has 181 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 2025 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-198 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 10.77% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.589744\n",
      "std         4.092475\n",
      "min      2000.000000\n",
      "25%      2015.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-202 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-202 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-203 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 65 unique values.\n",
      "The column geoAreaName has 65 unique values.\n",
      "The column timePeriodStart has 19 unique values.\n",
      "The column value has 3381 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 46 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 128 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Type of occupation has 24 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-203 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "\n",
      " Successfully mapped values of column: DIM_OCU_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 2294 rows in the dataframe and 5.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    2294.000000\n",
      "mean     2013.275065\n",
      "std         4.840024\n",
      "min      2001.000000\n",
      "25%      2006.000000\n",
      "50%      2014.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-204 \n",
      "\n",
      "There was an issue with source S-204\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-204 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'COUNTRY_ISO_3'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d7b181b49282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     dataframe = cleanse.Cleanser().add_and_discard_countries(\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mgrouped_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mcrba_country_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcountry_crba_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/data-etl/cleanse/__init__.py\u001b[0m in \u001b[0;36madd_and_discard_countries\u001b[0;34m(cls, grouped_data, crba_country_list, country_list_full)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# Discard countries that aren't part of the final CRBA master list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             grouped_data_iso_filt = grouped_data_iso.merge(\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrba_country_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"COUNTRY_ISO_3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7944\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7946\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   7947\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7948\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'COUNTRY_ISO_3'"
     ]
    }
   ],
   "source": [
    "# JSON sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (SDG)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    try:\n",
    "        # Extract data \n",
    "        dataframe = extract.JSONExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        \n",
    "        # Save dataframe\n",
    "        dataframe.to_csv(\n",
    "            data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "            sep = \";\")\n",
    "    except:\n",
    "        print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing in \n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "source": [
    "### HTML UN Treaty Sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UN Treaty HTML sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"UN Treaties\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    dataframe = extract.HTMLExtractor().extract(url = row[\"ADDRESS\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Cleansing\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_un_treaty_data(\n",
    "        dataframe = dataframe\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "source": [
    "### Export the combined dataframe from CSV and JSON loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # CLEANSED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_cleansed_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_cleansed_csv[available_dim_cols] = combined_cleansed_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_cleansed_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_cleansed.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# # # # # NORMALIZED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_normalized_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_normalized_csv[available_dim_cols] = combined_normalized_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_normalized_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "# DEVELOPMENT AND TRASH AREA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   COUNTRY_NAME RAW_OBS_VALUE COUNTRY_ISO_2 COUNTRY_ISO_3 _merge\n",
       "38        Congo           NaN            CG           COG   both"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_NAME</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>COUNTRY_ISO_3</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38</th>\n      <td>Congo</td>\n      <td>NaN</td>\n      <td>CG</td>\n      <td>COG</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "sample_html_2[sample_html_2[\"COUNTRY_NAME\"] == \"Congo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-4 \n",
      "\n",
      "https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XVIII-12-a&chapter=18&clang=_en  \n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 35 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a), Succession(d) has 172 unique values.\n",
      "There was an issue with source S-4\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-4 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-31 \n",
      "\n",
      "https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=IV-13&chapter=4 \n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 68 unique values.\n",
      "The column Signature, Succession to signature(d) has 35 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 55 unique values.\n",
      "There was an issue with source S-31\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-31 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-84 \n",
      "\n",
      "https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=IX-4&chapter=9&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 188 unique values.\n",
      "The column Signature has 80 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Formal confirmation(c), Accession(a), Succession(d) has 158 unique values.\n",
      "There was an issue with source S-84\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-84 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-105 \n",
      "\n",
      "https://treaties.un.org/Pages/ShowMTDSGDetails.aspx?src=UNTSONLINE&tabid=2&mtdsg_no=IX-1&chapter=9&lang=en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2, 3, 4 has 193 unique values.\n",
      "The column Signature has 4 unique values.\n",
      "The column Definitive signature(s), Acceptance(A) has 177 unique values.\n",
      "There was an issue with source S-105\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-105 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-115 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=IND&mtdsg_no=IV-11-c&chapter=4&lang=en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 185 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 173 unique values.\n",
      "There was an issue with source S-115\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-115 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-141 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetailsIII.aspx?src=IND&mtdsg_no=XXVII-7&chapter=27&Temp=mtdsg3&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 21 unique values.\n",
      "The column Approval(AA), Acceptance(A), Accession(a), Succession(d), Ratification has 180 unique values.\n",
      "There was an issue with source S-141\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-141 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-142 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XXVII-7-d&chapter=27&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 17 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 115 unique values.\n",
      "There was an issue with source S-142\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-142 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-143 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XXVII-3&chapter=27&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature has 13 unique values.\n",
      "The column Approval(AA), Formal confirmation(c), Acceptance(A), Accession(a), Succession(d), Ratification has 184 unique values.\n",
      "There was an issue with source S-143\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-143 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-144 \n",
      "\n",
      "https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XXVII-15&chapter=27\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature, Succession to signature(d) has 42 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 180 unique values.\n",
      "There was an issue with source S-144\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-144 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-145 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XXVII-5&chapter=27&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature has 5 unique values.\n",
      "The column Ratification, Accession(a), Acceptance(A), Approval(AA) has 45 unique values.\n",
      "There was an issue with source S-145\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-145 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-162 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=IND&mtdsg_no=IV-3&chapter=4&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2 has 175 unique values.\n",
      "The column Signature has 64 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 170 unique values.\n",
      "There was an issue with source S-162\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-162 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-171 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XVIII-6&chapter=18&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature, Succession to signature(d) has 17 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 37 unique values.\n",
      "There was an issue with source S-171\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-171 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-173 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=TREATY&mtdsg_no=IV-11-b&chapter=4&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 62 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 162 unique values.\n",
      "There was an issue with source S-173\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-173 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-182 \n",
      "\n",
      "https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XXV-4&chapter=25&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 80 unique values.\n",
      "The column Signature has 36 unique values.\n",
      "The column Definitive signature(s), Ratification, Acceptance(A), Approval(AA), Accession(a) has 50 unique values.\n",
      "There was an issue with source S-182\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-182 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-191 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=IND&mtdsg_no=IV-11&chapter=4&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Acceptance(A), Accession(a), Succession(d) has 185 unique values.\n",
      "There was an issue with source S-191\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-191 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-192 \n",
      "\n",
      "https://treaties.un.org/Pages/ViewDetails.aspx?src=IND&mtdsg_no=IV-11-d&chapter=4&clang=_en\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 64 unique values.\n",
      "The column Signature has 24 unique values.\n",
      "The column Accession(a), Ratification has 46 unique values.\n",
      "There was an issue with source S-192\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-192 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# UN Treaty HTML sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"UN Treaties\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    dataframe = extract.HTMLExtractor().extract(url = row[\"ADDRESS\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Cleansing\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_un_treaty_data(\n",
    "        dataframe = dataframe\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following columns are present in the datasets, and this is the number of unique values they have. \nThe column Participant 2, 3, 4 has 193 unique values.\nThe column Signature has 4 unique values.\nThe column Definitive signature(s), Acceptance(A) has 177 unique values.\n\n Calling function 'rename_and_discard_columns'...\n\n Calling function 'add_and_discard_countries'...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "StatisticsError",
     "evalue": "no median for empty data",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ed83fc903eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m sample_html_2 = cleanse.Cleanser().add_and_discard_countries(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgrouped_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_html_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcrba_country_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcountry_crba_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/data-etl/cleanse/__init__.py\u001b[0m in \u001b[0;36madd_and_discard_countries\u001b[0;34m(cls, grouped_data, crba_country_list, country_list_full)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# prepare 4: Determine if the country col in the raw dataframe is ISO2, ISO3 or the actual country name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# TO DO What if country_col_right_join is a list of > 1 element?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         med_country_col_len = median(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mcrba_country_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountry_col_right_join\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/statistics.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no median for empty data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatisticsError\u001b[0m: no median for empty data"
     ]
    }
   ],
   "source": [
    "sample_html = extract.HTMLExtractor().extract(\"https://treaties.un.org/Pages/ShowMTDSGDetails.aspx?src=UNTSONLINE&tabid=2&mtdsg_no=IX-1&chapter=9&lang=en\")\n",
    "\n",
    "sample_html_1 = cleanse.Cleanser().rename_and_discard_columns(\n",
    "    raw_data = sample_html,\n",
    "    mapping_dictionary=mapping_dict,\n",
    "    final_sdmx_col_list=sdmx_df_columns_all\n",
    ")\n",
    "sample_html_1\n",
    "\n",
    "\n",
    "sample_html_2 = cleanse.Cleanser().add_and_discard_countries(\n",
    "    grouped_data=sample_html_1,\n",
    "    crba_country_list=country_crba_list,\n",
    "    country_list_full = country_full_list\n",
    ")\n",
    "\n",
    "\n",
    "sample_html_3 = cleanse.Cleanser().encode_un_treaty_data(\n",
    "    dataframe = sample_html_2\n",
    ")\n",
    "\n",
    "sample_html_4 =  scaler.normalizer(\n",
    "        cleansed_data = sample_html_3,\n",
    "        sql_subset_query_string=None,\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = \"UN Treaty\",\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "sample_html_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_html_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<Response [200]>\n<http.client.HTTPResponse object at 0x7f3765632f10>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            Participant    Signature  \\\n",
       "0                           Afghanistan          NaN   \n",
       "1                               Albania  12 Dec 2000   \n",
       "2                               Algeria   6 Jun 2001   \n",
       "3                                Angola          NaN   \n",
       "4                   Antigua and Barbuda          NaN   \n",
       "..                                  ...          ...   \n",
       "175                          Uzbekistan  28 Jun 2001   \n",
       "176  Venezuela (Bolivarian Republic of)  14 Dec 2000   \n",
       "177                            Viet Nam          NaN   \n",
       "178                              Zambia          NaN   \n",
       "179                            Zimbabwe          NaN   \n",
       "\n",
       "    Ratification, Acceptance(A), Approval(AA), Accession(a), Succession(d)  \n",
       "0                                        15 Aug 2014 a                      \n",
       "1                                          21 Aug 2002                      \n",
       "2                                           9 Mar 2004                      \n",
       "3                                        19 Sep 2014 a                      \n",
       "4                                          17 Feb 2010                      \n",
       "..                                                 ...                      \n",
       "175                                        12 Aug 2008                      \n",
       "176                                        13 May 2002                      \n",
       "177                                       8 Jun 2012 a                      \n",
       "178                                      24 Apr 2005 a                      \n",
       "179                                      13 Dec 2013 a                      \n",
       "\n",
       "[180 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Participant</th>\n      <th>Signature</th>\n      <th>Ratification, Acceptance(A), Approval(AA), Accession(a), Succession(d)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Afghanistan</td>\n      <td>NaN</td>\n      <td>15 Aug 2014 a</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albania</td>\n      <td>12 Dec 2000</td>\n      <td>21 Aug 2002</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Algeria</td>\n      <td>6 Jun 2001</td>\n      <td>9 Mar 2004</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angola</td>\n      <td>NaN</td>\n      <td>19 Sep 2014 a</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Antigua and Barbuda</td>\n      <td>NaN</td>\n      <td>17 Feb 2010</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>Uzbekistan</td>\n      <td>28 Jun 2001</td>\n      <td>12 Aug 2008</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>Venezuela (Bolivarian Republic of)</td>\n      <td>14 Dec 2000</td>\n      <td>13 May 2002</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>Viet Nam</td>\n      <td>NaN</td>\n      <td>8 Jun 2012 a</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>Zambia</td>\n      <td>NaN</td>\n      <td>24 Apr 2005 a</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>Zimbabwe</td>\n      <td>NaN</td>\n      <td>13 Dec 2013 a</td>\n    </tr>\n  </tbody>\n</table>\n<p>180 rows Ã 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "\n",
    "raw_html_1 = requests.get(\"https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XVIII-12-a&chapter=18&clang=_en\")\n",
    "\n",
    "# raw_html_1.text\n",
    "raw_html_2 = urllib.request.urlopen(\"https://treaties.un.org/pages/ViewDetails.aspx?src=TREATY&mtdsg_no=XVIII-12-a&chapter=18&clang=_en\")\n",
    "\n",
    "print(raw_html_1)\n",
    "print(raw_html_2)\n",
    "\n",
    "soup = bs.BeautifulSoup(raw_html_1.text, features=\"lxml\")\n",
    "#soup_2 = bs.BeautifulSoup(raw_html_2, features=\"lxml\")\n",
    "\n",
    "#soup_2\n",
    "# soup_1\n",
    "\n",
    "# Extract the target table as attribute\n",
    "target_table = str(\n",
    "    soup.find_all(\n",
    "        \"table\",\n",
    "        {\"class\": \"table table-striped table-bordered table-hover table-condensed\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create dataframe with the data\n",
    "raw_data = pd.read_html(io=target_table, header=0)[\n",
    "    0\n",
    "]\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Index', 'Variant', 'Region, subregion, country or area *', 'Notes',\n",
       "       'Country code', 'Type', 'Parent code', '1950', '1951', '1952', '1953',\n",
       "       '1954', '1955', '1956', '1957', '1958', '1959', '1960', '1961', '1962',\n",
       "       '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971',\n",
       "       '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980',\n",
       "       '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989',\n",
       "       '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998',\n",
       "       '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007',\n",
       "       '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016',\n",
       "       '2017', '2018', '2019', '2020'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "un_pop_tot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all column names of the year in the dataframe\n",
    "years = [str(x) for x in list(range(1950, 2021))] \n",
    "\n",
    "un_pop_tot.melt(\n",
    "    id_vars = ['Index', 'Variant', 'Region, subregion, country or area *', 'Notes',\n",
    "       'Country code', 'Type', 'Parent code'],\n",
    "    value_vars = years,\n",
    "    var_name = \"year\",\n",
    "    value_name = 'population'\n",
    ").to_csv(\"delete_this_again.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PosixPath('.')"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "Path(\".\").parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "un_pop_tot = pd.read_excel(io=data_in / \"WPP2019_POP_F01_1_TOTAL_POPULATION_BOTH_SEXES.xlsx\", sheet_name=\"ESTIMATES\", header=16)\n",
    "\n",
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Load raw data of S-180 and S-181\n",
    "S_180_S_181 = pd.read_excel(\n",
    "    data_in / 'data_raw_manually_extracted' / 'S-180, S-181, S-189 idmc_displacement_all_dataset.xlsx').drop(0) # delete first row containing strings\n",
    "\n",
    "# Cast year as string, required for merge command later\n",
    "S_180_S_181[\"Year\"] = S_180_S_181[\"Year\"].astype(str) \n",
    "\n",
    "# Define list of columns corresponding to year name columns\n",
    "years = [str(x) for x in list(range(1950, 2021))] \n",
    "\n",
    "# bring dataframe from wide to longformat\n",
    "un_pop_tot = un_pop_tot.melt(\n",
    "    id_vars = ['Index', 'Variant', 'Region, subregion, country or area *', 'Notes',\n",
    "       'Country code', 'Type', 'Parent code'],\n",
    "    value_vars = years,\n",
    "    var_name = \"year\",\n",
    "    value_name = 'population'\n",
    ") \n",
    "\n",
    "# Add ISO3 code to the list to prepare for join\n",
    "un_pop_tot = un_pop_tot.merge(\n",
    "    right = country_full_list,\n",
    "    how=\"outer\",\n",
    "    left_on=\"Region, subregion, country or area *\",\n",
    "    right_on=\"COUNTRY_NAME\"\n",
    ")\n",
    "\n",
    "# Create new col of composite key for merge command\n",
    "# un_pop_tot[\"ISO3_YEAR\"] = un_pop_tot[\"COUNTRY_ISO_3\"] + un_pop_tot[\"year\"]\n",
    "# S_180_S_181[\"ISO3_YEAR\"] = S_180_S_181[\"ISO3\"] + S_180_S_181[\"Year\"] \n",
    "\n",
    "# Join raw data and population data together\n",
    "s_180_s_181_raw = un_pop_tot.merge(\n",
    "    right=S_180_S_181,\n",
    "    how='outer',\n",
    "    #on=\"ISO3_YEAR\"\n",
    "    left_on=[\"COUNTRY_ISO_3\", \"year\"],\n",
    "    right_on=[\"ISO3\", \"Year\"]\n",
    ")\n",
    "\n",
    "# Create S_180\n",
    "s_180_raw = s_180_s_181_raw\n",
    "\n",
    "# Calculate target KPI (number of Internally displaced people per 100.000 people)\n",
    "s_180_raw[\"RAW_OBS_VALUE\"] = s_180_raw[\"Conflict Stock Displacement\"] / (s_180_raw[\"population\"]) * 100\n",
    "\n",
    "# Add unit measure\n",
    "s_180_raw[\"ATTR_UNIT_MEASURE\"] = \"Total number of IDPs (conflict and violence) per 100.000 people. Calculated as 'Total Number of IDPs (Conflict and violence)' taken from https://www.internal-displacement.org/database/displacement-data multiplied by 100 and divided by 'Total Population (given in 1.000)' taken from https://population.un.org/wpp/Download/Standard/Population//\"\n",
    "\n",
    "# Store data \n",
    "s_180_raw.to_csv(\n",
    "    data_sources_raw / \"S-180_raw.csv\",\n",
    "    sep = \";\")\n",
    "\n",
    "# Create S_180\n",
    "s_181_raw = s_180_s_181_raw\n",
    "\n",
    "# Calculate target KPI (number of Internally displaced people per 100.000 people)\n",
    "s_181_raw[\"RAW_OBS_VALUE\"] = s_181_raw[\"Conflict New Displacements\"] / (s_181_raw[\"population\"]) * 100\n",
    "\n",
    "# Add unit measure\n",
    "s_181_raw[\"ATTR_UNIT_MEASURE\"] = \"Number of new IDPs (conflict and violence) per 100.000 people for a given year. Calculated as 'Number of new IDPs (Conflict and violence)' in a given year taken from https://www.internal-displacement.org/database/displacement-data multiplied by 100 and divided by 'Total Population (given in 1.000)' taken from https://population.un.org/wpp/Download/Standard/Population//\"\n",
    "\n",
    "# Store data \n",
    "s_181_raw.to_csv(\n",
    "    data_sources_raw / \"S-181_raw.csv\",\n",
    "    sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of Conflict Stocj Displacement per 100.000 inhabitants\n",
    "s_180_raw[\"RAW_OBS_VALUE\"] = s_180_raw[\"Conflict Stock Displacement\"] / (s_180_raw[\"population\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Index    Variant Region, subregion, country or area * Notes  \\\n",
       "4461   31.0  Estimates                             Ethiopia   NaN   \n",
       "4463   31.0  Estimates                             Ethiopia   NaN   \n",
       "4465   31.0  Estimates                             Ethiopia   NaN   \n",
       "4466   31.0  Estimates                             Ethiopia   NaN   \n",
       "4467   31.0  Estimates                             Ethiopia   NaN   \n",
       "4468   31.0  Estimates                             Ethiopia   NaN   \n",
       "4469   31.0  Estimates                             Ethiopia   NaN   \n",
       "4470   31.0  Estimates                             Ethiopia   NaN   \n",
       "4471   31.0  Estimates                             Ethiopia   NaN   \n",
       "\n",
       "      Country code          Type  Parent code  year population COUNTRY_NAME  \\\n",
       "4461         231.0  Country/Area        910.0  2009    85233.9     Ethiopia   \n",
       "4463         231.0  Country/Area        910.0  2011    90139.9     Ethiopia   \n",
       "4465         231.0  Country/Area        910.0  2013    95385.8     Ethiopia   \n",
       "4466         231.0  Country/Area        910.0  2014    98094.3     Ethiopia   \n",
       "4467         231.0  Country/Area        910.0  2015     100835     Ethiopia   \n",
       "4468         231.0  Country/Area        910.0  2016     103603     Ethiopia   \n",
       "4469         231.0  Country/Area        910.0  2017     106400     Ethiopia   \n",
       "4470         231.0  Country/Area        910.0  2018     109224     Ethiopia   \n",
       "4471         231.0  Country/Area        910.0  2019     112079     Ethiopia   \n",
       "\n",
       "      ... COUNTRY_ISO_3 ISO3      Name  Year Conflict Stock Displacement  \\\n",
       "4461  ...           ETH  ETH  Ethiopia  2009                      350000   \n",
       "4463  ...           ETH  ETH  Ethiopia  2011                      350000   \n",
       "4465  ...           ETH  ETH  Ethiopia  2013                      316000   \n",
       "4466  ...           ETH  ETH  Ethiopia  2014                      397000   \n",
       "4467  ...           ETH  ETH  Ethiopia  2015                      450000   \n",
       "4468  ...           ETH  ETH  Ethiopia  2016                      258000   \n",
       "4469  ...           ETH  ETH  Ethiopia  2017                     1078000   \n",
       "4470  ...           ETH  ETH  Ethiopia  2018                     2137000   \n",
       "4471  ...           ETH  ETH  Ethiopia  2019                     1414000   \n",
       "\n",
       "     Conflict New Displacements Disaster New Displacements  \\\n",
       "4461                     200000                        NaN   \n",
       "4463                      50000                        NaN   \n",
       "4465                     179000                      61000   \n",
       "4466                     137000                      49000   \n",
       "4467                      56000                     104000   \n",
       "4468                     296000                     347000   \n",
       "4469                     725000                     434000   \n",
       "4470                    2895000                     296000   \n",
       "4471                    1052000                     504000   \n",
       "\n",
       "     Disaster Stock Displacement RAW_OBS_VALUE  \\\n",
       "4461                         NaN       234.648   \n",
       "4463                         NaN       55.4693   \n",
       "4465                         NaN       187.659   \n",
       "4466                         NaN       139.662   \n",
       "4467                         NaN        55.536   \n",
       "4468                         NaN       285.705   \n",
       "4469                         NaN       681.391   \n",
       "4470                         NaN       2650.51   \n",
       "4471                      390000       938.626   \n",
       "\n",
       "                                      ATTR_UNIT_MEASURE  \n",
       "4461  Number of new IDPs (conflict and violence) per...  \n",
       "4463  Number of new IDPs (conflict and violence) per...  \n",
       "4465  Number of new IDPs (conflict and violence) per...  \n",
       "4466  Number of new IDPs (conflict and violence) per...  \n",
       "4467  Number of new IDPs (conflict and violence) per...  \n",
       "4468  Number of new IDPs (conflict and violence) per...  \n",
       "4469  Number of new IDPs (conflict and violence) per...  \n",
       "4470  Number of new IDPs (conflict and violence) per...  \n",
       "4471  Number of new IDPs (conflict and violence) per...  \n",
       "\n",
       "[9 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>Variant</th>\n      <th>Region, subregion, country or area *</th>\n      <th>Notes</th>\n      <th>Country code</th>\n      <th>Type</th>\n      <th>Parent code</th>\n      <th>year</th>\n      <th>population</th>\n      <th>COUNTRY_NAME</th>\n      <th>...</th>\n      <th>COUNTRY_ISO_3</th>\n      <th>ISO3</th>\n      <th>Name</th>\n      <th>Year</th>\n      <th>Conflict Stock Displacement</th>\n      <th>Conflict New Displacements</th>\n      <th>Disaster New Displacements</th>\n      <th>Disaster Stock Displacement</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_UNIT_MEASURE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4461</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2009</td>\n      <td>85233.9</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2009</td>\n      <td>350000</td>\n      <td>200000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>234.648</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4463</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2011</td>\n      <td>90139.9</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2011</td>\n      <td>350000</td>\n      <td>50000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>55.4693</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4465</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2013</td>\n      <td>95385.8</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2013</td>\n      <td>316000</td>\n      <td>179000</td>\n      <td>61000</td>\n      <td>NaN</td>\n      <td>187.659</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4466</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2014</td>\n      <td>98094.3</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2014</td>\n      <td>397000</td>\n      <td>137000</td>\n      <td>49000</td>\n      <td>NaN</td>\n      <td>139.662</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4467</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2015</td>\n      <td>100835</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2015</td>\n      <td>450000</td>\n      <td>56000</td>\n      <td>104000</td>\n      <td>NaN</td>\n      <td>55.536</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4468</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2016</td>\n      <td>103603</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2016</td>\n      <td>258000</td>\n      <td>296000</td>\n      <td>347000</td>\n      <td>NaN</td>\n      <td>285.705</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4469</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2017</td>\n      <td>106400</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2017</td>\n      <td>1078000</td>\n      <td>725000</td>\n      <td>434000</td>\n      <td>NaN</td>\n      <td>681.391</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4470</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2018</td>\n      <td>109224</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2018</td>\n      <td>2137000</td>\n      <td>2895000</td>\n      <td>296000</td>\n      <td>NaN</td>\n      <td>2650.51</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n    <tr>\n      <th>4471</th>\n      <td>31.0</td>\n      <td>Estimates</td>\n      <td>Ethiopia</td>\n      <td>NaN</td>\n      <td>231.0</td>\n      <td>Country/Area</td>\n      <td>910.0</td>\n      <td>2019</td>\n      <td>112079</td>\n      <td>Ethiopia</td>\n      <td>...</td>\n      <td>ETH</td>\n      <td>ETH</td>\n      <td>Ethiopia</td>\n      <td>2019</td>\n      <td>1414000</td>\n      <td>1052000</td>\n      <td>504000</td>\n      <td>390000</td>\n      <td>938.626</td>\n      <td>Number of new IDPs (conflict and violence) per...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9 rows Ã 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "s_181_raw[(s_180_raw.RAW_OBS_VALUE.notnull()) & (s_180_raw.Name == \"Ethiopia\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_pop_tot[un_pop_tot._merge == \"left_only\"][\"Region, subregion, country or area *\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates\n",
    "\n",
    "# Checking to see if there are any duplicate entries\n",
    "duplicates = combined_normalized_csv[combined_normalized_csv.duplicated(\n",
    "    subset = [\n",
    "        \"COUNTRY_ISO_3\",\n",
    "        \"TIME_PERIOD\",\n",
    "        \"COUNTRY_NAME\",\n",
    "        \"COUNTRY_ISO_2\",\n",
    "        \"RAW_OBS_VALUE\",\n",
    "        \"DIM_SEX\",\n",
    "        \"DIM_EDU_LEVEL\",\n",
    "        \"DIM_AGE\",\n",
    "        \"DIM_AGE_GROUP\",\n",
    "        \"DIM_MANAGEMENT_LEVEL\",\n",
    "        \"DIM_AREA_TYPE\",\n",
    "        \"DIM_QUANTILE\",\n",
    "        \"DIM_SDG_INDICATOR\",\n",
    "        \"DIM_OCU_TYPE\",\n",
    "        \"DIM_REP_TYPE\",\n",
    "        \"DIM_SECTOR\",\n",
    "        \"INDICATOR_CODE\"\n",
    "        ],\n",
    "    keep = False\n",
    "\n",
    ")]\n",
    "\n",
    "duplicates.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'duplicates.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that my old and new results are the same (before and after the refactor):\n",
    "\n",
    "combined_old = pd.read_csv(\n",
    "    cwd / 'data_out' / \"combined_normalized_old.csv\",\n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "combined_new = pd.read_csv(\n",
    "    cwd / 'data_out' / \"combined_normalized.csv\",\n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "# combined_old.equals(combined_new)\n",
    "combined_old.info()\n",
    "print(\"space\")\n",
    "combined_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION BEFORE REFACTOR\n",
    "\n",
    "# CSV sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (ILO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNESCO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WHO)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# define emty dataframe\n",
    "combined_cleansed_csv = pd.DataFrame()\n",
    "combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Extraction section\n",
    "    try:\n",
    "        # Extract data\n",
    "        dataframe = extract.CSVExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        \n",
    "        # Save raw data\n",
    "        dataframe.to_csv(\n",
    "            data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "            sep = \";\"\n",
    "            )\n",
    "    \n",
    "    except:\n",
    "       print(\"There was a problem with extraction of source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing section\n",
    "    # try: \n",
    "    print(row[\"VALUE_LABELS\"])\n",
    "    dataframe_cleansed = cleanse.Cleanser().cleanse(\n",
    "        raw_data = dataframe,\n",
    "        mapping_dictionary = mapping_dict,\n",
    "        final_sdmx_col_list = sdmx_df_columns_all,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "        country_list_full = country_full_list,\n",
    "        crba_country_list = country_crba_list,\n",
    "        variable_type = row[\"VALUE_LABELS\"]\n",
    "        )\n",
    "\n",
    "    # Map column values\n",
    "    dataframe_cleansed = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        value_mapping_dict = value_mapper)\n",
    "    \n",
    "\n",
    "    # Encode values of categorical variables\n",
    "    if row[\"VALUE_LABELS\"] != \"Continuous variable\":\n",
    "        dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(dataframe = dataframe_cleansed, encoding_string = row[\"VALUE_LABELS\"])\n",
    "\n",
    "\n",
    "    # Add columns\n",
    "    # Indicator name\n",
    "    dataframe_cleansed[\"INDICATOR_NAME\"] = row[\"INDICATOR_NAME_x\"]\n",
    "\n",
    "    # Index name\n",
    "    dataframe_cleansed[\"INDICATOR_INDEX\"] = row[\"INDEX\"]\n",
    "\n",
    "    # Issue name\n",
    "    dataframe_cleansed[\"INDICATOR_ISSUE\"] = row[\"ISSUE\"]\n",
    "\n",
    "    # Category name\n",
    "    dataframe_cleansed[\"INDICATOR_CATEGORY\"] = row[\"CATEGORY\"]\n",
    "\n",
    "    # YEAR_CRBA_RELEASE with current year\n",
    "    dataframe_cleansed[\"CRBA_RELEASE_YEAR\"] = datetime.datetime.now().year\n",
    "\n",
    "    # Create column indicator code\n",
    "    dataframe_cleansed[\"INDICATOR_CODE\"] = row[\"INDICATOR_CODE\"]\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Log if there is an error\n",
    "    # except:\n",
    "    #     print(\"There was a problem with cleansing of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    \n",
    "    # Normalizing section\n",
    "    # try:\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "    # except:\n",
    "    #    print(\"There was a problem with normalising of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    \n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (SDG)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    try:\n",
    "        dataframe = extract.JSONExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        dataframe.to_csv(\n",
    "            data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "            sep = \";\")\n",
    "    except:\n",
    "        print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing section \n",
    "    # try:\n",
    "    dataframe_cleansed = cleanse.Cleanser().cleanse(\n",
    "        raw_data = dataframe,\n",
    "        mapping_dictionary = mapping_dict,\n",
    "        final_sdmx_col_list = sdmx_df_columns_all,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "        country_list_full = country_full_list,\n",
    "        crba_country_list = country_crba_list,\n",
    "        variable_type=row[\"VALUE_LABELS\"]\n",
    "        )\n",
    "    \n",
    "    # Map column values\n",
    "    dataframe_cleansed = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        value_mapping_dict = value_mapper)\n",
    "    \n",
    "    # Encode values of categorical variables\n",
    "    if row[\"VALUE_LABELS\"] != \"Continuous variable\":\n",
    "        dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "            dataframe = dataframe_cleansed,\n",
    "            encoding_string = row[\"VALUE_LABELS\"])\n",
    "\n",
    "    # This is where columns were inserted\n",
    "\n",
    "    # Save dataframe\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # except:\n",
    "    #    print(\"There was an issue with cleansing of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    \n",
    "    # Normalizing section\n",
    "    # try:\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "\n",
    "\n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "sep = \";\")\n",
    "    # except:\n",
    "    #    print(\"There was a problem with normalising of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Append dataframe to combined cleansed dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )\n",
    "\n",
    "# TO DO: Also include JSON and HTML as extractor --> No other way to put it into the loop than eval()?"
   ]
  },
  {
   "source": [
    "### Develop normaliation for categorical variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(\n",
    "    cleansed_data,\n",
    "    sql_subset_query_string,\n",
    "    variable_type=\"Continuous variable\",\n",
    "    is_inverted=\"not inverted\",\n",
    "    whisker_factor=1.5,\n",
    "    raw_data_col=\"RAW_OBS_VALUE\",\n",
    "    scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "    maximum_score=10,\n",
    "):\n",
    "    \"\"\"Normalize the RAW_OBS_VALUES into indicator scores\n",
    "\n",
    "    TO DO\n",
    "\n",
    "    Parameters:\n",
    "    TO DO\n",
    "    **dimensions (mapping type): Define the present dimension variables as keys\n",
    "    along with the dimension value that is supposed to be taken for the normalization.\n",
    "\n",
    "    \"\"\"\n",
    "    if variable_type != \"Continuous variable\":\n",
    "        # Build conditions array\n",
    "        unique_values = cleansed_data[raw_data_col].unique()\n",
    "        print(unique_values)\n",
    "        print(type(unique_values))\n",
    "\n",
    "        conditions = []\n",
    "        for value in np.sort(unique_values):\n",
    "            print(value)\n",
    "            conditions += [cleansed_data[raw_data_col] == value]\n",
    "\n",
    "        # Assign variable for readability purpose\n",
    "        length_unique_values = len(np.sort(cleansed_data[raw_data_col].unique()))\n",
    "\n",
    "        # Build norm values array, where 0 =< norm_values => 10\n",
    "        norm_values = []\n",
    "        for value in range(length_unique_values):\n",
    "            distance = maximum_score / (length_unique_values - 1)\n",
    "            norm_values += [distance * float(value)]\n",
    "\n",
    "        # store normalized scores in SCALED_OBS_VALUE\n",
    "        cleansed_data[scaled_data_col_name] = np.select(conditions, norm_values)\n",
    "\n",
    "\n",
    "s82_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-182_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          GHO PUBLISHSTATE  YEAR REGION WORLDBANKINCOMEGROUP  \\\n",
       "0     GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2009    EMR                WB_LI   \n",
       "1     GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2010    EMR                WB_LI   \n",
       "2     GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2011    EMR                WB_LI   \n",
       "3     GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2012    EMR                WB_LI   \n",
       "4     GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2008    AFR               WB_UMI   \n",
       "...                       ...          ...   ...    ...                  ...   \n",
       "3558  GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2017    NaN               WB_UMI   \n",
       "3559  GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2008    NaN                WB_HI   \n",
       "3560  GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2009    NaN                WB_HI   \n",
       "3561  GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2010    NaN                WB_HI   \n",
       "3562  GHED_CHE_pc_PPP_SHA2011    PUBLISHED  2011    NaN                WB_HI   \n",
       "\n",
       "     COUNTRY  Display Value     Numeric  Low  High  Comments  \n",
       "0        AFG          143.8   143.84962  NaN   NaN       NaN  \n",
       "1        AFG          132.3   132.27129  NaN   NaN       NaN  \n",
       "2        AFG          138.8   138.82262  NaN   NaN       NaN  \n",
       "3        AFG          144.0   143.96532  NaN   NaN       NaN  \n",
       "4        DZA          510.9   510.92255  NaN   NaN       NaN  \n",
       "...      ...            ...         ...  ...   ...       ...  \n",
       "3558     NaN         1013.8  1013.75916  NaN   NaN       NaN  \n",
       "3559     NaN         2559.5  2559.51753  NaN   NaN       NaN  \n",
       "3560     NaN         2724.2  2724.21098  NaN   NaN       NaN  \n",
       "3561     NaN         2736.4  2736.44905  NaN   NaN       NaN  \n",
       "3562     NaN         2824.5  2824.53547  NaN   NaN       NaN  \n",
       "\n",
       "[3563 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GHO</th>\n      <th>PUBLISHSTATE</th>\n      <th>YEAR</th>\n      <th>REGION</th>\n      <th>WORLDBANKINCOMEGROUP</th>\n      <th>COUNTRY</th>\n      <th>Display Value</th>\n      <th>Numeric</th>\n      <th>Low</th>\n      <th>High</th>\n      <th>Comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2009</td>\n      <td>EMR</td>\n      <td>WB_LI</td>\n      <td>AFG</td>\n      <td>143.8</td>\n      <td>143.84962</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2010</td>\n      <td>EMR</td>\n      <td>WB_LI</td>\n      <td>AFG</td>\n      <td>132.3</td>\n      <td>132.27129</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2011</td>\n      <td>EMR</td>\n      <td>WB_LI</td>\n      <td>AFG</td>\n      <td>138.8</td>\n      <td>138.82262</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2012</td>\n      <td>EMR</td>\n      <td>WB_LI</td>\n      <td>AFG</td>\n      <td>144.0</td>\n      <td>143.96532</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2008</td>\n      <td>AFR</td>\n      <td>WB_UMI</td>\n      <td>DZA</td>\n      <td>510.9</td>\n      <td>510.92255</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3558</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2017</td>\n      <td>NaN</td>\n      <td>WB_UMI</td>\n      <td>NaN</td>\n      <td>1013.8</td>\n      <td>1013.75916</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3559</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2008</td>\n      <td>NaN</td>\n      <td>WB_HI</td>\n      <td>NaN</td>\n      <td>2559.5</td>\n      <td>2559.51753</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3560</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2009</td>\n      <td>NaN</td>\n      <td>WB_HI</td>\n      <td>NaN</td>\n      <td>2724.2</td>\n      <td>2724.21098</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3561</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2010</td>\n      <td>NaN</td>\n      <td>WB_HI</td>\n      <td>NaN</td>\n      <td>2736.4</td>\n      <td>2736.44905</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3562</th>\n      <td>GHED_CHE_pc_PPP_SHA2011</td>\n      <td>PUBLISHED</td>\n      <td>2011</td>\n      <td>NaN</td>\n      <td>WB_HI</td>\n      <td>NaN</td>\n      <td>2824.5</td>\n      <td>2824.53547</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3563 rows Ã 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "    test = pd.read_csv(\n",
    "        \"http://apps.who.int/gho/athena/api/GHO/GHED_CHE_pc_PPP_SHA2011.csv\"\n",
    "    )\n",
    "\n",
    "    test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n Categorical variable, still have to develop this section\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     SCALED_OBS_VALUE  RAW_OBS_VALUE\n",
       "0                10.0              2\n",
       "1                10.0              2\n",
       "2                10.0              2\n",
       "3                10.0              2\n",
       "4                 5.0              1\n",
       "..                ...            ...\n",
       "190              10.0              2\n",
       "191              10.0              2\n",
       "192               5.0              1\n",
       "193               5.0              1\n",
       "194               5.0              1\n",
       "\n",
       "[195 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SCALED_OBS_VALUE</th>\n      <th>RAW_OBS_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>10.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>195 rows Ã 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "\n",
    "s135_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-135_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "\n",
    "def dev_normalizer(\n",
    "    cleansed_data,\n",
    "    sql_subset_query_string,\n",
    "    variable_type=\"Continuous variable\",\n",
    "    is_inverted=\"not inverted\",\n",
    "    whisker_factor=1.5,\n",
    "    raw_data_col=\"RAW_OBS_VALUE\",\n",
    "    contains_zeros=True,\n",
    "    maximum_score=10\n",
    "):\n",
    "    \"\"\"Normalize the RAW_OBS_VALUES into indicator scores\n",
    "\n",
    "    TO DO\n",
    "\n",
    "    Parameters:\n",
    "    TO DO\n",
    "    **dimensions (mapping type): Define the present dimension variables as keys\n",
    "    along with the dimension value that is supposed to be taken for the normalization.\n",
    "\n",
    "    \"\"\"\n",
    "    if variable_type != \"Continuous variable\":\n",
    "        # Build conditions array \n",
    "        conditions = []\n",
    "\n",
    "        for value in np.sort(cleansed_data[raw_data_col].unique()):\n",
    "            conditions += [\n",
    "                cleansed_data[raw_data_col]\n",
    "                == value\n",
    "            ]\n",
    "        \n",
    "        # Assign variable for readability purpose\n",
    "        length_unique_values = len(np.sort(cleansed_data[raw_data_col].unique()))\n",
    "\n",
    "        # Build norm values array, where 0 =< norm_values => 10\n",
    "        norm_values = []\n",
    "        for value in range(length_unique_values):\n",
    "            distance = (maximum_score / (length_unique_values - 1))\n",
    "            norm_values +=  [distance * float(value)] \n",
    "\n",
    "        # store normalized scores in SCALED_OBS_VALUE\n",
    "        cleansed_data[\"SCALED_OBS_VALUE\"] = np.select(conditions, norm_values)\n",
    "\n",
    "        return cleansed_data\n",
    "\n",
    "s135_normalized = dev_normalizer(\n",
    "    cleansed_data = s135_cleansed,\n",
    "    sql_subset_query_string = \"somestring\",\n",
    "    variable_type=\"Some string\",\n",
    "    contains_zeros=True\n",
    ")\n",
    "\n",
    "s135_normalized[[\"SCALED_OBS_VALUE\", \"RAW_OBS_VALUE\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Max. working days limited to 6 days per week or less',\n",
       " 'No limit on working days']"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "test_string = \"2 = Max. working days limited to 6 days per week or less, 1 = No limit on working days\"\n",
    "\n",
    "temp_1 = re.split(\",\", test_string)\n",
    "\n",
    "empty_list=[]\n",
    "for element in temp_1:\n",
    "    empty_list += [re.split(\"=\", element)]\n",
    "empty_list\n",
    "\n",
    "raw_values=[]\n",
    "encodings=[]\n",
    "\n",
    "for list in range(len(empty_list)):\n",
    "    raw_values += [empty_list[list][1].rstrip().lstrip()]\n",
    "    encodings += [empty_list[list][0].rstrip().lstrip()]\n",
    "raw_values\n",
    "#encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['2', '3', '1'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "def encode_categorical_variables(\n",
    "    dataframe,\n",
    "    encoding_string,\n",
    "    obs_raw_value=\"OBS_RAW_VALUE\",\n",
    "    sep_character=\",\",\n",
    "    assign_character=\"=\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    \n",
    "    encoding_string(str): String that contains the mapping. Must follow a specific format, which is defined by sep_character and assign_character. With the default values, for example: \"2 = Max. working days limited to 6 days per week or less, 1 = No limit on working days\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Split string into mapping pairs\n",
    "    mapping_pairs = re.split(\n",
    "        sep_character,\n",
    "        encoding_string     \n",
    "    )\n",
    "\n",
    "    # Create nested list with encoded value and original value packed in a sublist\n",
    "    mapping_pairs_listed = []\n",
    "    for pair in mapping_pairs:\n",
    "            mapping_pairs_listed += [re.split(\n",
    "                assign_character,\n",
    "                pair\n",
    "            )]\n",
    "    \n",
    "    # Define conditions\n",
    "    raw_values=[]\n",
    "    encodings=[]\n",
    "    \n",
    "    # Extract raw values and encodings from mapping pairs listed\n",
    "    for mapping_sublist in range(len(mapping_pairs_listed)):\n",
    "            raw_values += [\n",
    "                dataframe[obs_raw_value]\n",
    "                == mapping_pairs_listed[mapping_sublist][1].rstrip().lstrip()]\n",
    "            encodings += [mapping_pairs_listed[mapping_sublist][0].rstrip().lstrip()]\n",
    "\n",
    "    dataframe[obs_raw_value] = np.select(\n",
    "        condlist=raw_values,\n",
    "        choicelist=encodings,\n",
    "        default=\"VALUE WITHOUT MAPPING - PLEASE MAP\"\n",
    "    )\n",
    "\n",
    "    # create attr_encoding_raw_values\n",
    "    dataframe[\"ATTR_ENCODING_LABELS\"] = encoding_string\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "s82_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-82_raw.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "\n",
    "s82_encoded = encode_categorical_variables(\n",
    "    dataframe = s82_raw,\n",
    "    encoding_string = \"3=Larger scale, 2=Limited, 1=None, 0=No data, 0=Don't Know\",\n",
    "    obs_raw_value=\"Display Value\",\n",
    "    sep_character=\",\",\n",
    "    assign_character=\"=\"\n",
    ")\n",
    "\n",
    "s82_encoded[\"Display Value\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data[\"RAW_OBS_VALUE_ENCODED\"] = np.select(conditions, norm_values)"
   ]
  },
  {
   "source": [
    "## integrate query rather than eval() in the function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0  TIME_PERIOD COUNTRY_ISO_3 DIM_AGE_GROUP     DIM_SEX  \\\n",
       "0              0       2016.0           AFG    5-19 YEARS  BOTH_SEXES   \n",
       "17            17       2016.0           ALB    5-19 YEARS  BOTH_SEXES   \n",
       "18            18       2016.0           AND    5-19 YEARS  BOTH_SEXES   \n",
       "27            27       2016.0           DZA    5-19 YEARS  BOTH_SEXES   \n",
       "36            36       2016.0           AGO    5-19 YEARS  BOTH_SEXES   \n",
       "...          ...          ...           ...           ...         ...   \n",
       "1686        1686       2016.0           VEN    5-19 YEARS  BOTH_SEXES   \n",
       "1695        1695       2016.0           VNM    5-19 YEARS  BOTH_SEXES   \n",
       "1704        1704       2016.0           YEM    5-19 YEARS  BOTH_SEXES   \n",
       "1713        1713       2016.0           ZMB    5-19 YEARS  BOTH_SEXES   \n",
       "1722        1722       2016.0           ZWE    5-19 YEARS  BOTH_SEXES   \n",
       "\n",
       "      RAW_OBS_VALUE ATTR_SOURCE_COMMENTS _merge  \\\n",
       "0               9.4                  NaN   both   \n",
       "17             25.0                  NaN   both   \n",
       "18             35.8                  NaN   both   \n",
       "27             31.0                  NaN   both   \n",
       "36             11.0                  NaN   both   \n",
       "...             ...                  ...    ...   \n",
       "1686           34.1                  NaN   both   \n",
       "1695            9.7                  NaN   both   \n",
       "1704           20.0                  NaN   both   \n",
       "1713           12.7                  NaN   both   \n",
       "1722           14.5                  NaN   both   \n",
       "\n",
       "                               INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "0     Older children and teenagers overweight     Marketplace   \n",
       "17    Older children and teenagers overweight     Marketplace   \n",
       "18    Older children and teenagers overweight     Marketplace   \n",
       "27    Older children and teenagers overweight     Marketplace   \n",
       "36    Older children and teenagers overweight     Marketplace   \n",
       "...                                       ...             ...   \n",
       "1686  Older children and teenagers overweight     Marketplace   \n",
       "1695  Older children and teenagers overweight     Marketplace   \n",
       "1704  Older children and teenagers overweight     Marketplace   \n",
       "1713  Older children and teenagers overweight     Marketplace   \n",
       "1722  Older children and teenagers overweight     Marketplace   \n",
       "\n",
       "                INDICATOR_ISSUE INDICATOR_CATEGORY  CRBA_RELEASE_YEAR  \\\n",
       "0     Marketing and Advertising            Outcome               2020   \n",
       "17    Marketing and Advertising            Outcome               2020   \n",
       "18    Marketing and Advertising            Outcome               2020   \n",
       "27    Marketing and Advertising            Outcome               2020   \n",
       "36    Marketing and Advertising            Outcome               2020   \n",
       "...                         ...                ...                ...   \n",
       "1686  Marketing and Advertising            Outcome               2020   \n",
       "1695  Marketing and Advertising            Outcome               2020   \n",
       "1704  Marketing and Advertising            Outcome               2020   \n",
       "1713  Marketing and Advertising            Outcome               2020   \n",
       "1722  Marketing and Advertising            Outcome               2020   \n",
       "\n",
       "       INDICATOR_CODE  \n",
       "0     MP_MA_OC_OLCHTO  \n",
       "17    MP_MA_OC_OLCHTO  \n",
       "18    MP_MA_OC_OLCHTO  \n",
       "27    MP_MA_OC_OLCHTO  \n",
       "36    MP_MA_OC_OLCHTO  \n",
       "...               ...  \n",
       "1686  MP_MA_OC_OLCHTO  \n",
       "1695  MP_MA_OC_OLCHTO  \n",
       "1704  MP_MA_OC_OLCHTO  \n",
       "1713  MP_MA_OC_OLCHTO  \n",
       "1722  MP_MA_OC_OLCHTO  \n",
       "\n",
       "[192 rows x 14 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>TIME_PERIOD</th>\n      <th>COUNTRY_ISO_3</th>\n      <th>DIM_AGE_GROUP</th>\n      <th>DIM_SEX</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_COMMENTS</th>\n      <th>_merge</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>9.4</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>2016.0</td>\n      <td>ALB</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>2016.0</td>\n      <td>AND</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>35.8</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>2016.0</td>\n      <td>DZA</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>31.0</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>2016.0</td>\n      <td>AGO</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1686</th>\n      <td>1686</td>\n      <td>2016.0</td>\n      <td>VEN</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>34.1</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>1695</td>\n      <td>2016.0</td>\n      <td>VNM</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>9.7</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>1704</th>\n      <td>1704</td>\n      <td>2016.0</td>\n      <td>YEM</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>20.0</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>1713</th>\n      <td>1713</td>\n      <td>2016.0</td>\n      <td>ZMB</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>12.7</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n    <tr>\n      <th>1722</th>\n      <td>1722</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>14.5</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n    </tr>\n  </tbody>\n</table>\n<p>192 rows Ã 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "s103_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-103_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "s103_cleansed.query(\"DIM_SEX == 'BOTH_SEXES' & DIM_AGE_GROUP == '5-19 YEARS'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 56.437499999999986 \n See histogram printed below for info. \n\nThe distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 6.8. This value corresponds to country:      Unnamed: 0  TIME_PERIOD COUNTRY_ISO_3 DIM_AGE_GROUP     DIM_SEX  \\\n684         684       2016.0           IND    5-19 YEARS  BOTH_SEXES   \n\n     RAW_OBS_VALUE ATTR_SOURCE_COMMENTS _merge  \\\n684            6.8                  NaN   both   \n\n                              INDICATOR_NAME INDICATOR_INDEX  \\\n684  Older children and teenagers overweight     Marketplace   \n\n               INDICATOR_ISSUE INDICATOR_CATEGORY  CRBA_RELEASE_YEAR  \\\n684  Marketing and Advertising            Outcome               2020   \n\n      INDICATOR_CODE  \n684  MP_MA_OC_OLCHTO   \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Unnamed: 0  TIME_PERIOD COUNTRY_ISO_3 DIM_AGE_GROUP     DIM_SEX  \\\n",
       "0              0       2016.0           AFG    5-19 YEARS  BOTH_SEXES   \n",
       "1              1       2016.0           AFG    5-09 YEARS  BOTH_SEXES   \n",
       "2              2       2016.0           AFG   10-19 YEARS  BOTH_SEXES   \n",
       "3              3       2016.0           AFG    5-19 YEARS      FEMALE   \n",
       "4              4       2016.0           AFG    5-09 YEARS      FEMALE   \n",
       "...          ...          ...           ...           ...         ...   \n",
       "1726        1726       2016.0           ZWE    5-09 YEARS      FEMALE   \n",
       "1727        1727       2016.0           ZWE   10-19 YEARS      FEMALE   \n",
       "1728        1728       2016.0           ZWE    5-19 YEARS        MALE   \n",
       "1729        1729       2016.0           ZWE    5-09 YEARS        MALE   \n",
       "1730        1730       2016.0           ZWE   10-19 YEARS        MALE   \n",
       "\n",
       "      RAW_OBS_VALUE ATTR_SOURCE_COMMENTS _merge  \\\n",
       "0               9.4                  NaN   both   \n",
       "1              10.6                  NaN   both   \n",
       "2               8.8                  NaN   both   \n",
       "3               9.9                  NaN   both   \n",
       "4              10.7                  NaN   both   \n",
       "...             ...                  ...    ...   \n",
       "1726           23.6                  NaN   both   \n",
       "1727           21.7                  NaN   both   \n",
       "1728            6.6                  NaN   both   \n",
       "1729            7.5                  NaN   both   \n",
       "1730            6.1                  NaN   both   \n",
       "\n",
       "                               INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "0     Older children and teenagers overweight     Marketplace   \n",
       "1     Older children and teenagers overweight     Marketplace   \n",
       "2     Older children and teenagers overweight     Marketplace   \n",
       "3     Older children and teenagers overweight     Marketplace   \n",
       "4     Older children and teenagers overweight     Marketplace   \n",
       "...                                       ...             ...   \n",
       "1726  Older children and teenagers overweight     Marketplace   \n",
       "1727  Older children and teenagers overweight     Marketplace   \n",
       "1728  Older children and teenagers overweight     Marketplace   \n",
       "1729  Older children and teenagers overweight     Marketplace   \n",
       "1730  Older children and teenagers overweight     Marketplace   \n",
       "\n",
       "                INDICATOR_ISSUE INDICATOR_CATEGORY  CRBA_RELEASE_YEAR  \\\n",
       "0     Marketing and Advertising            Outcome               2020   \n",
       "1     Marketing and Advertising            Outcome               2020   \n",
       "2     Marketing and Advertising            Outcome               2020   \n",
       "3     Marketing and Advertising            Outcome               2020   \n",
       "4     Marketing and Advertising            Outcome               2020   \n",
       "...                         ...                ...                ...   \n",
       "1726  Marketing and Advertising            Outcome               2020   \n",
       "1727  Marketing and Advertising            Outcome               2020   \n",
       "1728  Marketing and Advertising            Outcome               2020   \n",
       "1729  Marketing and Advertising            Outcome               2020   \n",
       "1730  Marketing and Advertising            Outcome               2020   \n",
       "\n",
       "       INDICATOR_CODE  SCALED_OBS_VALUE OBS_STATUS  \n",
       "0     MP_MA_OC_OLCHTO              0.45          O  \n",
       "1     MP_MA_OC_OLCHTO               NaN        nan  \n",
       "2     MP_MA_OC_OLCHTO               NaN        nan  \n",
       "3     MP_MA_OC_OLCHTO               NaN        nan  \n",
       "4     MP_MA_OC_OLCHTO               NaN        nan  \n",
       "...               ...               ...        ...  \n",
       "1726  MP_MA_OC_OLCHTO               NaN        nan  \n",
       "1727  MP_MA_OC_OLCHTO               NaN        nan  \n",
       "1728  MP_MA_OC_OLCHTO               NaN        nan  \n",
       "1729  MP_MA_OC_OLCHTO               NaN        nan  \n",
       "1730  MP_MA_OC_OLCHTO               NaN        nan  \n",
       "\n",
       "[1731 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>TIME_PERIOD</th>\n      <th>COUNTRY_ISO_3</th>\n      <th>DIM_AGE_GROUP</th>\n      <th>DIM_SEX</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_COMMENTS</th>\n      <th>_merge</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n      <th>SCALED_OBS_VALUE</th>\n      <th>OBS_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>5-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>9.4</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>0.45</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>5-09 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>10.6</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>10-19 YEARS</td>\n      <td>BOTH_SEXES</td>\n      <td>8.8</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>5-19 YEARS</td>\n      <td>FEMALE</td>\n      <td>9.9</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2016.0</td>\n      <td>AFG</td>\n      <td>5-09 YEARS</td>\n      <td>FEMALE</td>\n      <td>10.7</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1726</th>\n      <td>1726</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>5-09 YEARS</td>\n      <td>FEMALE</td>\n      <td>23.6</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>1727</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>10-19 YEARS</td>\n      <td>FEMALE</td>\n      <td>21.7</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1728</th>\n      <td>1728</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>5-19 YEARS</td>\n      <td>MALE</td>\n      <td>6.6</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1729</th>\n      <td>1729</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>5-09 YEARS</td>\n      <td>MALE</td>\n      <td>7.5</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n    <tr>\n      <th>1730</th>\n      <td>1730</td>\n      <td>2016.0</td>\n      <td>ZWE</td>\n      <td>10-19 YEARS</td>\n      <td>MALE</td>\n      <td>6.1</td>\n      <td>NaN</td>\n      <td>both</td>\n      <td>Older children and teenagers overweight</td>\n      <td>Marketplace</td>\n      <td>Marketing and Advertising</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>MP_MA_OC_OLCHTO</td>\n      <td>NaN</td>\n      <td>nan</td>\n    </tr>\n  </tbody>\n</table>\n<p>1731 rows Ã 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "def normalizer(\n",
    "    cleansed_data,\n",
    "    sql_subset_query_string,\n",
    "    variable_type=\"Continuous variable\",\n",
    "    is_inverted=\"not inverted\",\n",
    "    whisker_factor=1.5,\n",
    "    raw_data_col=\"RAW_OBS_VALUE\",\n",
    "):\n",
    "    \"\"\"Normalize the RAW_OBS_VALUES into indicator scores\n",
    "\n",
    "    TO DO\n",
    "\n",
    "    Parameters:\n",
    "    TO DO\n",
    "    **dimensions (mapping type): Define the present dimension variables as keys\n",
    "    along with the dimension value that is supposed to be taken for the normalization.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the dimension subgroup for which normalization is done:\n",
    "    # normalization_subset = cleansed_data\n",
    "\n",
    "    # Empty string which will be filled with subset conditions\n",
    "    # subset = \"\"\n",
    "\n",
    "    # Run loop to get dimensions vaues specified in **dimensions\n",
    "    # for key in dimensions:\n",
    "    #    subset += \"(cleansed_data['{}'] == '{}')&\".format(key, dimensions[key])\n",
    "\n",
    "    # Get rid of the \"&-sign\" at the end\n",
    "    # subset = subset.rstrip(\"& \")\n",
    "\n",
    "    # Subset the actual dataframe\n",
    "    #print(sql_subset_query_string)\n",
    "    cleansed_data_subset = cleansed_data.query(sql_subset_query_string)\n",
    "    #print(cleansed_data.query('{}'.format(sql_subset_query_string)))\n",
    "\n",
    "    if variable_type != \"Continuous variable\":\n",
    "        print(\"\\n Categorical variable, still have to develop this section\")\n",
    "\n",
    "    elif variable_type == \"Continuous variable\":\n",
    "\n",
    "        # Determine basic descriptive statistics of the distribution that are required for the normalization\n",
    "        min_val = np.nanmin(cleansed_data_subset[raw_data_col].astype(\"float\"))\n",
    "        max_val = np.nanmax(cleansed_data_subset[raw_data_col].astype(\"float\"))\n",
    "        q1 = cleansed_data_subset[raw_data_col].astype(\"float\").quantile(q=0.25)\n",
    "        q2 = cleansed_data_subset[raw_data_col].astype(\"float\").quantile(q=0.50)\n",
    "        q3 = cleansed_data_subset[raw_data_col].astype(\"float\").quantile(q=0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Define what max value to use for the normalization\n",
    "        if max_val > q3 + whisker_factor * iqr:\n",
    "            max_to_use = q3 + whisker_factor * iqr\n",
    "            print(\n",
    "                \"The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "                    whisker_factor, max_to_use\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            max_to_use = max_val\n",
    "            print(\n",
    "                \"The distribution of the raw data for this subgroup does not contain outliers on the upper end. It is also not too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "                    max_to_use,\n",
    "                    cleansed_data_subset[\n",
    "                        cleansed_data_subset[raw_data_col].astype(\"float\") == max_val\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Define what min value to use for the normalization\n",
    "        if min_val < q1 - whisker_factor * iqr:\n",
    "            min_to_use = q1 - whisker_factor * iqr\n",
    "            print(\n",
    "                \"The distribution of the raw data values for this subgroup contains outliers or is too skewed on the lower end. The minimum value to be used for the normalisation is 1st quartile or distribution - {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "                    whisker_factor, min_to_use\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            min_to_use = min_val\n",
    "            print(\n",
    "                \"The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "                    min_to_use,\n",
    "                    cleansed_data_subset[\n",
    "                        cleansed_data_subset[raw_data_col].astype(\"float\") == min_val\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        # If there are outliers or a skewed distribution, print the distribution for the user.\n",
    "        if (min_val < q1 - whisker_factor * iqr) or (\n",
    "            max_val > q3 + whisker_factor * iqr\n",
    "        ):\n",
    "            print(\n",
    "                \"\\n This is the distribution of the raw data of the indicator.\"\n",
    "            )\n",
    "            print(\n",
    "                pd.to_numeric(s55_cleansed[\"RAW_OBS_VALUE\"]).hist(\n",
    "                    bins=30\n",
    "                )\n",
    "            )\"\"\"\n",
    "\n",
    "        # Define the value range that is used for the scaling (normalization)\n",
    "        tot_range = max_val - min_val\n",
    "\n",
    "        # Compute the normalized value of the raw data in the column \"SCALED\"\n",
    "        # Distinguish between indicators, whose value must be inverted\n",
    "        if is_inverted == \"inverted\":\n",
    "            cleansed_data_subset[\"SCALED_OBS_VALUE\"] = round(\n",
    "                10\n",
    "                - 10\n",
    "                * (cleansed_data_subset[raw_data_col].astype(\"float\") - min_val)\n",
    "                / tot_range,\n",
    "                2,\n",
    "            )\n",
    "        else:\n",
    "            cleansed_data_subset[\"SCALED_OBS_VALUE\"] = round(\n",
    "                10\n",
    "                * (cleansed_data_subset[raw_data_col].astype(\"float\") - min_val)\n",
    "                / tot_range,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "    # join normalized data to original dataframe\n",
    "    cleansed_data = cleansed_data.merge(right=cleansed_data_subset, how=\"outer\")\n",
    "\n",
    "    # cleansed_data = pd.concat([cleansed_data, cleansed_data_subset], axis=1, copy = False)\n",
    "\n",
    "    # insert column to indicate OBS status\n",
    "    result = cleansed_data.assign(\n",
    "        OBS_STATUS=np.where(cleansed_data[\"SCALED_OBS_VALUE\"].isnull(), np.nan, \"O\")\n",
    "    )\n",
    "\n",
    "    # Return result\n",
    "    return result\n",
    "\n",
    "s103_normalized = normalizer(\n",
    "    cleansed_data = s103_cleansed,\n",
    "    sql_subset_query_string=\"DIM_SEX=='BOTH_SEXES' & DIM_AGE_GROUP=='5-19 YEARS'\"\n",
    ")\n",
    "\n",
    "s103_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0                                 GHO PUBLISHSTATE       YEAR  \\\n",
       "0             0  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "1             1  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "2             2  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "3             3  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "4             4  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "..          ...                                 ...          ...        ...   \n",
       "127         127  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "128         128  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "129         129  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "130         130  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "131         131  VIOLENCE_EXTENTIMP_CHILDPROTECTION    PUBLISHED  2012-2014   \n",
       "\n",
       "    REGION COUNTRY Display Value  Numeric  Low  High  Comments  \n",
       "0      EMR     OMN       Limited      NaN  NaN   NaN       NaN  \n",
       "1      AMR     PER  Larger scale      NaN  NaN   NaN       NaN  \n",
       "2      EUR     PRT  Larger scale      NaN  NaN   NaN       NaN  \n",
       "3      EUR     ROU  Larger scale      NaN  NaN   NaN       NaN  \n",
       "4      WPR     WSM  Larger scale      NaN  NaN   NaN       NaN  \n",
       "..     ...     ...           ...      ...  ...   ...       ...  \n",
       "127    AFR     BDI       Limited      NaN  NaN   NaN       NaN  \n",
       "128    AFR     BWA       Limited      NaN  NaN   NaN       NaN  \n",
       "129    AMR     BOL       Limited      NaN  NaN   NaN       NaN  \n",
       "130    EUR     BLR  Larger scale      NaN  NaN   NaN       NaN  \n",
       "131    AFR     ZWE       Limited      NaN  NaN   NaN       NaN  \n",
       "\n",
       "[132 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>GHO</th>\n      <th>PUBLISHSTATE</th>\n      <th>YEAR</th>\n      <th>REGION</th>\n      <th>COUNTRY</th>\n      <th>Display Value</th>\n      <th>Numeric</th>\n      <th>Low</th>\n      <th>High</th>\n      <th>Comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>EMR</td>\n      <td>OMN</td>\n      <td>Limited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>AMR</td>\n      <td>PER</td>\n      <td>Larger scale</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>EUR</td>\n      <td>PRT</td>\n      <td>Larger scale</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>EUR</td>\n      <td>ROU</td>\n      <td>Larger scale</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>WPR</td>\n      <td>WSM</td>\n      <td>Larger scale</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>127</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>AFR</td>\n      <td>BDI</td>\n      <td>Limited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>128</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>AFR</td>\n      <td>BWA</td>\n      <td>Limited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>129</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>AMR</td>\n      <td>BOL</td>\n      <td>Limited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>130</th>\n      <td>130</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>EUR</td>\n      <td>BLR</td>\n      <td>Larger scale</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>131</td>\n      <td>VIOLENCE_EXTENTIMP_CHILDPROTECTION</td>\n      <td>PUBLISHED</td>\n      <td>2012-2014</td>\n      <td>AFR</td>\n      <td>ZWE</td>\n      <td>Limited</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>132 rows Ã 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "s82_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-82_raw.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "if \"Display Value\" in s82_raw.columns:\n",
    "    s82_raw[\"Display Value\"] = s82_raw[\"Display Value\"].astype(str)\n",
    "    s82_raw[\"Display Value\"] = s82_raw[\"Display Value\"].apply(\n",
    "            lambda x: re.sub(\" \\[.*\\]\", \"\", x)\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "s82_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s82_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "s82_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s88_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-88_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "norm_values = [\"No\", \"Yes\", \"No data\"]\n",
    "contains_zeros = False\n",
    "\n",
    "conditions = [\n",
    "    (s88_cleansed[\"RAW_OBS_VALUE\"] == index)\n",
    "    for index, value in enumerate(norm_values, start=0 if contains_zeros else 1)\n",
    "]\n",
    "\n",
    "# s88_cleansed[\"RAW_OBS_VALUE\"] == index\n",
    "# print(index)\n",
    "\n",
    "# conditions.size_of\n",
    "\n",
    "conditions = \n",
    "\n",
    "--> Get unique values (not necessary, just do manually and then insert it)\n",
    "--> Then do a mapping (\"No\" = 0, \"Yes\" = 1) --> This must be indicator specific --> CLEANSER, INFO FOR THAT IN THE data dictionary --> Create two columns \"RAW_VALUES\" and \"ENCODEDE VALUES\"\n",
    "--> Then convert these into scores --> SCLAER (Global and )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'enumerate' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-bb50a0c828e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#conditions.size_of()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# conditions[1].sum()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontains_zeros\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'enumerate' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# dir(conditions)\n",
    "#conditions.size_of()\n",
    "# conditions[1].sum()\n",
    "enumerate(norm_values, start=0 if contains_zeros else 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nconditions = [\\n    (cleansed_data[indicator_raw_value] == index)\\n    for index, value in enumerate(norm_values, start=0 if contains_zeros else 1)\\n]\\n\\n# create a new column and assign values to it using our lists\\ncleansed_data[\"SCALED\"] = np.select(conditions, norm_values)\\n\\n# Right join country list\\ncleansed_data_full = cleansed_data.merge(\\n    right=crba_final_country_list,\\n    how=\"right\",\\n    left_on=cleansed_df_iso2_col,\\n    right_on=crba_final_country_list_iso_col,\\n    indicator=\"RJ_CRBA_FULL_LIST\",\\n)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "conditions = [\n",
    "    (cleansed_data[indicator_raw_value] == index)\n",
    "    for index, value in enumerate(norm_values, start=0 if contains_zeros else 1)\n",
    "]\n",
    "\n",
    "# create a new column and assign values to it using our lists\n",
    "cleansed_data[\"SCALED\"] = np.select(conditions, norm_values)\n",
    "\n",
    "# Right join country list\n",
    "cleansed_data_full = cleansed_data.merge(\n",
    "    right=crba_final_country_list,\n",
    "    how=\"right\",\n",
    "    left_on=cleansed_df_iso2_col,\n",
    "    right_on=crba_final_country_list_iso_col,\n",
    "    indicator=\"RJ_CRBA_FULL_LIST\",\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a Real\nb Python\nc Is\nd Great\ne !\n"
     ]
    }
   ],
   "source": [
    "def test_func(**kwargs):\n",
    "    for key in kwargs:\n",
    "        print(key, kwargs[key])\n",
    "\n",
    "test_func(a=\"Real\", b=\"Python\", c=\"Is\", d=\"Great\", e=\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s55_cleansed.SCALED_OBS_VALUE.describe()\n",
    "\n",
    "# s55_cleansed[s55_cleansed.SCALED_OBS_VALUE > 9.2][[\"COUNTRY_ISO_2\", \"RAW_OBS_VALUE\", \"SCALED_OBS_VALUE\"]]"
   ]
  },
  {
   "source": [
    "### Develop normalier function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.8 [18.1-29.9]\n3\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    1692.000000\n",
       "mean       24.318617\n",
       "std        11.999569\n",
       "min         4.300000\n",
       "25%        14.800000\n",
       "50%        24.800000\n",
       "75%        31.225000\n",
       "max        70.400000\n",
       "Name: RAW_OBS_VALUE, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "# # # # # # # # # \n",
    "\n",
    "s103_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-103_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "print(s103_cleansed[\"RAW_OBS_VALUE\"][10])\n",
    "print(s103_cleansed[\"RAW_OBS_VALUE\"].isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# print(s103_cleansed[\"RAW_OBS_VALUE\"].dtypes== object) \n",
    "\n",
    "if s103_cleansed[\"RAW_OBS_VALUE\"].dtypes== object:\n",
    "    #s103_cleansed = s103_cleansed[s103_cleansed[\"RAW_OBS_VALUE\"].dropna()]\n",
    "    s103_cleansed[\"RAW_OBS_VALUE\"] = s103_cleansed[\"RAW_OBS_VALUE\"].astype(str)\n",
    "    s103_cleansed[\"RAW_OBS_VALUE\"] = pd.to_numeric(s103_cleansed[\"RAW_OBS_VALUE\"].apply(\n",
    "          lambda x: re.sub(\n",
    "                \"No data\", \"\", re.sub(\n",
    "                         \" \\[.*\\]\", '', x\n",
    "                    ))),\n",
    "            errors = \"coerce\"\n",
    "    )  \n",
    "\n",
    "    # s103_cleansed = s103_cleansed[\"RAW_OBS_VALUE\"].apply(\n",
    "    #      lambda x: re.sub(\n",
    "    #         \" \\[.*\\]\", \"\", re.sub(\n",
    "    #            \"No data\", None, x))) \n",
    "\n",
    "s103_cleansed[\"RAW_OBS_VALUE\"].describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-6e04ca9c2250>, line 170)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-82-6e04ca9c2250>\"\u001b[0;36m, line \u001b[0;32m170\u001b[0m\n\u001b[0;31m    dimensions = [DIM_SEX = \"BOTH_SEXES\",\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "s55_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-55_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "def normalizer(\n",
    "    cleansed_data,\n",
    "    cat_var = False,\n",
    "    inverted = False,\n",
    "    whisker_factor = 1.5,\n",
    "    raw_data_col = \"RAW_OBS_VALUE\",\n",
    "    **dimensions\n",
    "):\n",
    "    \"\"\"Normalize the RAW_OBS_VALUES into indicator scores\n",
    "\n",
    "    TO DO\n",
    "\n",
    "    Parameters: \n",
    "    TO DO\n",
    "    **dimensions (mapping type): Define the present dimension variables as keys\n",
    "    along with the dimension value that is supposed to be taken for the normalization.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the dimension subgroup for which normalization is done:\n",
    "    # normalization_subset = cleansed_data\n",
    "\n",
    "    # Empty string which will be filled with subset conditions\n",
    "    subset = \"\"\n",
    "\n",
    "    # Run loop to get dimensions vaues specified in **dimensions\n",
    "    for key in dimensions:\n",
    "        subset += \"(cleansed_data['{}'] == '{}')&\".format(\n",
    "            key,\n",
    "            dimensions[key]\n",
    "        )\n",
    "    \n",
    "    # Get rid of the \"&-sign\" at the end\n",
    "    subset = subset.rstrip(\"& \")\n",
    "\n",
    "    # Subset the actual dataframe\n",
    "    cleansed_data_subset = cleansed_data[eval(subset)]\n",
    "\n",
    "    if cat_var == False: \n",
    "        # Determine basic descriptive statistics of the distribution that are required for the normalization\n",
    "        min_val = np.nanmin(\n",
    "            cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "        )\n",
    "        max_val = np.nanmax(\n",
    "            cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "        )\n",
    "        q1 = (\n",
    "            cleansed_data_subset[raw_data_col]\n",
    "            .astype(\"float\")\n",
    "            .quantile(q=0.25)\n",
    "        )\n",
    "        q2 = (\n",
    "            cleansed_data_subset[raw_data_col]\n",
    "            .astype(\"float\")\n",
    "            .quantile(q=0.50)\n",
    "        )\n",
    "        q3 = (\n",
    "            cleansed_data_subset[raw_data_col]\n",
    "            .astype(\"float\")\n",
    "            .quantile(q=0.75)\n",
    "        )\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Define what max value to use for the normalization\n",
    "        if max_val > q3 + whisker_factor * iqr:\n",
    "            max_to_use = q3 + whisker_factor * iqr\n",
    "            print(\n",
    "                \"The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "                    whisker_factor, max_to_use\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            max_to_use = max_val\n",
    "            print(\n",
    "                \"The distribution of the raw data for this subgroup does not contain outliers on the upper end. It is also not too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "                    max_to_use,\n",
    "                    cleansed_data_subset[\n",
    "                        cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "                        == max_val\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Define what min value to use for the normalization\n",
    "        if min_val < q1 - whisker_factor * iqr:\n",
    "            min_to_use = q1 - whisker_factor * iqr\n",
    "            print(\n",
    "                \"The distribution of the raw data values for this subgroup contains outliers or is too skewed on the lower end. The minimum value to be used for the normalisation is 1st quartile or distribution - {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "                    whisker_factor, min_to_use\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            min_to_use = min_val\n",
    "            print(\n",
    "                \"The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "                    min_to_use,\n",
    "                    cleansed_data_subset[\n",
    "                        cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "                        == min_val\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        \"\"\"\n",
    "        # If there are outliers or a skewed distribution, print the distribution for the user.\n",
    "        if (min_val < q1 - whisker_factor * iqr) or (\n",
    "            max_val > q3 + whisker_factor * iqr\n",
    "        ):\n",
    "            print(\n",
    "                \"\\n This is the distribution of the raw data of the indicator.\"\n",
    "            )\n",
    "            print(\n",
    "                pd.to_numeric(s55_cleansed[\"RAW_OBS_VALUE\"]).hist(\n",
    "                    bins=30\n",
    "                )\n",
    "            )\"\"\"\n",
    "\n",
    "        # Define the value range that is used for the scaling (normalization)\n",
    "        tot_range = max_val - min_val\n",
    "\n",
    "        # Compute the normalized value of the raw data in the column \"SCALED\"\n",
    "        # Distinguish between indicators, whose value must be inverted\n",
    "        if inverted == True:\n",
    "            cleansed_data_subset[\"SCALED_OBS_VALUE\"] = round(\n",
    "                10\n",
    "                - 10\n",
    "                * (\n",
    "                    cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "                    - min_val\n",
    "                )\n",
    "                / tot_range,\n",
    "                2,\n",
    "            )\n",
    "        else:\n",
    "            cleansed_data_subset[\"SCALED_OBS_VALUE\"] = round(\n",
    "                10\n",
    "                * (\n",
    "                    cleansed_data_subset[raw_data_col].astype(\"float\")\n",
    "                    - min_val\n",
    "                )\n",
    "                / tot_range,\n",
    "                2,\n",
    "            )\n",
    "    \n",
    "    # join normalized data to original dataframe\n",
    "    cleansed_data = cleansed_data.merge(\n",
    "        right=cleansed_data_subset,\n",
    "        how=\"outer\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    # cleansed_data = pd.concat([cleansed_data, cleansed_data_subset], axis=1, copy = False)\n",
    "\n",
    "    # insert column to indicate OBS status\n",
    "    result = cleansed_data.assign(\n",
    "        OBS_STATUS=np.where(\n",
    "            cleansed_data[\"SCALED_OBS_VALUE\"].isnull(), np.nan, \"O\"\n",
    "        ))\n",
    "\n",
    "    # Return result\n",
    "    return result\n",
    "\n",
    "s55_normalized = normalizer(\n",
    "    cleansed_data=s55_cleansed,\n",
    "    DIM_SEX = \"BOTH_SEXES\",\n",
    "    DIM_EDU_LEVEL = \"LOWER SECONDARY EDUCATION\",\n",
    "    DIM_AGE = \"SCHOOL_AGE_POPULATION\"\n",
    ")\n",
    "\n",
    "print(s55_cleansed.shape)\n",
    "print(s55_normalized.shape)\n",
    "print(s55_normalized.columns)\n",
    "s55_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 32.41972750000001 \n See histogram printed below for info. \n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n\\n# iv) Append the subset including its scaled value to the final returned dataframe\\n# Right join to have all countries from the final crba master list\\n# cleansed_data_subset_rj = cleansed_data_subset.merge(\\n#     right=crba_final_country_list,\\n#     how=\"right\",\\n#    left_on=cleansed_df_iso2_col,\\n#    right_on=crba_final_country_list_iso_col,\\n#    indicator=\"RJ_CRBA_FULL_LIST\",\\n#)\\n\\n# Append the values\\n# cleansed_data_full = cleansed_data_full.append(cleansed_data_subset_rj)\\n\\n\\n# For debugging, include\\nprint(\\n    \"\\n The shape of the dataframe should be 195 x X. It is:  {} \\n \".format(\\n        cleansed_data_subset_rj.shape\\n    )\\n)\\n\\n\\nexcept:\\nprint(\"Dataframe is empty. There are no values to append.\")\\n\\n# Log: print information that this loop run is terminated\\nprint(\" \\n This is the end of loop #{}. \\n - \\n \".format(j + 1))\\n\\n# Sanity Check: The resulting dataframe should always have 195 rows. NB: if you put the line of code before the above \"Append the values\" bit, Python throws and error\\nassert (\\npd.to_numeric(cleansed_data_full.shape[0]) % 195 == 0\\n), \"Number of rows should be a multiple of 195, but it is not. Check if all columns which should be part of the group by statement are listed\"\\nprint(\\n\"The number of rows of the final dataframe (before the conversion from wide to long format is) is divisible by 195. It is: {}\".format(\\ncleansed_data_full.shape\\n)\\n)\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "s55_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-55_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "s55_cleansed_scaler = s55_cleansed[(s55_cleansed.DIM_EDU_LEVEL == \"LOWER SECONDARY EDUCATION\") &\n",
    "    (s55_cleansed.DIM_AGE == \"SCHOOL_AGE_POPULATION\") &\n",
    "    (s55_cleansed.DIM_SEX == \"BOTH_SEXES\")]\n",
    "\n",
    "whisker_factor = 1.5\n",
    "inverted = True\n",
    "numeric \n",
    "\n",
    "# iii) Determine basic descriptive statistics of the distribution that are required for the normalization\n",
    "min_val = np.nanmin(\n",
    "    s55_cleansed[\"RAW_OBS_VALUE\"].astype(\"float\")\n",
    ")\n",
    "max_val = np.nanmax(\n",
    "    s55_cleansed[\"RAW_OBS_VALUE\"].astype(\"float\")\n",
    ")\n",
    "q1 = (\n",
    "    s55_cleansed[\"RAW_OBS_VALUE\"]\n",
    "    .astype(\"float\")\n",
    "    .quantile(q=0.25)\n",
    ")\n",
    "q2 = (\n",
    "    s55_cleansed[\"RAW_OBS_VALUE\"]\n",
    "    .astype(\"float\")\n",
    "    .quantile(q=0.50)\n",
    ")\n",
    "q3 = (\n",
    "    s55_cleansed[\"RAW_OBS_VALUE\"]\n",
    "    .astype(\"float\")\n",
    "    .quantile(q=0.75)\n",
    ")\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Define what max value to use for the normalization\n",
    "if max_val > q3 + whisker_factor * iqr:\n",
    "    max_to_use = q3 + whisker_factor * iqr\n",
    "    print(\n",
    "        \"The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "            whisker_factor, max_to_use\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    max_to_use = max_val\n",
    "    \"\"\"\n",
    "    print(\n",
    "        \"The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "            max_to_use,\n",
    "            s55_cleansed[\n",
    "                s55_cleansed[\"RAW_OBS_VALUE\"].astype(\"float\")\n",
    "                == max_val\n",
    "            ].COUNTRY_NAME,\n",
    "        )\n",
    "    )\"\"\"\n",
    "\n",
    "# Define what min value to use for the normalization\n",
    "if min_val < q1 - whisker_factor * iqr:\n",
    "    min_to_use = q1 - whisker_factor * iqr\n",
    "    print(\n",
    "        \"The distribution of the raw data values for this subgroup contains outliers or is too skewed on the lower end. The minimum value to be used for the normalisation is 1st quartile or distribution - {} * IQR. It is: {} \\n See histogram printed below for info. \\n\".format(\n",
    "            whisker_factor, min_to_use\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    min_to_use = min_val\n",
    "    \"\"\"\n",
    "    print(\n",
    "        \"The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is {}. This value corresponds to country: {} \\n\".format(\n",
    "            min_to_use,\n",
    "            cleansed_data[\n",
    "                cleansed_data[indicator_raw_value].astype(\"float\")\n",
    "                == min_val\n",
    "            ].COUNTRY_NAME,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# If there are outliers or a skewed distribution, print the distribution for the user.\n",
    "if (min_val < q1 - whisker_factor * iqr) or (\n",
    "    max_val > q3 + whisker_factor * iqr\n",
    "):\n",
    "    print(\n",
    "        \"\\n This is the distribution of the raw data of the indicator.\"\n",
    "    )\n",
    "    print(\n",
    "        pd.to_numeric(s55_cleansed[\"RAW_OBS_VALUE\"]).hist(\n",
    "            bins=30\n",
    "        )\n",
    "    )\"\"\"\n",
    "\n",
    "# Define the value range that is used for the scaling (normalization)\n",
    "tot_range = max_val - min_val\n",
    "\n",
    "# Compute the normalized value of the raw data in the column \"SCALED\"\n",
    "# Distinguish between indicators, whose value must be inverted\n",
    "if inverted == True:\n",
    "    s55_cleansed[\"SCALED_OBS_VALUE\"] = round(\n",
    "        10\n",
    "        - 10\n",
    "        * (\n",
    "            s55_cleansed[\"RAW_OBS_VALUE\"].astype(\"float\")\n",
    "            - min_val\n",
    "        )\n",
    "        / tot_range,\n",
    "        2,\n",
    "    )\n",
    "else:\n",
    "    s55_cleansed[\"SCALED_OBS_VALUE\"] = round(\n",
    "        10\n",
    "        * (\n",
    "            s55_cleansed[\"RAW_OBS_VALUE\"].astype(\"float\")\n",
    "            - min_val\n",
    "        )\n",
    "        / tot_range,\n",
    "        2,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# iv) Append the subset including its scaled value to the final returned dataframe\n",
    "# Right join to have all countries from the final crba master list\n",
    "# cleansed_data_subset_rj = cleansed_data_subset.merge(\n",
    "#     right=crba_final_country_list,\n",
    "#     how=\"right\",\n",
    "#    left_on=cleansed_df_iso2_col,\n",
    "#    right_on=crba_final_country_list_iso_col,\n",
    "#    indicator=\"RJ_CRBA_FULL_LIST\",\n",
    "#)\n",
    "\n",
    "# Append the values\n",
    "# cleansed_data_full = cleansed_data_full.append(cleansed_data_subset_rj)\n",
    "\n",
    "\n",
    "# For debugging, include\n",
    "print(\n",
    "    \"\\n The shape of the dataframe should be 195 x X. It is:  {} \\n \".format(\n",
    "        cleansed_data_subset_rj.shape\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "except:\n",
    "print(\"Dataframe is empty. There are no values to append.\")\n",
    "\n",
    "# Log: print information that this loop run is terminated\n",
    "print(\" \\n This is the end of loop #{}. \\n - \\n \".format(j + 1))\n",
    "\n",
    "# Sanity Check: The resulting dataframe should always have 195 rows. NB: if you put the line of code before the above \"Append the values\" bit, Python throws and error\n",
    "assert (\n",
    "pd.to_numeric(cleansed_data_full.shape[0]) % 195 == 0\n",
    "), \"Number of rows should be a multiple of 195, but it is not. Check if all columns which should be part of the group by statement are listed\"\n",
    "print(\n",
    "\"The number of rows of the final dataframe (before the conversion from wide to long format is) is divisible by 195. It is: {}\".format(\n",
    "cleansed_data_full.shape\n",
    ")\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0 ATTR_UNIT_MEASURE              DIM_EDU_LEVEL     DIM_SEX  \\\n",
       "1             1                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "7             7                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "10           10                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "11           11                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "14           14                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "..          ...               ...                        ...         ...   \n",
       "365         365                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "366         366                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "367         367                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "368         368                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "372         372                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "\n",
       "                   DIM_AGE COUNTRY_ISO_2  TIME_PERIOD  RAW_OBS_VALUE  \\\n",
       "1    SCHOOL_AGE_POPULATION            AL       2018.0        3.05680   \n",
       "7    SCHOOL_AGE_POPULATION            AG       2018.0        1.43781   \n",
       "10   SCHOOL_AGE_POPULATION            AR       2017.0        0.00779   \n",
       "11   SCHOOL_AGE_POPULATION            AM       2018.0        8.21479   \n",
       "14   SCHOOL_AGE_POPULATION            AU       2017.0        1.88277   \n",
       "..                     ...           ...          ...            ...   \n",
       "365  SCHOOL_AGE_POPULATION            GB       2017.0        0.12779   \n",
       "366  SCHOOL_AGE_POPULATION            US       2017.0        0.22621   \n",
       "367  SCHOOL_AGE_POPULATION            UY       2017.0        0.26134   \n",
       "368  SCHOOL_AGE_POPULATION            UZ       2018.0        3.66859   \n",
       "372  SCHOOL_AGE_POPULATION            VE       2017.0       14.07770   \n",
       "\n",
       "    ATTR_SOURCE_OBS_STATUS _merge           INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "1                        A   both  Freedom of association.       Workplace   \n",
       "7                        A   both  Freedom of association.       Workplace   \n",
       "10                       A   both  Freedom of association.       Workplace   \n",
       "11                       A   both  Freedom of association.       Workplace   \n",
       "14                       A   both  Freedom of association.       Workplace   \n",
       "..                     ...    ...                      ...             ...   \n",
       "365                      A   both  Freedom of association.       Workplace   \n",
       "366                      E   both  Freedom of association.       Workplace   \n",
       "367                      A   both  Freedom of association.       Workplace   \n",
       "368                      E   both  Freedom of association.       Workplace   \n",
       "372                      A   both  Freedom of association.       Workplace   \n",
       "\n",
       "               INDICATOR_ISSUE INDICATOR_CATEGORY  CRBA_RELEASE_YEAR  \\\n",
       "1    Decent working conditions            Outcome               2020   \n",
       "7    Decent working conditions            Outcome               2020   \n",
       "10   Decent working conditions            Outcome               2020   \n",
       "11   Decent working conditions            Outcome               2020   \n",
       "14   Decent working conditions            Outcome               2020   \n",
       "..                         ...                ...                ...   \n",
       "365  Decent working conditions            Outcome               2020   \n",
       "366  Decent working conditions            Outcome               2020   \n",
       "367  Decent working conditions            Outcome               2020   \n",
       "368  Decent working conditions            Outcome               2020   \n",
       "372  Decent working conditions            Outcome               2020   \n",
       "\n",
       "      INDICATOR_CODE  SCALED_OBS_VALUE  \n",
       "1    WP_DW_OC_FREASS              9.53  \n",
       "7    WP_DW_OC_FREASS              9.78  \n",
       "10   WP_DW_OC_FREASS             10.00  \n",
       "11   WP_DW_OC_FREASS              8.74  \n",
       "14   WP_DW_OC_FREASS              9.71  \n",
       "..               ...               ...  \n",
       "365  WP_DW_OC_FREASS              9.98  \n",
       "366  WP_DW_OC_FREASS              9.97  \n",
       "367  WP_DW_OC_FREASS              9.96  \n",
       "368  WP_DW_OC_FREASS              9.44  \n",
       "372  WP_DW_OC_FREASS              7.83  \n",
       "\n",
       "[111 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_EDU_LEVEL</th>\n      <th>DIM_SEX</th>\n      <th>DIM_AGE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OBS_STATUS</th>\n      <th>_merge</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n      <th>SCALED_OBS_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AL</td>\n      <td>2018.0</td>\n      <td>3.05680</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.53</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AG</td>\n      <td>2018.0</td>\n      <td>1.43781</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.78</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AR</td>\n      <td>2017.0</td>\n      <td>0.00779</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AM</td>\n      <td>2018.0</td>\n      <td>8.21479</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>8.74</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AU</td>\n      <td>2017.0</td>\n      <td>1.88277</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.71</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>365</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>GB</td>\n      <td>2017.0</td>\n      <td>0.12779</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.98</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>366</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>US</td>\n      <td>2017.0</td>\n      <td>0.22621</td>\n      <td>E</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.97</td>\n    </tr>\n    <tr>\n      <th>367</th>\n      <td>367</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>UY</td>\n      <td>2017.0</td>\n      <td>0.26134</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.96</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>368</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>UZ</td>\n      <td>2018.0</td>\n      <td>3.66859</td>\n      <td>E</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>9.44</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>372</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>VE</td>\n      <td>2017.0</td>\n      <td>14.07770</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n      <td>7.83</td>\n    </tr>\n  </tbody>\n</table>\n<p>111 rows Ã 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# s55_cleansed.DIM_SEX.unique()\n",
    "\n",
    "# s55_cleansed.DIM_AGE.unique()\n",
    "\n",
    "# s55_cleansed[(s55_cleansed.DIM_EDU_LEVEL == \"LOWER SECONDARY EDUCATION\") &\n",
    "    #  (s55_cleansed.DIM_AGE == \"SCHOOL_AGE_POPULATION\") &\n",
    "    # (s55_cleansed.DIM_SEX == \"BOTH_SEXES\")\n",
    "# ]\n",
    "\n",
    "s55_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0 ATTR_UNIT_MEASURE              DIM_EDU_LEVEL     DIM_SEX  \\\n",
       "0             0               NaN                          0  BOTH_SEXES   \n",
       "1             1                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "2             2                PT  LOWER SECONDARY EDUCATION      FEMALE   \n",
       "3             3                PT  LOWER SECONDARY EDUCATION        MALE   \n",
       "4             4               NaN                          0  BOTH_SEXES   \n",
       "..          ...               ...                        ...         ...   \n",
       "374         374                PT  LOWER SECONDARY EDUCATION        MALE   \n",
       "375         375               NaN                          0  BOTH_SEXES   \n",
       "376         376               NaN                          0  BOTH_SEXES   \n",
       "377         377               NaN                          0  BOTH_SEXES   \n",
       "378         378               NaN                          0  BOTH_SEXES   \n",
       "\n",
       "                   DIM_AGE COUNTRY_ISO_2  TIME_PERIOD  RAW_OBS_VALUE  \\\n",
       "0                       _T            AF       2020.0            NaN   \n",
       "1    SCHOOL_AGE_POPULATION            AL       2018.0        3.05680   \n",
       "2    SCHOOL_AGE_POPULATION            AL       2018.0        0.55400   \n",
       "3    SCHOOL_AGE_POPULATION            AL       2018.0        5.22058   \n",
       "4                       _T            AD       2020.0            NaN   \n",
       "..                     ...           ...          ...            ...   \n",
       "374  SCHOOL_AGE_POPULATION            VE       2017.0       14.91150   \n",
       "375                     _T            VN       2020.0            NaN   \n",
       "376                     _T            YE       2020.0            NaN   \n",
       "377                     _T            ZM       2020.0            NaN   \n",
       "378                     _T            ZW       2020.0            NaN   \n",
       "\n",
       "    ATTR_SOURCE_OBS_STATUS      _merge           INDICATOR_NAME  \\\n",
       "0                      NaN  right_only  Freedom of association.   \n",
       "1                        A        both  Freedom of association.   \n",
       "2                        A        both  Freedom of association.   \n",
       "3                        A        both  Freedom of association.   \n",
       "4                      NaN  right_only  Freedom of association.   \n",
       "..                     ...         ...                      ...   \n",
       "374                      A        both  Freedom of association.   \n",
       "375                    NaN  right_only  Freedom of association.   \n",
       "376                    NaN  right_only  Freedom of association.   \n",
       "377                    NaN  right_only  Freedom of association.   \n",
       "378                    NaN  right_only  Freedom of association.   \n",
       "\n",
       "    INDICATOR_INDEX            INDICATOR_ISSUE INDICATOR_CATEGORY  \\\n",
       "0         Workplace  Decent working conditions            Outcome   \n",
       "1         Workplace  Decent working conditions            Outcome   \n",
       "2         Workplace  Decent working conditions            Outcome   \n",
       "3         Workplace  Decent working conditions            Outcome   \n",
       "4         Workplace  Decent working conditions            Outcome   \n",
       "..              ...                        ...                ...   \n",
       "374       Workplace  Decent working conditions            Outcome   \n",
       "375       Workplace  Decent working conditions            Outcome   \n",
       "376       Workplace  Decent working conditions            Outcome   \n",
       "377       Workplace  Decent working conditions            Outcome   \n",
       "378       Workplace  Decent working conditions            Outcome   \n",
       "\n",
       "     CRBA_RELEASE_YEAR   INDICATOR_CODE  \n",
       "0                 2020  WP_DW_OC_FREASS  \n",
       "1                 2020  WP_DW_OC_FREASS  \n",
       "2                 2020  WP_DW_OC_FREASS  \n",
       "3                 2020  WP_DW_OC_FREASS  \n",
       "4                 2020  WP_DW_OC_FREASS  \n",
       "..                 ...              ...  \n",
       "374               2020  WP_DW_OC_FREASS  \n",
       "375               2020  WP_DW_OC_FREASS  \n",
       "376               2020  WP_DW_OC_FREASS  \n",
       "377               2020  WP_DW_OC_FREASS  \n",
       "378               2020  WP_DW_OC_FREASS  \n",
       "\n",
       "[379 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_EDU_LEVEL</th>\n      <th>DIM_SEX</th>\n      <th>DIM_AGE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OBS_STATUS</th>\n      <th>_merge</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AL</td>\n      <td>2018.0</td>\n      <td>3.05680</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>FEMALE</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AL</td>\n      <td>2018.0</td>\n      <td>0.55400</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>MALE</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AL</td>\n      <td>2018.0</td>\n      <td>5.22058</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>AD</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>374</th>\n      <td>374</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>MALE</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>VE</td>\n      <td>2017.0</td>\n      <td>14.91150</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>375</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>VN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>376</th>\n      <td>376</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>YE</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>377</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>ZM</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>378</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>BOTH_SEXES</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>right_only</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n  </tbody>\n</table>\n<p>379 rows Ã 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "s55_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-55_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "s55_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(cleansed_data['DIM_SEX'] == 'BOTH_SEXES')&(cleansed_data['DIM_EDU_LEVEL'] == 'LOWER SECONDARY EDUCATION')&(cleansed_data['DIM_AGE'] == 'SCHOOL_AGE_POPULATION')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Unnamed: 0 ATTR_UNIT_MEASURE              DIM_EDU_LEVEL     DIM_SEX  \\\n",
       "1             1                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "7             7                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "10           10                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "11           11                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "14           14                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "..          ...               ...                        ...         ...   \n",
       "365         365                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "366         366                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "367         367                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "368         368                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "372         372                PT  LOWER SECONDARY EDUCATION  BOTH_SEXES   \n",
       "\n",
       "                   DIM_AGE COUNTRY_ISO_2  TIME_PERIOD  RAW_OBS_VALUE  \\\n",
       "1    SCHOOL_AGE_POPULATION            AL       2018.0        3.05680   \n",
       "7    SCHOOL_AGE_POPULATION            AG       2018.0        1.43781   \n",
       "10   SCHOOL_AGE_POPULATION            AR       2017.0        0.00779   \n",
       "11   SCHOOL_AGE_POPULATION            AM       2018.0        8.21479   \n",
       "14   SCHOOL_AGE_POPULATION            AU       2017.0        1.88277   \n",
       "..                     ...           ...          ...            ...   \n",
       "365  SCHOOL_AGE_POPULATION            GB       2017.0        0.12779   \n",
       "366  SCHOOL_AGE_POPULATION            US       2017.0        0.22621   \n",
       "367  SCHOOL_AGE_POPULATION            UY       2017.0        0.26134   \n",
       "368  SCHOOL_AGE_POPULATION            UZ       2018.0        3.66859   \n",
       "372  SCHOOL_AGE_POPULATION            VE       2017.0       14.07770   \n",
       "\n",
       "    ATTR_SOURCE_OBS_STATUS _merge           INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "1                        A   both  Freedom of association.       Workplace   \n",
       "7                        A   both  Freedom of association.       Workplace   \n",
       "10                       A   both  Freedom of association.       Workplace   \n",
       "11                       A   both  Freedom of association.       Workplace   \n",
       "14                       A   both  Freedom of association.       Workplace   \n",
       "..                     ...    ...                      ...             ...   \n",
       "365                      A   both  Freedom of association.       Workplace   \n",
       "366                      E   both  Freedom of association.       Workplace   \n",
       "367                      A   both  Freedom of association.       Workplace   \n",
       "368                      E   both  Freedom of association.       Workplace   \n",
       "372                      A   both  Freedom of association.       Workplace   \n",
       "\n",
       "               INDICATOR_ISSUE INDICATOR_CATEGORY  CRBA_RELEASE_YEAR  \\\n",
       "1    Decent working conditions            Outcome               2020   \n",
       "7    Decent working conditions            Outcome               2020   \n",
       "10   Decent working conditions            Outcome               2020   \n",
       "11   Decent working conditions            Outcome               2020   \n",
       "14   Decent working conditions            Outcome               2020   \n",
       "..                         ...                ...                ...   \n",
       "365  Decent working conditions            Outcome               2020   \n",
       "366  Decent working conditions            Outcome               2020   \n",
       "367  Decent working conditions            Outcome               2020   \n",
       "368  Decent working conditions            Outcome               2020   \n",
       "372  Decent working conditions            Outcome               2020   \n",
       "\n",
       "      INDICATOR_CODE  \n",
       "1    WP_DW_OC_FREASS  \n",
       "7    WP_DW_OC_FREASS  \n",
       "10   WP_DW_OC_FREASS  \n",
       "11   WP_DW_OC_FREASS  \n",
       "14   WP_DW_OC_FREASS  \n",
       "..               ...  \n",
       "365  WP_DW_OC_FREASS  \n",
       "366  WP_DW_OC_FREASS  \n",
       "367  WP_DW_OC_FREASS  \n",
       "368  WP_DW_OC_FREASS  \n",
       "372  WP_DW_OC_FREASS  \n",
       "\n",
       "[111 rows x 16 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_EDU_LEVEL</th>\n      <th>DIM_SEX</th>\n      <th>DIM_AGE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OBS_STATUS</th>\n      <th>_merge</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AL</td>\n      <td>2018.0</td>\n      <td>3.05680</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AG</td>\n      <td>2018.0</td>\n      <td>1.43781</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AR</td>\n      <td>2017.0</td>\n      <td>0.00779</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AM</td>\n      <td>2018.0</td>\n      <td>8.21479</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>AU</td>\n      <td>2017.0</td>\n      <td>1.88277</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>365</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>GB</td>\n      <td>2017.0</td>\n      <td>0.12779</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>366</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>US</td>\n      <td>2017.0</td>\n      <td>0.22621</td>\n      <td>E</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>367</th>\n      <td>367</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>UY</td>\n      <td>2017.0</td>\n      <td>0.26134</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>368</th>\n      <td>368</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>UZ</td>\n      <td>2018.0</td>\n      <td>3.66859</td>\n      <td>E</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>372</td>\n      <td>PT</td>\n      <td>LOWER SECONDARY EDUCATION</td>\n      <td>BOTH_SEXES</td>\n      <td>SCHOOL_AGE_POPULATION</td>\n      <td>VE</td>\n      <td>2017.0</td>\n      <td>14.07770</td>\n      <td>A</td>\n      <td>both</td>\n      <td>Freedom of association.</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n  </tbody>\n</table>\n<p>111 rows Ã 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "def subset_creator(\n",
    "    cleansed_data,\n",
    "    **dimensions\n",
    "):\n",
    "    # Empty string which will be filled with subset conditions\n",
    "    subset = \"\"\n",
    "\n",
    "    # Run loop to get dimensions vaues specified in **dimensions\n",
    "    for key in dimensions:\n",
    "        subset += \"(cleansed_data['{}'] == '{}')&\".format(\n",
    "            key,\n",
    "            dimensions[key]\n",
    "        )\n",
    "    \n",
    "    # Get rid of the \"&-sign\" at the end\n",
    "    subset = subset.rstrip(\"& \")\n",
    "\n",
    "    # Just for dev:\n",
    "    print(subset)\n",
    "\n",
    "    # Subset\n",
    "    cleansed_data_subset = cleansed_data[eval(subset)]\n",
    "\n",
    "    # \n",
    "    # print(cleansed_data_subset)\n",
    "\n",
    "    # Return cleansed data\n",
    "    return cleansed_data_subset\n",
    "\n",
    "\n",
    "s55_cleansed = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_cleansed / \"S-55_cleansed.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "s55_subset = subset_creator(\n",
    "    cleansed_data = s55_cleansed,\n",
    "    DIM_SEX = \"BOTH_SEXES\",\n",
    "    DIM_EDU_LEVEL = \"LOWER SECONDARY EDUCATION\",\n",
    "    DIM_AGE = \"SCHOOL_AGE_POPULATION\"\n",
    ")\n",
    "\n",
    "s55_subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def map_values(\n",
    "    dataframe,\n",
    "    value_mapping_dict\n",
    "):\n",
    "\n",
    "    for key in value_mapping_dict:\n",
    "        # try:\n",
    "        # Define emtpy lists to be mapped to each other\n",
    "        original_values = []\n",
    "        mapped_values = []\n",
    "\n",
    "        # Loop obtain all possible original/ mapped value variations mappings\n",
    "        for sub_key in value_mapper[key]:\n",
    "            original_values += value_mapping_dict[key][sub_key]\n",
    "            mapped_values += len(value_mapping_dict[key][sub_key]) * [sub_key]\n",
    "        \n",
    "        print(original_values)\n",
    "        print(mapped_values)\n",
    "\n",
    "        # Convert the values\n",
    "        dataframe[key] = np.select(\n",
    "            original_values, mapped_values\n",
    "        )\n",
    "    \n",
    "        # log info for user\n",
    "        print(\"Successfully mapped value of column: {}\".format(\n",
    "            key\n",
    "        ))\n",
    "        #except:\n",
    "        #    print(\"The following dimension is not present in the raw dataframe {}. There are thus no values to be mapped.\".format(\n",
    "        #        key\n",
    "        #    ))\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "\n",
    "s55_raw[\"REF_AREA\"].apply(lambda x: len(str(x))).quantile(q=0.25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 3 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 326 unique values.\n",
      "The column TIME_PERIOD has 14 unique values.\n",
      "The column OBS_VALUE has 26627 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1953f6dd7330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlenght\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms55_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"REF_AREA\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# s55_raw.to_csv(data_sources_raw / \"S_55_raw.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1953f6dd7330>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlenght\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms55_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"REF_AREA\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# s55_raw.to_csv(data_sources_raw / \"S_55_raw.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "from statistics import median, mean\n",
    "\n",
    "s55_raw = extract.CSVExtractor.extract(url =\n",
    "    'https://api.uis.unesco.org/sdmx/data/UNESCO,SDG4,2.0/ROFST.PT.L2+L2_3+L3._T._T+F+M.SCH_AGE_GROUP._T.INST_T._Z._T._Z._Z._Z._T._T._Z._Z._Z.?startPeriod=2005&endPeriod=2018&format=csv-sdmx&locale=en&subscription-key=460ab272abdd43c892bb59c218c22c09'\n",
    ")\n",
    "\n",
    "lenght = s55_raw[\"REF_AREA\"].apply(lambda x: len(x))\n",
    "\n",
    "# s55_raw.to_csv(data_sources_raw / \"S_55_raw.csv\")"
   ]
  },
  {
   "source": [
    "# Cleansing\n",
    "\n",
    "\n",
    "< STOPPED HERE , the below code runs (but have to define tha mapping_dict first) --> Next step is to Bring this thing into a loop and take care of the exceptions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleansing done. There are 569 rows in the dataframe and 1.41% have a NA-value in the column 'OBS_RAW_VALUE\n\n Successfully mapped value of column: DIM_SEX\nValues of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \nValues of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \nValues of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \nValues of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \nValues of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \nValues of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n"
     ]
    }
   ],
   "source": [
    "s98_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-98_raw.csv\"\n",
    ")\n",
    "\n",
    "s98_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s98_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "s98_cleansed_mapped = map_values(\n",
    "    dataframe = s98_cleansed,\n",
    "    value_mapping_dict = value_mapper\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Loop through all possible columns as defined for the final SDMX structure\n",
    "for key in value_mapper:\n",
    "    try:\n",
    "        # Define emtpy lists to be mapped to each other\n",
    "        original_values = []\n",
    "        mapped_values = []\n",
    "\n",
    "        # Loop obtain all possible original/ mapped value variations mappings\n",
    "        for sub_key in value_mapper[key]:\n",
    "            # Obtain boolean arrays for each possible original value\n",
    "            for list_element in range(len(value_mapper[key][sub_key])):\n",
    "                original_values += [s98_cleansed[key] == value_mapper[key][sub_key][list_element]]\n",
    "            \n",
    "            # Define the target value if original_values evaluates to true\n",
    "            mapped_values += len(value_mapper[key][sub_key]) * [sub_key]\n",
    "        \n",
    "        # Convert (map) the values\n",
    "        s98_cleansed[key] = np.select(\n",
    "            original_values, mapped_values\n",
    "        )\n",
    "\n",
    "        # log info for user\n",
    "        print(\"\\n Successfully mapped value of column: {}\".format(\n",
    "            key\n",
    "        ))\n",
    "\n",
    "    # If column is not presnt (or if there are other issues)\n",
    "    except:\n",
    "        print(\"Values of column: {} couldn't be mapped. If column {} is present, there is an error with the code. \".format(\n",
    "            key,\n",
    "            key\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleansing done. There are 195 rows in the dataframe and 26.15% have a NA-value in the column 'OBS_RAW_VALUE\n['_T', 'BOTHSEX', 'BTSX', 'SEX_T', 'M', 'MALE', 'MLE', 'SEX_M', 'F', 'FEMALE', 'FMLE', 'SEX_F']\n['BOTH_SEXES', 'BOTH_SEXES', 'BOTH_SEXES', 'BOTH_SEXES', 'MALE', 'MALE', 'MALE', 'MALE', 'FEMALE', 'FEMALE', 'FEMALE', 'FEMALE']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "invalid entry 0 in condlist: should be boolean ndarray",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9d1d335d9d46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0ms102_cleansed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m s102_cleansed_mapped = map_values(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms102_cleansed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mvalue_mapping_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dc9b75e6815a>\u001b[0m in \u001b[0;36mmap_values\u001b[0;34m(dataframe, value_mapping_dict)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Convert the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         dataframe[key] = np.select(\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moriginal_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         )\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mselect\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(condlist, choicelist, default)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    689\u001b[0m                 'invalid entry {} in condlist: should be boolean ndarray'.format(i))\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid entry 0 in condlist: should be boolean ndarray"
     ]
    }
   ],
   "source": [
    "import cleanse\n",
    "import pandas as pd\n",
    "\n",
    "s102_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-102_raw.csv\"\n",
    ")\n",
    "\n",
    "s102_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s102_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    ")\n",
    "\n",
    "# s102_cleansed[\"REF_AREA\"].apply(lambda x: mean(len(x)))\n",
    "s102_cleansed.head(30)\n",
    "\n",
    "s102_cleansed_mapped = map_values(\n",
    "    dataframe = s102_cleansed,\n",
    "    value_mapping_dict = value_mapper\n",
    ")\n",
    "\n",
    "s102_cleansed_mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\nCOUNTRY_ISO_2\n2\nCleansing done. There are 1051 rows in the dataframe and 1.52% have a NA-value in the column 'OBS_RAW_VALUE\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ATTR_UNIT_MEASURE DIM_EDU_LEVEL DIM_SEX DIM_AGE COUNTRY_ISO_2  \\\n",
       "0                   PT           L01      _T      _T            AF   \n",
       "1                   PT           L01       F      _T            AF   \n",
       "2                   PT           L01       M      _T            AF   \n",
       "3                   PT           L01      _T      _T            AL   \n",
       "4                   PT           L01       F      _T            AL   \n",
       "...                ...           ...     ...     ...           ...   \n",
       "1046                PT           L01       F      _T            ZW   \n",
       "1047                PT           L01       M      _T            ZW   \n",
       "1048                PT           L02      _T      _T            ZW   \n",
       "1049                PT           L02       F      _T            ZW   \n",
       "1050                PT           L02       M      _T            ZW   \n",
       "\n",
       "      TIME_PERIOD  RAW_OBS_VALUE ATTR_SOURCE_OBS_STATUS _merge  \n",
       "0          2018.0        0.00000                      Z   both  \n",
       "1          2018.0        0.00000                      Z   both  \n",
       "2          2018.0        0.00000                      Z   both  \n",
       "3          2012.0        0.00000                      Z   both  \n",
       "4          2012.0        0.00000                      Z   both  \n",
       "...           ...            ...                    ...    ...  \n",
       "1046       2013.0        0.00000                      Z   both  \n",
       "1047       2013.0        0.00000                      Z   both  \n",
       "1048       2013.0       46.95562                      A   both  \n",
       "1049       2013.0       47.51739                      A   both  \n",
       "1050       2013.0       46.39818                      A   both  \n",
       "\n",
       "[1051 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_EDU_LEVEL</th>\n      <th>DIM_SEX</th>\n      <th>DIM_AGE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OBS_STATUS</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>AL</td>\n      <td>2012.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>AL</td>\n      <td>2012.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1046</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1047</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>46.95562</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1049</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>47.51739</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>46.39818</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n<p>1051 rows Ã 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import cleanse\n",
    "import pandas as pd\n",
    "\n",
    "s52_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-52_raw.csv\"\n",
    ")\n",
    "\n",
    "s52_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s52_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    ")\n",
    "\n",
    "# s102_cleansed[\"REF_AREA\"].apply(lambda x: mean(len(x)))\n",
    "s52_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import mapping_dictionary\n",
    "# %run utils.mapping_dictionary.py\n",
    "\n",
    "# %run \"D:\\Documents\\2020\\28_UNICEF\\10_working_repo\\data-etl\\utils\\mapping_dictionary.py\"\n",
    "\n",
    "country_tuple = (\"REF_AREA\", \"COUNTRY\")\n",
    "country_mapper = {key: \"REF_AREA\" for key in country_tuple}\n",
    "\n",
    "\n",
    "year_tuple = (\n",
    "    \"TIME_PERIOD\",\n",
    "    \"YEAR\",\n",
    ")\n",
    "year_mapper = {key: \"TIME_PERIOD\" for key in year_tuple}\n",
    "\n",
    "\n",
    "obs_value_tuple = (\"OBS_VALUE\", \"Display Value\")\n",
    "obs_value_mapper = {key: \"OBS_VALUE\" for key in obs_value_tuple}\n",
    "\n",
    "\n",
    "dim_sex_tuple = \"SEX\"\n",
    "dim_sex_mapper = {key: \"OBS_VALUE\" for key in obs_value_tuple}\n",
    "\n",
    "\"\"\"\n",
    "dim_edu_tuple = (\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "dim_age_tuple = (\n",
    "    \"SEX\"\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create list of all mapper dictionaries\n",
    "mapper_tuple_list = [country_mapper, year_mapper, obs_value_mapper, dim_sex_mapper]\n",
    "\n",
    "# Define the mapping dictionary\n",
    "mapping_dict = {}\n",
    "\n",
    "for mapper_tuple in mapper_tuple_list:\n",
    "    mapping_dict.update(mapper_tuple)\n",
    "\n",
    "with open(\"mapping_dict.json\", \"w\") as fp:\n",
    "    json.dump(mapping_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'REF_AREA': 'xxx', 'COUNTRY': 'xxx', 'TIME_PERIOD': 'yyy', 'YEAR': 'yyy'}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "year_tuple = (\n",
    "    \"TIME_PERIOD\",\n",
    "    \"YEAR\", \n",
    ")\n",
    "\n",
    "x = {key: \"xxx\" for key in country_tuple}\n",
    "y = {key: \"yyy\" for key in year_tuple}\n",
    "\n",
    "x.update(y)\n",
    "x}\n",
    "y = {key: \"yyy\" for key in year_tuple}\n",
    "\n",
    "x.update(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s55_cleansed = cleanse.Cleanser.cleanse(\n",
    "    raw_data = s55_raw,\n",
    "    raw_data_iso_2_col = 'REF_AREA',\n",
    "    country_df = country_crba_list,\n",
    "    country_df_iso2_col = 'COUNTRY_ISO_2',\n",
    "    non_dim_cols = ['OBS_VALUE', 'TIME_PERIOD', 'OBS_STATUS']\n",
    ")\n",
    "\n",
    "s55_cleansed.to_csv(data_sources_raw / \"S_55_cleansed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You have a selected a few columns, which will not be regarded as dimensions.These are the remaining columns in the dataset, along with the number of values they take in the dataset.\n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 3 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The total number of subgroups in the dataset is therefore: 9\n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #1, which has these defining values: \n",
      " \n",
      " Empty DataFrame\n",
      "Columns: [Dataflow, STAT_UNIT, UNIT_MEASURE, EDU_LEVEL, EDU_CAT, SEX, AGE, GRADE, SECTOR_EDU, EDU_ATTAIN, SUBJECT, WEALTH_QUINTILE, INFRASTR, LOCATION, EDU_TYPE, SE_BKGRD, SOURCE_FUND, FUND_FLOW, IMM_STATUS, UNIT_MULT, FREQ, DECIMALS]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (0, 30) \n",
      " \n",
      " \n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #1. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #2, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1387  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1387  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1387       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1387        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (163, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 43.630325000000006 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.00589. This value corresponds to country: 739    Lithuania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #2. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #3, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1395  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1395  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1395       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1395        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (160, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 83.84053. This value corresponds to country: 1317    Tanzania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.67013. This value corresponds to country: 128    Belgium\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #3. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #4, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1394  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1394  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1394       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1394        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (160, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 89.7091. This value corresponds to country: 255    Central African Republic\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.07972. This value corresponds to country: 941    New Zealand\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #4. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #5, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1393  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1393  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1393       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1393        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (165, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 86.14805. This value corresponds to country: 958    Niger\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06444. This value corresponds to country: 931    Netherlands\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #5. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #6, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1392  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1392  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1392       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1392        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (161, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 65.25736 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.08982000000000001. This value corresponds to country: 1193    Singapore\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #6. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #7, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1391  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1391  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1391       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1391        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (161, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 66.091475 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06039. This value corresponds to country: 616    Ireland\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #7. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #8, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1390  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1390  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1390       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1390        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (162, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 69.8756925 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.07741. This value corresponds to country: 1191    Singapore\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #8. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #9, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1389  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1389  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1389       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1389        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (155, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 43.3836 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06477999999999999. This value corresponds to country: 656    Kazakhstan\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #9. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #10, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1388  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1388  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1388       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1388        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (155, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 45.940870000000004 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.09435. This value corresponds to country: 740    Lithuania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #10. \n",
      " - \n",
      " \n",
      "The number of rows of the final dataframe (before the conversion from wide to long format is) is divisible by 195. It is: (585, 38)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT  SEX  \\\n",
       "0    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "1    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "2                 NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "3                 NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "4    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "..                ...       ...          ...       ...     ...  ...   \n",
       "190  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "191               NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "192  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "193               NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "194  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "\n",
       "               AGE GRADE SECTOR_EDU EDU_ATTAIN  ... COUNTRY_ISO_3_y  \\\n",
       "0    SCH_AGE_GROUP    _T     INST_T         _Z  ...             AFG   \n",
       "1    SCH_AGE_GROUP    _T     INST_T         _Z  ...             ALB   \n",
       "2              NaN   NaN        NaN        NaN  ...             AND   \n",
       "3              NaN   NaN        NaN        NaN  ...             DZA   \n",
       "4    SCH_AGE_GROUP    _T     INST_T         _Z  ...             AGO   \n",
       "..             ...   ...        ...        ...  ...             ...   \n",
       "190  SCH_AGE_GROUP    _T     INST_T         _Z  ...             VEN   \n",
       "191            NaN   NaN        NaN        NaN  ...             VNM   \n",
       "192  SCH_AGE_GROUP    _T     INST_T         _Z  ...             YEM   \n",
       "193            NaN   NaN        NaN        NaN  ...             ZMB   \n",
       "194  SCH_AGE_GROUP    _T     INST_T         _Z  ...             ZWE   \n",
       "\n",
       "    COUNTRY_NAME_y COUNTRY_ISO_2_y RJ_CRBA_FULL_LIST  \\\n",
       "0      Afghanistan              AF              both   \n",
       "1          Albania              AL              both   \n",
       "2          Andorra              AD        right_only   \n",
       "3          Algeria              DZ        right_only   \n",
       "4           Angola              AO              both   \n",
       "..             ...             ...               ...   \n",
       "190      Venezuela              VE              both   \n",
       "191        Vietnam              VN        right_only   \n",
       "192          Yemen              YE              both   \n",
       "193         Zambia              ZM        right_only   \n",
       "194       Zimbabwe              ZW              both   \n",
       "\n",
       "                                  INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "0    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "1    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "2    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "3    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "4    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "..                                           ...             ...   \n",
       "190  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "191  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "192  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "193  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "194  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "\n",
       "               INDICATOR_ISSUE INDICATOR_CATEGORY CRBA_RELEASE_YEAR  \\\n",
       "0    Decent working conditions            Outcome              2020   \n",
       "1    Decent working conditions            Outcome              2020   \n",
       "2    Decent working conditions            Outcome              2020   \n",
       "3    Decent working conditions            Outcome              2020   \n",
       "4    Decent working conditions            Outcome              2020   \n",
       "..                         ...                ...               ...   \n",
       "190  Decent working conditions            Outcome              2020   \n",
       "191  Decent working conditions            Outcome              2020   \n",
       "192  Decent working conditions            Outcome              2020   \n",
       "193  Decent working conditions            Outcome              2020   \n",
       "194  Decent working conditions            Outcome              2020   \n",
       "\n",
       "      INDICATOR_CODE  \n",
       "0    WP_DW_OC_FREASS  \n",
       "1    WP_DW_OC_FREASS  \n",
       "2    WP_DW_OC_FREASS  \n",
       "3    WP_DW_OC_FREASS  \n",
       "4    WP_DW_OC_FREASS  \n",
       "..               ...  \n",
       "190  WP_DW_OC_FREASS  \n",
       "191  WP_DW_OC_FREASS  \n",
       "192  WP_DW_OC_FREASS  \n",
       "193  WP_DW_OC_FREASS  \n",
       "194  WP_DW_OC_FREASS  \n",
       "\n",
       "[585 rows x 44 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataflow</th>\n      <th>STAT_UNIT</th>\n      <th>UNIT_MEASURE</th>\n      <th>EDU_LEVEL</th>\n      <th>EDU_CAT</th>\n      <th>SEX</th>\n      <th>AGE</th>\n      <th>GRADE</th>\n      <th>SECTOR_EDU</th>\n      <th>EDU_ATTAIN</th>\n      <th>...</th>\n      <th>COUNTRY_ISO_3_y</th>\n      <th>COUNTRY_NAME_y</th>\n      <th>COUNTRY_ISO_2_y</th>\n      <th>RJ_CRBA_FULL_LIST</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>AL</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>AND</td>\n      <td>Andorra</td>\n      <td>AD</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>DZA</td>\n      <td>Algeria</td>\n      <td>DZ</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>AGO</td>\n      <td>Angola</td>\n      <td>AO</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>VEN</td>\n      <td>Venezuela</td>\n      <td>VE</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>VNM</td>\n      <td>Vietnam</td>\n      <td>VN</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>YEM</td>\n      <td>Yemen</td>\n      <td>YE</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>ZMB</td>\n      <td>Zambia</td>\n      <td>ZM</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>ZWE</td>\n      <td>Zimbabwe</td>\n      <td>ZW</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n  </tbody>\n</table>\n<p>585 rows Ã 44 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from normalize.scaler import normalizer\n",
    "\n",
    "s55_normalized = normalizer(\n",
    "    cleansed_data = s55_cleansed,\n",
    "    indicator_raw_value = 'OBS_VALUE',\n",
    "    indicator_code = 'WP_DW_OC_FREASS',\n",
    "    indicator_name = 'Out-of-school adolescents (lower secondary)',\n",
    "    indicator_index = 'Workplace',\n",
    "    indicator_issue = 'Decent working conditions',\n",
    "    indicator_category = 'Outcome',\n",
    "    cleansed_df_iso2_col = 'REF_AREA',\n",
    "    crba_final_country_list = country_crba_list,\n",
    "    crba_final_country_list_iso_col = 'COUNTRY_ISO_2',\n",
    "    inverted = True,\n",
    "    non_dim_cols = [\n",
    "        'TIME_PERIOD', \n",
    "        'REF_AREA', \n",
    "        'OBS_VALUE', \n",
    "        'OBS_STATUS', \n",
    "        'COUNTRY_ISO_3', \n",
    "        'COUNTRY_NAME', \n",
    "        'COUNTRY_ISO_2', \n",
    "        '_merge'\n",
    "    ])\n",
    "\n",
    "s55_normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}