{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600935211265",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required standard libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import selenium\n",
    "import html5lib\n",
    "from selenium import webdriver\n",
    "\n",
    "# Extractors (cluster specific)\n",
    "from extract.unesco_extractor import extract_unesco_api_data\n",
    "from extract.ilo_extractor import extract_ilo_api_data\n",
    "from extract.sdg_extractor import extract_sdg_api_data\n",
    "from extract.who_extractor import extract_who_api_data\n",
    "from extract.un_treaty_extractor import extract_un_treaties_data\n",
    "from extract.ilo_normlex_extractor import extract_ilo_normlex_data\n",
    "\n",
    "from extract import save_raw_data\n",
    "\n",
    "# Cleansers (cluster specific)\n",
    "from cleanse.unesco_cleanser import cleanse_unesco_api_data\n",
    "from cleanse.ilo_cleanser import cleanse_ilo_api_data\n",
    "from cleanse.sdg_cleanser import cleanse_sdg_api_data\n",
    "from cleanse.who_cleanser import cleanse_who_api_num_data\n",
    "from cleanse.un_treaty_cleanser import cleanse_un_treaty_data\n",
    "from cleanse.wpac_cleanser import cleanse_wpac_data\n",
    "\n",
    "# from cleanse.save_cleansed_data import save_cleansed_data \n",
    "\n",
    "# Normalizer (generalised across all clusters)\n",
    "from normalize import scaler\n",
    "# from normalize import save_normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export path for all data exports\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path('.')\n",
    "\n",
    "data_in = cwd / 'data_in'\n",
    "data_sources_raw = cwd / 'data_out'\n",
    "data_sources_raw.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    COUNTRY_ISO_3 COUNTRY_NAME COUNTRY_ISO_2\n0             AFG  Afghanistan            AF\n1             ALB      Albania            AL\n2             AND      Andorra            AD\n3             DZA      Algeria            DZ\n4             AGO       Angola            AO\n..            ...          ...           ...\n190           VEN    Venezuela            VE\n191           VNM      Vietnam            VN\n192           YEM        Yemen            YE\n193           ZMB       Zambia            ZM\n194           ZWE     Zimbabwe            ZW\n\n[195 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>COUNTRY_ISO_3</th>\n      <th>COUNTRY_NAME</th>\n      <th>COUNTRY_ISO_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>Andorra</td>\n      <td>AD</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DZA</td>\n      <td>Algeria</td>\n      <td>DZ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AGO</td>\n      <td>Angola</td>\n      <td>AO</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>VEN</td>\n      <td>Venezuela</td>\n      <td>VE</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>VNM</td>\n      <td>Vietnam</td>\n      <td>VN</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>YEM</td>\n      <td>Yemen</td>\n      <td>YE</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>ZMB</td>\n      <td>Zambia</td>\n      <td>ZM</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>ZWE</td>\n      <td>Zimbabwe</td>\n      <td>ZW</td>\n    </tr>\n  </tbody>\n</table>\n<p>195 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Create a version of the list with unique ISO2 and ISO3 codes\n",
    "country_iso_list = country_full_list.drop_duplicates(subset = 'CountryIso2')\n",
    "\n",
    "# Country CRBA list, this is the list of the countries that should be in the final CRBA indicator list\n",
    "country_crba_list = pd.read_excel(\n",
    "    data_in / 'crba_country_list.xlsx',\n",
    "    header = None,\n",
    "    usecols = [0, 1], \n",
    "    names = ['COUNTRY_ISO_3', 'COUNTRY_NAME']).merge(\n",
    "        right = country_iso_list,\n",
    "        how = 'left',\n",
    "        left_on = 'COUNTRY_ISO_3',\n",
    "        right_on = 'CountryIso3',\n",
    "        validate = 'one_to_one')[\n",
    "    ['COUNTRY_ISO_3', 'COUNTRY_NAME', 'CountryIso2']].rename(\n",
    "    columns = {'CountryIso2': \"COUNTRY_ISO_2\"})\n",
    "\n",
    "country_crba_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crba_data_dictionary_sources = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Source\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Load data dictionary snapshot sheet\n",
    "crba_data_dictionary_snapshot = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Snapshot\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The following columns are present in the datasets, and this is the number of unique values they have. \nThe column Dataflow has 1 unique values.\nThe column STAT_UNIT has 1 unique values.\nThe column UNIT_MEASURE has 1 unique values.\nThe column EDU_LEVEL has 3 unique values.\nThe column EDU_CAT has 1 unique values.\nThe column SEX has 3 unique values.\nThe column AGE has 1 unique values.\nThe column GRADE has 1 unique values.\nThe column SECTOR_EDU has 1 unique values.\nThe column EDU_ATTAIN has 1 unique values.\nThe column SUBJECT has 1 unique values.\nThe column WEALTH_QUINTILE has 1 unique values.\nThe column INFRASTR has 1 unique values.\nThe column LOCATION has 1 unique values.\nThe column EDU_TYPE has 1 unique values.\nThe column SE_BKGRD has 1 unique values.\nThe column SOURCE_FUND has 1 unique values.\nThe column FUND_FLOW has 1 unique values.\nThe column IMM_STATUS has 1 unique values.\nThe column REF_AREA has 326 unique values.\nThe column TIME_PERIOD has 14 unique values.\nThe column OBS_VALUE has 26627 unique values.\nThe column UNIT_MULT has 1 unique values.\nThe column OBS_STATUS has 3 unique values.\nThe column FREQ has 1 unique values.\nThe column DECIMALS has 1 unique values.\n"
    }
   ],
   "source": [
    "# Extract data\n",
    "from extract import CSVExtractor\n",
    "\n",
    "s55_raw = CSVExtractor.extract(\n",
    "    'https://api.uis.unesco.org/sdmx/data/UNESCO,SDG4,2.0/ROFST.PT.L2+L2_3+L3._T._T+F+M.SCH_AGE_GROUP._T.INST_T._Z._T._Z._Z._Z._T._T._Z._Z._Z.?startPeriod=2005&endPeriod=2018&format=csv-sdmx&locale=en&subscription-key=460ab272abdd43c892bb59c218c22c09'\n",
    ")\n",
    "\n",
    "s55_raw.to_csv(data_sources_raw / \"data_raw/S_55_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanse import Cleanser\n",
    "\n",
    "cleansed= Cleanser.cleanse(\n",
    "    raw_data = s55_raw,\n",
    "    raw_data_iso_2_col = 'REF_AREA',\n",
    "    country_df = country_crba_list,\n",
    "    country_df_iso2_col = 'COUNTRY_ISO_2',\n",
    "    non_dim_cols = ['OBS_VALUE', 'TIME_PERIOD', 'OBS_STATUS']\n",
    ")\n",
    "\n",
    "s55_raw.to_csv(data_sources_raw / \"S_55_cleansed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}