{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Required standard libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import selenium\n",
    "import html5lib\n",
    "#import nltk\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "# Extractors \n",
    "import extract\n",
    "\n",
    "# Cleansers (cluster specific)\n",
    "import cleanse\n",
    "\n",
    "# Normalizer (generalised across all clusters)\n",
    "from normalize import scaler\n",
    "\n",
    "# Utils\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export path for all data exports\n",
    "from pathlib import Path\n",
    "\n",
    "# Current working directory\n",
    "cwd = Path('.')\n",
    "\n",
    "# Folder with data-in artifacts, quired to run this script\n",
    "data_in = cwd / 'data_in'\n",
    "\n",
    "# Folder containing manually extracted raw data, ready to be put in the loop\n",
    "data_sources_staged_raw = cwd / 'data_out' / 'data_staged_raw'\n",
    "data_sources_staged_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export raw data\n",
    "data_sources_raw = cwd / 'data_out' / 'data_raw'\n",
    "data_sources_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export cleansed data\n",
    "data_sources_cleansed = cwd / 'data_out' / 'data_cleansed'\n",
    "data_sources_cleansed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export normalized data\n",
    "data_sources_normalized = cwd / 'data_out' / 'data_normalized'\n",
    "data_sources_normalized.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load country list and mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Create a version of the list with unique ISO2 and ISO3 codes\n",
    "country_iso_list = country_full_list.drop_duplicates(subset = 'COUNTRY_ISO_2')\n",
    "\n",
    "# Country CRBA list, this is the list of the countries that should be in the final CRBA indicator list\n",
    "country_crba_list = pd.read_excel(\n",
    "    data_in / 'crba_country_list.xlsx',\n",
    "    header = None,\n",
    "    usecols = [0, 1], \n",
    "    names = ['COUNTRY_ISO_3', 'COUNTRY_NAME']).merge(\n",
    "        right = country_iso_list[['COUNTRY_ISO_2', 'COUNTRY_ISO_3']],\n",
    "        how = 'left',\n",
    "        on='COUNTRY_ISO_3',\n",
    "        validate = 'one_to_one')\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'column_mapping.py') as file:\n",
    "    exec(file.read())\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'value_mapping.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources sheet\n",
    "crba_data_dictionary_source = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Source\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# snapshot sheet\n",
    "crba_data_dictionary_snapshot = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Snapshot\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# indicator sheet\n",
    "crba_data_dictionary_indicator = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Indicator\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Input lists\n",
    "crba_data_dictionary_input_list = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Input_Lists\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Add 2-digit shortcodes of index, issue and category to indicators sheet\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.merge(\n",
    "    right=crba_data_dictionary_input_list[['INDEX', 'INDEX_CODE']],\n",
    "    left_on='INDEX',\n",
    "    right_on='INDEX'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['ISSUE', 'ISSUE_CODE']],\n",
    "    left_on='ISSUE',\n",
    "    right_on='ISSUE'\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['CATEGORY', 'CATEGORY_CODE']],\n",
    "    left_on='CATEGORY',\n",
    "    right_on='CATEGORY'\n",
    ")\n",
    "\n",
    "# Create indicator code prefix (INDEX-ISSUE_CAEGORY CODE)\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE_PREFIX = crba_data_dictionary_indicator.INDEX_CODE +\n",
    "    \"_\" +\n",
    "    crba_data_dictionary_indicator.ISSUE_CODE+\n",
    "    \"_\"+\n",
    "    crba_data_dictionary_indicator.CATEGORY_CODE+\n",
    "    \"_\")\n",
    "\n",
    "# Create indicator code\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE = crba_data_dictionary_indicator.INDICATOR_CODE_PREFIX + crba_data_dictionary_indicator.INDICATOR_NAME.apply(\n",
    "    lambda x: utils.create_ind_code(x)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, inspect\n",
    "\n",
    "extractors = { \n",
    "    cls.type: cls for name, cls in inspect.getmembers(\n",
    "        importlib.import_module(\"extract\"), \n",
    "        inspect.isclass\n",
    "    ) if hasattr(cls, 'type')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Staging (pre-processing) to create exceptional indicatorsÂ´ raw data \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 98 unique values.\n",
      "The column geoAreaName has 98 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 599 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 95 unique values.\n",
      "The column geoAreaName has 95 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 84 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 87 unique values.\n",
      "The column geoAreaName has 87 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 88 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 110 unique values.\n",
      "The column geoAreaName has 110 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 79 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 183 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column ENVCAUSE has 1 unique values.\n",
      "The column Display Value has 374 unique values.\n",
      "The column Numeric has 547 unique values.\n",
      "The column Low has 547 unique values.\n",
      "The column High has 547 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column REF_AREA:Geographic area has 202 unique values.\n",
      "The column INDICATOR:Indicator has 1 unique values.\n",
      "The column RESIDENCE:Residence has 1 unique values.\n",
      "The column SEX:Sex has 1 unique values.\n",
      "The column AGE:Current age has 1 unique values.\n",
      "The column TIME_PERIOD:Time period has 1 unique values.\n",
      "The column OBS_VALUE:Observation Value has 185 unique values.\n",
      "The column UNIT_MEASURE:Unit of measure has 1 unique values.\n",
      "The column UNIT_MULTIPLIER:Unit multiplier has 1 unique values.\n",
      "The column SOURCE_LINK:Citation of or link to the data source has 1 unique values.\n",
      "The column SERIES_FOOTNOTE:Series footnote has 1 unique values.\n",
      "The column OBS_STATUS:Observation Status has 1 unique values.\n",
      "The column OBS_CONF:Observation confidentaility has 1 unique values.\n",
      "The column DATA_SOURCE:Data Source has 1 unique values.\n",
      "The column COVERAGE_TIME:The period of time for which data are provided has 1 unique values.\n",
      "The column FREQ_COLL:Time interval at which the source data are collected has 1 unique values.\n",
      "The column TIME_PERIOD_METHOD:Time period activity related to when the data are collected has 1 unique values.\n",
      "The column OBS_FOOTNOTE:Observation footnote has 1 unique values.\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing of exceptional indicators, which require extra transformation\n",
    "# Important: File requires having filepaths from above defined and pandas already imported\n",
    "with open(data_in / 'staging_create_raw_data.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract - Transform - Load Loop\n",
    "## API sources\n",
    "### CSV API sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-155 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column CountryISO has 81 unique values.\n",
      "The column Country has 83 unique values.\n",
      "The column Sector has 2 unique values.\n",
      "The column Region has 7 unique values.\n",
      "The column ElementNumber has 205 unique values.\n",
      "The column ElementType has 8 unique values.\n",
      "The column ElementName has 205 unique values.\n",
      "The column Score has 102 unique values.\n",
      "There was a problem with extraction of source S-155 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-155 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "      COUNTRY_NAME DIM_SECTOR  TIME_PERIOD  \\\n",
      "0      Afghanistan     Mining         2017   \n",
      "1      Afghanistan     Mining         2017   \n",
      "2      Afghanistan     Mining         2017   \n",
      "3      Afghanistan     Mining         2017   \n",
      "4      Afghanistan     Mining         2017   \n",
      "...            ...        ...          ...   \n",
      "18240     Zimbabwe     Mining         2017   \n",
      "18241     Zimbabwe     Mining         2017   \n",
      "18242     Zimbabwe     Mining         2017   \n",
      "18243     Zimbabwe     Mining         2017   \n",
      "18244     Zimbabwe     Mining         2017   \n",
      "\n",
      "                                   DIM_ELEMENT_TYPE RAW_OBS_VALUE  \\\n",
      "0                    2017 RESOURCE GOVERNANCE INDEX            34   \n",
      "1                                 VALUE REALIZATION            58   \n",
      "2                                         LICENSING            46   \n",
      "3                               RESERVES DISCLOSURE            57   \n",
      "4                        Reserves volume disclosure           100   \n",
      "...                                             ...           ...   \n",
      "18240   POLITICAL STABILITY AND ABSENCE OF VIOLENCE            49   \n",
      "18241                                     OPEN DATA             8   \n",
      "18242                           OPEN DATA INVENTORY            20   \n",
      "18243                           OPEN DATA BAROMETER             4   \n",
      "18244                               OPEN DATA INDEX             2   \n",
      "\n",
      "      COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0                AF           AFG  \n",
      "1                AF           AFG  \n",
      "2                AF           AFG  \n",
      "3                AF           AFG  \n",
      "4                AF           AFG  \n",
      "...             ...           ...  \n",
      "18240            ZW           ZWE  \n",
      "18241            ZW           ZWE  \n",
      "18242            ZW           ZWE  \n",
      "18243            ZW           ZWE  \n",
      "18244            ZW           ZWE  \n",
      "\n",
      "[18245 rows x 7 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 17950 rows in the dataframe and 0.64% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    17950.000000\n",
      "mean      2017.019220\n",
      "std          0.239362\n",
      "min       2017.000000\n",
      "25%       2017.000000\n",
      "50%       2017.000000\n",
      "75%       2017.000000\n",
      "max       2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-156 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column CountryISO has 81 unique values.\n",
      "The column Country has 83 unique values.\n",
      "The column Sector has 2 unique values.\n",
      "The column Region has 7 unique values.\n",
      "The column ElementNumber has 205 unique values.\n",
      "The column ElementType has 8 unique values.\n",
      "The column ElementName has 205 unique values.\n",
      "The column Score has 102 unique values.\n",
      "There was a problem with extraction of source S-156 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-156 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "      COUNTRY_NAME DIM_SECTOR  TIME_PERIOD  \\\n",
      "0      Afghanistan     Mining         2017   \n",
      "1      Afghanistan     Mining         2017   \n",
      "2      Afghanistan     Mining         2017   \n",
      "3      Afghanistan     Mining         2017   \n",
      "4      Afghanistan     Mining         2017   \n",
      "...            ...        ...          ...   \n",
      "18240     Zimbabwe     Mining         2017   \n",
      "18241     Zimbabwe     Mining         2017   \n",
      "18242     Zimbabwe     Mining         2017   \n",
      "18243     Zimbabwe     Mining         2017   \n",
      "18244     Zimbabwe     Mining         2017   \n",
      "\n",
      "                                   DIM_ELEMENT_TYPE RAW_OBS_VALUE  \\\n",
      "0                    2017 RESOURCE GOVERNANCE INDEX            34   \n",
      "1                                 VALUE REALIZATION            58   \n",
      "2                                         LICENSING            46   \n",
      "3                               RESERVES DISCLOSURE            57   \n",
      "4                        Reserves volume disclosure           100   \n",
      "...                                             ...           ...   \n",
      "18240   POLITICAL STABILITY AND ABSENCE OF VIOLENCE            49   \n",
      "18241                                     OPEN DATA             8   \n",
      "18242                           OPEN DATA INVENTORY            20   \n",
      "18243                           OPEN DATA BAROMETER             4   \n",
      "18244                               OPEN DATA INDEX             2   \n",
      "\n",
      "      COUNTRY_ISO_2 COUNTRY_ISO_3  \n",
      "0                AF           AFG  \n",
      "1                AF           AFG  \n",
      "2                AF           AFG  \n",
      "3                AF           AFG  \n",
      "4                AF           AFG  \n",
      "...             ...           ...  \n",
      "18240            ZW           ZWE  \n",
      "18241            ZW           ZWE  \n",
      "18242            ZW           ZWE  \n",
      "18243            ZW           ZWE  \n",
      "18244            ZW           ZWE  \n",
      "\n",
      "[18245 rows x 7 columns]\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 17950 rows in the dataframe and 0.64% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    17950.000000\n",
      "mean      2017.019220\n",
      "std          0.239362\n",
      "min       2017.000000\n",
      "25%       2017.000000\n",
      "50%       2017.000000\n",
      "75%       2017.000000\n",
      "max       2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# CSV sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    #(crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (ILO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNESCO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WHO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNICEF)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (NRGI)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "# Delete again (only for temporary debugging 12.11.20)\n",
    "# # # # # # # # # # # # \n",
    "api_sources = api_sources[(api_sources[\"SOURCE_ID\"] == 'S-155') | \n",
    "(api_sources[\"SOURCE_ID\"] == 'S-156')]\n",
    "#api_sources = api_sources[(api_sources[\"SOURCE_ID\"] == 'S-97')]\n",
    "\n",
    "# define emty dataframe\n",
    "combined_cleansed_csv = pd.DataFrame()\n",
    "combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Extraction section\n",
    "    # try:\n",
    "        # Extract data\n",
    "    # print(row[\"ENDPOINT_URL\"]+\"continue here\")\n",
    "    dataframe = extract.CSVExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "    \n",
    "    # Save raw data\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\"\n",
    "        )\n",
    "    \n",
    "    # except:\n",
    "    print(\"There was a problem with extraction of source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().extract_year_from_timeperiod(\n",
    "        dataframe=dataframe,\n",
    "        year_col=\"TIME_PERIOD\",\n",
    "        time_cov_col=\"COVERAGE_TIME\"\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON API sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-23 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 3190 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 51 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Activity has 3 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-23 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 747 rows in the dataframe and 16.87% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     747.00000\n",
      "mean     2016.26506\n",
      "std         3.17993\n",
      "min      2004.00000\n",
      "25%      2014.00000\n",
      "50%      2017.00000\n",
      "75%      2018.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-23 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 3190 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 51 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Activity has 3 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-23 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_SECTOR\n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 747 rows in the dataframe and 16.87% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     747.00000\n",
      "mean     2016.26506\n",
      "std         3.17993\n",
      "min      2004.00000\n",
      "25%      2014.00000\n",
      "50%      2017.00000\n",
      "75%      2018.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-24 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 83 unique values.\n",
      "The column geoAreaName has 83 unique values.\n",
      "The column timePeriodStart has 10 unique values.\n",
      "The column value has 215 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 4 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 5 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-24 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 361 rows in the dataframe and 31.02% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     361.000000\n",
      "mean     2015.927978\n",
      "std         3.379730\n",
      "min      2010.000000\n",
      "25%      2013.000000\n",
      "50%      2016.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-61 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 142 unique values.\n",
      "The column geoAreaName has 142 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 375 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-61 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 27.69% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.743590\n",
      "std         2.798361\n",
      "min      2008.000000\n",
      "25%      2016.000000\n",
      "50%      2017.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-62 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 208 unique values.\n",
      "The column geoAreaName has 208 unique values.\n",
      "The column timePeriodStart has 29 unique values.\n",
      "The column value has 86 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 11 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-62 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 15.9% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.271795\n",
      "std         4.545642\n",
      "min      1992.000000\n",
      "25%      2014.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-71 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 113 unique values.\n",
      "The column geoAreaName has 113 unique values.\n",
      "The column timePeriodStart has 4 unique values.\n",
      "The column value has 66 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-71 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 60.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2018.594872\n",
      "std         1.843063\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-78 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-78 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-79 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-79 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-80 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-80 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-81 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 75 unique values.\n",
      "The column geoAreaName has 75 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 340 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 79 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 83 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-81 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 255 rows in the dataframe and 52.94% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     255.000000\n",
      "mean     2015.921569\n",
      "std         4.924002\n",
      "min      2002.000000\n",
      "25%      2012.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-125 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 58 unique values.\n",
      "The column geoAreaName has 58 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 62 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 13 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 2 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-125 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 206 rows in the dataframe and 69.42% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     206.000000\n",
      "mean     2018.315534\n",
      "std         3.078240\n",
      "min      2005.000000\n",
      "25%      2017.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-129 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4129 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-129 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-130 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4121 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-130 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-160 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 211 unique values.\n",
      "The column geoAreaName has 211 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 107 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-160 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 6.15% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2016.246154\n",
      "std         0.963736\n",
      "min      2016.000000\n",
      "25%      2016.000000\n",
      "50%      2016.000000\n",
      "75%      2016.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-161 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 294 unique values.\n",
      "The column geoAreaName has 294 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 51 unique values.\n",
      "The column valueType has 2 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 111 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-161 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 0.51% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.000000\n",
      "mean     2015.025510\n",
      "std         0.357143\n",
      "min      2015.000000\n",
      "25%      2015.000000\n",
      "50%      2015.000000\n",
      "75%      2015.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-166 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 191 unique values.\n",
      "The column date has 17 unique values.\n",
      "The column value has 76 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 191 unique values.\n",
      "The column country.value has 213 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-166 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 217 rows in the dataframe and 5.07% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     217.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "WARNING: There are 8 duplicate rows in the cleansed dataframe. Apart from soure S-166, this should not be the case. Check if you have mapped all columns (specifically the dimensions) and values. Now dropping duplicate rows and returning dataframe without duplicates.\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-183 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 82 unique values.\n",
      "The column geoAreaName has 82 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 90 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-183 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 359 rows in the dataframe and 31.48% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     359.000000\n",
      "mean     2018.679666\n",
      "std         1.126325\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-184 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 1193 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-184 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     469.000000\n",
      "mean     2017.147122\n",
      "std         2.662195\n",
      "min      2007.000000\n",
      "25%      2016.000000\n",
      "50%      2018.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-198 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 181 unique values.\n",
      "The column geoAreaName has 181 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 2025 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-198 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 10.77% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2015.589744\n",
      "std         4.092475\n",
      "min      2000.000000\n",
      "25%      2015.000000\n",
      "50%      2017.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-202 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 18 unique values.\n",
      "The column value has 631 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 150 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 157 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Quantile has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-202 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_QUANTILE\n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 303 rows in the dataframe and 28.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     303.000000\n",
      "mean     2013.676568\n",
      "std         5.114679\n",
      "min      1999.000000\n",
      "25%      2010.000000\n",
      "50%      2014.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-203 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 65 unique values.\n",
      "The column geoAreaName has 65 unique values.\n",
      "The column timePeriodStart has 19 unique values.\n",
      "The column value has 3381 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 46 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 128 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Type of occupation has 24 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-203 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "\n",
      " Successfully mapped values of column: DIM_OCU_TYPE\n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 2294 rows in the dataframe and 5.71% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    2294.000000\n",
      "mean     2013.275065\n",
      "std         4.840024\n",
      "min      2001.000000\n",
      "25%      2006.000000\n",
      "50%      2014.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-204 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 127 unique values.\n",
      "The column geoAreaName has 127 unique values.\n",
      "The column timePeriodStart has 20 unique values.\n",
      "The column value has 748 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 3 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-204 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 1075 rows in the dataframe and 7.91% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count    1075.000000\n",
      "mean     2014.181395\n",
      "std         3.646843\n",
      "min      2003.000000\n",
      "25%      2012.000000\n",
      "50%      2015.000000\n",
      "75%      2017.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-212 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 142 unique values.\n",
      "The column date has 67 unique values.\n",
      "The column value has 1088 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 146 unique values.\n",
      "The column country.value has 150 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-212 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 100.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2054.871795\n",
      "std        39.772017\n",
      "min      2020.000000\n",
      "25%      2020.000000\n",
      "50%      2020.000000\n",
      "75%      2100.000000\n",
      "max      2100.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-214 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 196 unique values.\n",
      "The column geoAreaName has 196 unique values.\n",
      "The column timePeriodStart has 13 unique values.\n",
      "The column value has 119 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 45 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 35 unique values.\n",
      "The column attributes.Nature has 2 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 5 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-214 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 10.26% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.917949\n",
      "std         3.259156\n",
      "min      2006.000000\n",
      "25%      2013.500000\n",
      "50%      2015.000000\n",
      "75%      2017.500000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-216 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 81 unique values.\n",
      "The column geoAreaName has 81 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 17 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "The column dimensions.Policy instruments has 5 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-216 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "\n",
      " Successfully mapped values of column: DIM_POLICY_TYPE\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 280 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     280.000000\n",
      "mean     2019.432143\n",
      "std         0.496261\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-217 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 2 unique values.\n",
      "The column indicator has 2 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 83 unique values.\n",
      "The column geoAreaName has 83 unique values.\n",
      "The column timePeriodStart has 10 unique values.\n",
      "The column value has 660 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-217 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 265 rows in the dataframe and 47.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     265.000000\n",
      "mean     2019.441509\n",
      "std         0.581740\n",
      "min      2017.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-218 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 86 unique values.\n",
      "The column geoAreaName has 86 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 8 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-218 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.594872\n",
      "std         0.492180\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-219 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4166 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-219 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-220 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4232 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-220 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 1.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-222 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 292 unique values.\n",
      "The column geoAreaName has 292 unique values.\n",
      "The column timePeriodStart has 6 unique values.\n",
      "The column value has 1725 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1725 unique values.\n",
      "The column lowerBound has 1725 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 7 unique values.\n",
      "The column attributes.Nature has 4 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column attributes.Observation Status has 3 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 3 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-222 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "\n",
      " Successfully mapped values of column: DIM_SEX\n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_AGE_GROUP\n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 586 rows in the dataframe and 0.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     586.000000\n",
      "mean     2018.013652\n",
      "std         0.130028\n",
      "min      2018.000000\n",
      "25%      2018.000000\n",
      "50%      2018.000000\n",
      "75%      2018.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-223 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4244 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-223 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-224 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 222 unique values.\n",
      "The column geoAreaName has 222 unique values.\n",
      "The column timePeriodStart has 2 unique values.\n",
      "The column value has 61 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-224 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 4.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.00000\n",
      "mean     2019.94898\n",
      "std         0.50378\n",
      "min      2015.00000\n",
      "25%      2020.00000\n",
      "50%      2020.00000\n",
      "75%      2020.00000\n",
      "max      2020.00000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-225 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 226 unique values.\n",
      "The column geoAreaName has 226 unique values.\n",
      "The column timePeriodStart has 2 unique values.\n",
      "The column value has 69 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-225 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 196 rows in the dataframe and 4.59% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     196.000000\n",
      "mean     2019.846939\n",
      "std         0.863529\n",
      "min      2015.000000\n",
      "25%      2020.000000\n",
      "50%      2020.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-226 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column countryiso3code has 209 unique values.\n",
      "The column date has 21 unique values.\n",
      "The column value has 4139 unique values.\n",
      "The column unit has 1 unique values.\n",
      "The column obs_status has 1 unique values.\n",
      "The column decimal has 1 unique values.\n",
      "The column indicator.id has 1 unique values.\n",
      "The column indicator.value has 1 unique values.\n",
      "The column country.id has 214 unique values.\n",
      "The column country.value has 214 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-226 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "Values of column: DIM_SDG_INDICATOR couldn't be mapped. If column DIM_SDG_INDICATOR is present, there is an error with the code. \n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_REP_TYPE couldn't be mapped. If column DIM_REP_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "Values of column: ATTR_UNIT_MEASURE couldn't be mapped. If column ATTR_UNIT_MEASURE is present, there is an error with the code. \n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2019.0\n",
      "std         0.0\n",
      "min      2019.0\n",
      "25%      2019.0\n",
      "50%      2019.0\n",
      "75%      2019.0\n",
      "max      2019.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-227 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 93 unique values.\n",
      "The column geoAreaName has 93 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 40 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-227 \n",
      "\n",
      "\n",
      " Calling function 'extract_who_raw_data'...\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'extract_year_from_timeperiod'...\n",
      "\n",
      " Calling function 'retrieve_latest_observation'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'map_values'...\n",
      "Values of column: DIM_SEX couldn't be mapped. If column DIM_SEX is present, there is an error with the code. \n",
      "Values of column: DIM_EDU_LEVEL couldn't be mapped. If column DIM_EDU_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AGE couldn't be mapped. If column DIM_AGE is present, there is an error with the code. \n",
      "Values of column: DIM_AGE_GROUP couldn't be mapped. If column DIM_AGE_GROUP is present, there is an error with the code. \n",
      "Values of column: DIM_MANAGEMENT_LEVEL couldn't be mapped. If column DIM_MANAGEMENT_LEVEL is present, there is an error with the code. \n",
      "Values of column: DIM_AREA_TYPE couldn't be mapped. If column DIM_AREA_TYPE is present, there is an error with the code. \n",
      "Values of column: DIM_QUANTILE couldn't be mapped. If column DIM_QUANTILE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_SDG_INDICATOR\n",
      "Values of column: DIM_OCU_TYPE couldn't be mapped. If column DIM_OCU_TYPE is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: DIM_REP_TYPE\n",
      "Values of column: DIM_SECTOR couldn't be mapped. If column DIM_SECTOR is present, there is an error with the code. \n",
      "\n",
      " Successfully mapped values of column: ATTR_UNIT_MEASURE\n",
      "Values of column: DIM_POLICY_TYPE couldn't be mapped. If column DIM_POLICY_TYPE is present, there is an error with the code. \n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 381 rows in the dataframe and 26.77% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     381.000000\n",
      "mean     2018.622047\n",
      "std         1.087700\n",
      "min      2015.000000\n",
      "25%      2018.000000\n",
      "50%      2019.000000\n",
      "75%      2020.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "WARNING: There are 186 duplicate rows in the cleansed dataframe. Apart from soure S-166, this should not be the case. Check if you have mapped all columns (specifically the dimensions) and values. Now dropping duplicate rows and returning dataframe without duplicates.\n"
     ]
    }
   ],
   "source": [
    "# JSON sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (SDG)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WB)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # #\n",
    "# Delete again (only for temporary debugging 12.11.20)\n",
    "# # # # # # # # # # # # \n",
    "\"\"\"\n",
    "api_sources = api_sources[\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-222') | \n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-223') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-224') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-225') |\n",
    "    (api_sources[\"SOURCE_ID\"] == 'S-226')\n",
    "]\n",
    "\"\"\"\n",
    "#combined_cleansed_csv = pd.DataFrame()\n",
    "#combined_normalized_csv = pd.DataFrame()\n",
    "##############################################\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    #try:\n",
    "    # Extract data \n",
    "    dataframe = extract.JSONExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "    # except:\n",
    "        #print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing in \n",
    "    dataframe = cleanse.Cleanser().extract_who_raw_data(\n",
    "        raw_data=dataframe,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        display_value_col=\"Display Value\"\n",
    "    )\n",
    "    \n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    # print(dataframe)\n",
    "\n",
    "    dataframe = cleanse.Cleanser().extract_year_from_timeperiod(\n",
    "        dataframe=dataframe,\n",
    "        year_col=\"TIME_PERIOD\",\n",
    "        time_cov_col=\"COVERAGE_TIME\"\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().retrieve_latest_observation(\n",
    "        renamed_data=dataframe,\n",
    "        dim_cols = sdmx_df_columns_dims,\n",
    "        country_cols = sdmx_df_columns_country,\n",
    "        time_cols = sdmx_df_columns_time,\n",
    "        attr_cols=sdmx_df_columns_attr,\n",
    "    )\n",
    "\n",
    "    # print(dataframe)\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().map_values(\n",
    "        cleansed_data = dataframe,\n",
    "        value_mapping_dict = value_mapper\n",
    "    )\n",
    "    \n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"],\n",
    "        na_encodings = row[\"NA_ENCODING\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Sources\n",
    "### UN Treaty Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-4 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 35 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a), Succession(d) has 172 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-4 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-31 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 68 unique values.\n",
      "The column Signature, Succession to signature(d) has 35 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 55 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-31 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-84 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 188 unique values.\n",
      "The column Signature has 80 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Formal confirmation(c), Accession(a), Succession(d) has 158 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-84 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-105 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2, 3, 4 has 193 unique values.\n",
      "The column Signature has 4 unique values.\n",
      "The column Definitive signature(s), Acceptance(A) has 177 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-105 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-115 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 185 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 173 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-115 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-141 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 21 unique values.\n",
      "The column Approval(AA), Acceptance(A), Accession(a), Succession(d), Ratification has 180 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-141 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-142 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 17 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 116 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-142 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-143 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature has 13 unique values.\n",
      "The column Approval(AA), Formal confirmation(c), Acceptance(A), Accession(a), Succession(d), Ratification has 184 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-143 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-144 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 190 unique values.\n",
      "The column Signature, Succession to signature(d) has 42 unique values.\n",
      "The column Ratification, Acceptance(A), Approval(AA), Accession(a) has 180 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-144 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-145 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature has 5 unique values.\n",
      "The column Ratification, Accession(a), Acceptance(A), Approval(AA) has 45 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-145 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-162 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant 2 has 175 unique values.\n",
      "The column Signature has 64 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 170 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-162 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-171 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 45 unique values.\n",
      "The column Signature, Succession to signature(d) has 17 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 37 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-171 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-173 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 180 unique values.\n",
      "The column Signature has 62 unique values.\n",
      "The column Ratification, Accession(a), Succession(d) has 162 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-173 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-182 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 80 unique values.\n",
      "The column Signature has 36 unique values.\n",
      "The column Definitive signature(s), Ratification, Acceptance(A), Approval(AA), Accession(a) has 50 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-182 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-191 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 197 unique values.\n",
      "The column Signature has 59 unique values.\n",
      "The column Ratification, Acceptance(A), Accession(a), Succession(d) has 185 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-191 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-192 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Participant has 64 unique values.\n",
      "The column Signature has 24 unique values.\n",
      "The column Accession(a), Ratification has 46 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-192 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_ilo_un_treaty_data'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# UN Treaty HTML sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"UN Treaties\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    dataframe = extract.HTMLExtractor().extract(url = row[\"ADDRESS\"])\n",
    "    \n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Cleansing\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    # Cleansing\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_ilo_un_treaty_data(\n",
    "        dataframe = dataframe,\n",
    "        treaty_source_body = row[\"SOURCE_BODY\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "    \n",
    "    # Normalizing section\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "    \n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "source": [
    "## Other sources\n",
    "### WPA sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-8 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  admiss_age  TIME_PERIOD\n",
      "0   AFG         5.0         2019\n",
      "1   ALB         5.0         2019\n",
      "2   DZA         5.0         2019\n",
      "3   AND         5.0         2019\n",
      "4   AGO         5.0         2019\n",
      "5   ATG         3.0         2019\n",
      "6   ARG         5.0         2019\n",
      "7   ARM         5.0         2019\n",
      "8   AUS         4.0         2019\n",
      "9   AUT         4.0         2019\n",
      "10  AZE         4.0         2019\n",
      "11  BHS         5.0         2019\n",
      "12  BHR         4.0         2019\n",
      "13  BGD         3.0         2019\n",
      "14  BRB         5.0         2019\n",
      "15  BLR         5.0         2019\n",
      "16  BEL         4.0         2019\n",
      "17  BLZ         3.0         2019\n",
      "18  BEN         3.0         2019\n",
      "19  BTN         2.0         2019\n",
      "20  BOL         3.0         2019\n",
      "21  BIH         4.0         2019\n",
      "22  BWA         4.0         2019\n",
      "23  BRA         5.0         2019\n",
      "24  BRN         5.0         2019\n",
      "25  BGR         5.0         2019\n",
      "26  BFA         5.0         2019\n",
      "27  BDI         5.0         2019\n",
      "28  KHM         4.0         2019\n",
      "29  CMR         3.0         2019\n",
      "There was an issue with source S-8\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-8 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-8 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4.  2.  1. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-9 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  light_age  TIME_PERIOD\n",
      "0   AFG        5.0         2019\n",
      "1   ALB        5.0         2019\n",
      "2   DZA        3.0         2019\n",
      "3   AND        4.0         2019\n",
      "4   AGO        4.0         2019\n",
      "5   ATG        1.0         2019\n",
      "6   ARG        4.0         2019\n",
      "7   ARM        4.0         2019\n",
      "8   AUS        3.0         2019\n",
      "9   AUT        3.0         2019\n",
      "10  AZE        4.0         2019\n",
      "11  BHS        1.0         2019\n",
      "12  BHR        5.0         2019\n",
      "13  BGD        2.0         2019\n",
      "14  BRB        5.0         2019\n",
      "15  BLR        4.0         2019\n",
      "16  BEL        5.0         2019\n",
      "17  BLZ        2.0         2019\n",
      "18  BEN        2.0         2019\n",
      "19  BTN        3.0         2019\n",
      "20  BOL        2.0         2019\n",
      "21  BIH        5.0         2019\n",
      "22  BWA        4.0         2019\n",
      "23  BRA        5.0         2019\n",
      "24  BRN        4.0         2019\n",
      "25  BGR        5.0         2019\n",
      "26  BFA        3.0         2019\n",
      "27  BDI        2.0         2019\n",
      "28  KHM        2.0         2019\n",
      "29  CMR        4.0         2019\n",
      "There was an issue with source S-9\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-9 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-9 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4.  1.  2. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-10 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  edu_comp_begsec  TIME_PERIOD\n",
      "0   AFG              5.0         2014\n",
      "1   ALB              5.0         2014\n",
      "2   DZA              5.0         2014\n",
      "3   AND              5.0         2014\n",
      "4   AGO              1.0         2014\n",
      "5   ATG              NaN         2014\n",
      "6   ARG              5.0         2014\n",
      "7   ARM              5.0         2014\n",
      "8   AUS              5.0         2014\n",
      "9   AUT              5.0         2014\n",
      "10  AZE              5.0         2014\n",
      "11  BHS              NaN         2014\n",
      "12  BHR              5.0         2014\n",
      "13  BGD              1.0         2014\n",
      "14  BRB              5.0         2014\n",
      "15  BLR              5.0         2014\n",
      "16  BEL              5.0         2014\n",
      "17  BLZ              5.0         2014\n",
      "18  BEN              1.0         2014\n",
      "19  BTN              1.0         2014\n",
      "20  BOL              5.0         2014\n",
      "21  BIH              5.0         2014\n",
      "22  BWA              1.0         2014\n",
      "23  BRA              5.0         2014\n",
      "24  BRN              5.0         2014\n",
      "25  BGR              5.0         2014\n",
      "26  BFA              5.0         2014\n",
      "27  BDI              1.0         2014\n",
      "28  KHM              5.0         2014\n",
      "29  CMR              1.0         2014\n",
      "There was an issue with source S-10\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-10 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-10 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-13 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  cl_haz_minage  TIME_PERIOD\n",
      "0   AFG           18.0         2014\n",
      "1   ALB           18.0         2014\n",
      "2   DZA           18.0         2014\n",
      "3   AND           18.0         2014\n",
      "4   AGO            NaN         2014\n",
      "5   ATG           16.0         2014\n",
      "6   ARG           18.0         2014\n",
      "7   ARM           18.0         2014\n",
      "8   AUS            0.0         2014\n",
      "9   AUT           18.0         2014\n",
      "10  AZE           18.0         2014\n",
      "11  BHS           18.0         2014\n",
      "12  BHR           16.0         2014\n",
      "13  BGD           18.0         2014\n",
      "14  BRB           16.0         2014\n",
      "15  BLR           18.0         2014\n",
      "16  BEL           18.0         2014\n",
      "17  BLZ           15.0         2014\n",
      "18  BEN           18.0         2014\n",
      "19  BTN           18.0         2014\n",
      "20  BOL           18.0         2014\n",
      "21  BIH           18.0         2014\n",
      "22  BWA           18.0         2014\n",
      "23  BRA           18.0         2014\n",
      "24  BRN           18.0         2014\n",
      "25  BGR           18.0         2014\n",
      "26  BFA           18.0         2014\n",
      "27  BDI           16.0         2014\n",
      "28  KHM           18.0         2014\n",
      "29  CMR           18.0         2014\n",
      "There was an issue with source S-13\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-13 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-13 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[18. nan 16.  0. 15. 17. 14.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-36 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  minwage_leg  TIME_PERIOD\n",
      "0   AFG          5.0         2014\n",
      "1   ALB          5.0         2014\n",
      "2   DZA          5.0         2014\n",
      "3   AND          5.0         2014\n",
      "4   AGO          5.0         2014\n",
      "5   ATG          5.0         2014\n",
      "6   ARG          5.0         2014\n",
      "7   ARM          5.0         2014\n",
      "8   AUS          5.0         2014\n",
      "9   AUT          5.0         2014\n",
      "10  AZE          5.0         2014\n",
      "11  BHS          5.0         2014\n",
      "12  BHR          1.0         2014\n",
      "13  BGD          5.0         2014\n",
      "14  BRB          5.0         2014\n",
      "15  BLR          5.0         2014\n",
      "16  BEL          3.0         2014\n",
      "17  BLZ          5.0         2014\n",
      "18  BEN          5.0         2014\n",
      "19  BTN          5.0         2014\n",
      "20  BOL          5.0         2014\n",
      "21  BIH          3.0         2014\n",
      "22  BWA          5.0         2014\n",
      "23  BRA          5.0         2014\n",
      "24  BRN          1.0         2014\n",
      "25  BGR          5.0         2014\n",
      "26  BFA          5.0         2014\n",
      "27  BDI          5.0         2014\n",
      "28  KHM          5.0         2014\n",
      "29  CMR          5.0         2014\n",
      "There was an issue with source S-36\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-36 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-36 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-40 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  paid_anlv  TIME_PERIOD\n",
      "0   AFG        5.0         2019\n",
      "1   ALB        5.0         2019\n",
      "2   DZA        5.0         2019\n",
      "3   AND        5.0         2019\n",
      "4   AGO        5.0         2019\n",
      "5   ATG        3.0         2019\n",
      "6   ARG        3.0         2019\n",
      "7   ARM        5.0         2019\n",
      "8   AUS        5.0         2019\n",
      "9   AUT        5.0         2019\n",
      "10  AZE        5.0         2019\n",
      "11  BHS        3.0         2019\n",
      "12  BHR        5.0         2019\n",
      "13  BGD        3.0         2019\n",
      "14  BRB        4.0         2019\n",
      "15  BLR        5.0         2019\n",
      "16  BEL        5.0         2019\n",
      "17  BLZ        3.0         2019\n",
      "18  BEN        5.0         2019\n",
      "19  BTN        4.0         2019\n",
      "20  BOL        NaN         2019\n",
      "21  BIH        4.0         2019\n",
      "22  BWA        4.0         2019\n",
      "23  BRA        5.0         2019\n",
      "24  BRN        2.0         2019\n",
      "25  BGR        5.0         2019\n",
      "26  BFA        5.0         2019\n",
      "27  BDI        4.0         2019\n",
      "28  KHM        4.0         2019\n",
      "29  CMR        4.0         2019\n",
      "There was an issue with source S-40\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-40 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-40 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  3.  4. nan  2.  1.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-41 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  sickleave_duration  TIME_PERIOD\n",
      "0   AFG                 2.0         2019\n",
      "1   ALB                 5.0         2019\n",
      "2   DZA                 5.0         2019\n",
      "3   AND                 5.0         2019\n",
      "4   AGO                 1.0         2019\n",
      "5   ATG                 5.0         2019\n",
      "6   ARG                 4.0         2019\n",
      "7   ARM                 5.0         2019\n",
      "8   AUS                 5.0         2019\n",
      "9   AUT                 5.0         2019\n",
      "10  AZE                 5.0         2019\n",
      "11  BHS                 5.0         2019\n",
      "12  BHR                 3.0         2019\n",
      "13  BGD                 2.0         2019\n",
      "14  BRB                 5.0         2019\n",
      "15  BLR                 NaN         2019\n",
      "16  BEL                 5.0         2019\n",
      "17  BLZ                 5.0         2019\n",
      "18  BEN                 5.0         2019\n",
      "19  BTN                 2.0         2019\n",
      "20  BOL                 5.0         2019\n",
      "21  BIH                 5.0         2019\n",
      "22  BWA                 2.0         2019\n",
      "23  BRA                 5.0         2019\n",
      "24  BRN                 3.0         2019\n",
      "25  BGR                 5.0         2019\n",
      "26  BFA                 4.0         2019\n",
      "27  BDI                 4.0         2019\n",
      "28  KHM                 NaN         2019\n",
      "29  CMR                 3.0         2019\n",
      "There was an issue with source S-41\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-41 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-41 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  5.  1.  4.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-42 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  promdemo_sex  TIME_PERIOD\n",
      "0   AFG             1         2020\n",
      "1   ALB             5         2020\n",
      "2   DZA             4         2020\n",
      "3   AND             5         2020\n",
      "4   AGO             5         2020\n",
      "5   ATG             5         2020\n",
      "6   ARG             5         2020\n",
      "7   ARM             4         2020\n",
      "8   AUS             5         2020\n",
      "9   AUT             5         2020\n",
      "10  AZE             5         2020\n",
      "11  BHS             5         2020\n",
      "12  BHR             4         2020\n",
      "13  BGD             1         2020\n",
      "14  BRB             1         2020\n",
      "15  BLR             4         2020\n",
      "16  BEL             5         2020\n",
      "17  BLZ             5         2020\n",
      "18  BEN             5         2020\n",
      "19  BTN             5         2020\n",
      "20  BOL             5         2020\n",
      "21  BIH             5         2020\n",
      "22  BWA             1         2020\n",
      "23  BRA             5         2020\n",
      "24  BRN             1         2020\n",
      "25  BGR             5         2020\n",
      "26  BFA             4         2020\n",
      "27  BDI             5         2020\n",
      "28  KHM             5         2020\n",
      "29  CMR             1         2020\n",
      "There was an issue with source S-42\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-42 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-42 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[1 5 4]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-43 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  pay_sex  TIME_PERIOD\n",
      "0   AFG        2         2020\n",
      "1   ALB        5         2020\n",
      "2   DZA        5         2020\n",
      "3   AND        4         2020\n",
      "4   AGO        5         2020\n",
      "5   ATG        4         2020\n",
      "6   ARG        5         2020\n",
      "7   ARM        5         2020\n",
      "8   AUS        3         2020\n",
      "9   AUT        5         2020\n",
      "10  AZE        5         2020\n",
      "11  BHS        5         2020\n",
      "12  BHR        4         2020\n",
      "13  BGD        5         2020\n",
      "14  BRB        1         2020\n",
      "15  BLR        3         2020\n",
      "16  BEL        5         2020\n",
      "17  BLZ        1         2020\n",
      "18  BEN        5         2020\n",
      "19  BTN        5         2020\n",
      "20  BOL        4         2020\n",
      "21  BIH        5         2020\n",
      "22  BWA        1         2020\n",
      "23  BRA        5         2020\n",
      "24  BRN        1         2020\n",
      "25  BGR        5         2020\n",
      "26  BFA        5         2020\n",
      "27  BDI        4         2020\n",
      "28  KHM        5         2020\n",
      "29  CMR        4         2020\n",
      "There was an issue with source S-43\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-43 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-43 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 4 3 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-44 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  sh_covered  TIME_PERIOD\n",
      "0   AFG         NaN         2020\n",
      "1   ALB         5.0         2020\n",
      "2   DZA         5.0         2020\n",
      "3   AND         5.0         2020\n",
      "4   AGO         5.0         2020\n",
      "5   ATG         1.0         2020\n",
      "6   ARG         5.0         2020\n",
      "7   ARM         5.0         2020\n",
      "8   AUS         5.0         2020\n",
      "9   AUT         5.0         2020\n",
      "10  AZE         5.0         2020\n",
      "11  BHS         5.0         2020\n",
      "12  BHR         1.0         2020\n",
      "13  BGD         3.0         2020\n",
      "14  BRB         1.0         2020\n",
      "15  BLR         1.0         2020\n",
      "16  BEL         5.0         2020\n",
      "17  BLZ         5.0         2020\n",
      "18  BEN         5.0         2020\n",
      "19  BTN         5.0         2020\n",
      "20  BOL         5.0         2020\n",
      "21  BIH         5.0         2020\n",
      "22  BWA         1.0         2020\n",
      "23  BRA         5.0         2020\n",
      "24  BRN         1.0         2020\n",
      "25  BGR         5.0         2020\n",
      "26  BFA         5.0         2020\n",
      "27  BDI         5.0         2020\n",
      "28  KHM         5.0         2020\n",
      "29  CMR         5.0         2020\n",
      "There was an issue with source S-44\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-44 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-44 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[nan  5.  1.  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.0\n",
      "mean     2020.0\n",
      "std         0.0\n",
      "min      2020.0\n",
      "25%      2020.0\n",
      "50%      2020.0\n",
      "75%      2020.0\n",
      "max      2020.0\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-45 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  fb_ccschsupp  TIME_PERIOD\n",
      "0   AFG           1.0         2014\n",
      "1   ALB           NaN         2014\n",
      "2   DZA           4.0         2014\n",
      "3   AND           1.0         2014\n",
      "4   AGO           1.0         2014\n",
      "5   ATG           1.0         2014\n",
      "6   ARG           3.0         2014\n",
      "7   ARM           1.0         2014\n",
      "8   AUS           4.0         2014\n",
      "9   AUT           3.0         2014\n",
      "10  AZE           4.0         2014\n",
      "11  BHS           1.0         2014\n",
      "12  BHR           1.0         2014\n",
      "13  BGD           1.0         2014\n",
      "14  BRB           1.0         2014\n",
      "15  BLR           1.0         2014\n",
      "16  BEL           1.0         2014\n",
      "17  BLZ           1.0         2014\n",
      "18  BEN           NaN         2014\n",
      "19  BTN           1.0         2014\n",
      "20  BOL           1.0         2014\n",
      "21  BIH           1.0         2014\n",
      "22  BWA           1.0         2014\n",
      "23  BRA           1.0         2014\n",
      "24  BRN           1.0         2014\n",
      "25  BGR           4.0         2014\n",
      "26  BFA           1.0         2014\n",
      "27  BDI           1.0         2014\n",
      "28  KHM           1.0         2014\n",
      "29  CMR           1.0         2014\n",
      "There was an issue with source S-45\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-45 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-45 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 1. nan  4.  3.  5.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-49 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  minwage_ppp  TIME_PERIOD\n",
      "0   AFG          4.0         2014\n",
      "1   ALB          5.0         2014\n",
      "2   DZA          5.0         2014\n",
      "3   AND          NaN         2014\n",
      "4   AGO          3.0         2014\n",
      "5   ATG          5.0         2014\n",
      "6   ARG          5.0         2014\n",
      "7   ARM          4.0         2014\n",
      "8   AUS          5.0         2014\n",
      "9   AUT          5.0         2014\n",
      "10  AZE          4.0         2014\n",
      "11  BHS          5.0         2014\n",
      "12  BHR          1.0         2014\n",
      "13  BGD          2.0         2014\n",
      "14  BRB          5.0         2014\n",
      "15  BLR          5.0         2014\n",
      "16  BEL          5.0         2014\n",
      "17  BLZ          5.0         2014\n",
      "18  BEN          3.0         2014\n",
      "19  BTN          4.0         2014\n",
      "20  BOL          4.0         2014\n",
      "21  BIH          5.0         2014\n",
      "22  BWA          4.0         2014\n",
      "23  BRA          5.0         2014\n",
      "24  BRN          1.0         2014\n",
      "25  BGR          5.0         2014\n",
      "26  BFA          3.0         2014\n",
      "27  BDI          2.0         2014\n",
      "28  KHM          2.0         2014\n",
      "29  CMR          3.0         2014\n",
      "There was an issue with source S-49\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-49 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-49 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[  4.   5.  nan   3.   1.   2. 999.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2014.061538\n",
      "std         0.606076\n",
      "min      2014.000000\n",
      "25%      2014.000000\n",
      "50%      2014.000000\n",
      "75%      2014.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-63 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  mtlv_job_protect  TIME_PERIOD\n",
      "0   AFG                 2         2019\n",
      "1   ALB                 5         2019\n",
      "2   DZA                 2         2019\n",
      "3   AND                 5         2019\n",
      "4   AGO                 5         2019\n",
      "5   ATG                 2         2019\n",
      "6   ARG                 5         2019\n",
      "7   ARM                 3         2019\n",
      "8   AUS                 5         2019\n",
      "9   AUT                 5         2019\n",
      "10  AZE                 2         2019\n",
      "11  BHS                 5         2019\n",
      "12  BHR                 5         2019\n",
      "13  BGD                 2         2019\n",
      "14  BRB                 5         2019\n",
      "15  BLR                 2         2019\n",
      "16  BEL                 5         2019\n",
      "17  BLZ                 5         2019\n",
      "18  BEN                 5         2019\n",
      "19  BTN                 2         2019\n",
      "20  BOL                 2         2019\n",
      "21  BIH                 5         2019\n",
      "22  BWA                 5         2019\n",
      "23  BRA                 5         2019\n",
      "24  BRN                 5         2019\n",
      "25  BGR                 5         2019\n",
      "26  BFA                 5         2019\n",
      "27  BDI                 5         2019\n",
      "28  KHM                 5         2019\n",
      "29  CMR                 5         2019\n",
      "There was an issue with source S-63\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-63 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-63 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 3 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-64 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  ptlv_job_protect  TIME_PERIOD\n",
      "0   AFG               2.0         2019\n",
      "1   ALB               1.0         2019\n",
      "2   DZA               2.0         2019\n",
      "3   AND               5.0         2019\n",
      "4   AGO               5.0         2019\n",
      "5   ATG               1.0         2019\n",
      "6   ARG               2.0         2019\n",
      "7   ARM               2.0         2019\n",
      "8   AUS               3.0         2019\n",
      "9   AUT               5.0         2019\n",
      "10  AZE               2.0         2019\n",
      "11  BHS               1.0         2019\n",
      "12  BHR               2.0         2019\n",
      "13  BGD               1.0         2019\n",
      "14  BRB               1.0         2019\n",
      "15  BLR               2.0         2019\n",
      "16  BEL               5.0         2019\n",
      "17  BLZ               1.0         2019\n",
      "18  BEN               2.0         2019\n",
      "19  BTN               2.0         2019\n",
      "20  BOL               2.0         2019\n",
      "21  BIH               2.0         2019\n",
      "22  BWA               1.0         2019\n",
      "23  BRA               5.0         2019\n",
      "24  BRN               1.0         2019\n",
      "25  BGR               5.0         2019\n",
      "26  BFA               1.0         2019\n",
      "27  BDI               2.0         2019\n",
      "28  KHM               1.0         2019\n",
      "29  CMR               1.0         2019\n",
      "There was an issue with source S-64\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-64 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-64 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  1.  5.  3. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-65 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  maternal_leave  TIME_PERIOD\n",
      "0   AFG               2         2019\n",
      "1   ALB               5         2019\n",
      "2   DZA               3         2019\n",
      "3   AND               3         2019\n",
      "4   AGO               2         2019\n",
      "5   ATG               2         2019\n",
      "6   ARG               2         2019\n",
      "7   ARM               5         2019\n",
      "8   AUS               3         2019\n",
      "9   AUT               5         2019\n",
      "10  AZE               5         2019\n",
      "11  BHS               2         2019\n",
      "12  BHR               2         2019\n",
      "13  BGD               3         2019\n",
      "14  BRB               2         2019\n",
      "15  BLR               5         2019\n",
      "16  BEL               4         2019\n",
      "17  BLZ               3         2019\n",
      "18  BEN               3         2019\n",
      "19  BTN               2         2019\n",
      "20  BOL               2         2019\n",
      "21  BIH               5         2019\n",
      "22  BWA               2         2019\n",
      "23  BRA               3         2019\n",
      "24  BRN               2         2019\n",
      "25  BGR               5         2019\n",
      "26  BFA               3         2019\n",
      "27  BDI               2         2019\n",
      "28  KHM               2         2019\n",
      "29  CMR               3         2019\n",
      "There was an issue with source S-65\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-65 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-65 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[2 5 3 4 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-66 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  maternal_min_wrr_ilo  TIME_PERIOD\n",
      "0   AFG                     5         2019\n",
      "1   ALB                     3         2019\n",
      "2   DZA                     5         2019\n",
      "3   AND                     5         2019\n",
      "4   AGO                     5         2019\n",
      "5   ATG                     3         2019\n",
      "6   ARG                     5         2019\n",
      "7   ARM                     2         2019\n",
      "8   AUS                     2         2019\n",
      "9   AUT                     2         2019\n",
      "10  AZE                     2         2019\n",
      "11  BHS                     5         2019\n",
      "12  BHR                     5         2019\n",
      "13  BGD                     5         2019\n",
      "14  BRB                     5         2019\n",
      "15  BLR                     3         2019\n",
      "16  BEL                     2         2019\n",
      "17  BLZ                     5         2019\n",
      "18  BEN                     5         2019\n",
      "19  BTN                     5         2019\n",
      "20  BOL                     2         2019\n",
      "21  BIH                     3         2019\n",
      "22  BWA                     3         2019\n",
      "23  BRA                     5         2019\n",
      "24  BRN                     5         2019\n",
      "25  BGR                     5         2019\n",
      "26  BFA                     5         2019\n",
      "27  BDI                     5         2019\n",
      "28  KHM                     3         2019\n",
      "29  CMR                     5         2019\n",
      "There was an issue with source S-66\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-66 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-66 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[5 3 2 4 1]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-67 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  paternal_leave  TIME_PERIOD\n",
      "0   AFG             2.0         2019\n",
      "1   ALB             1.0         2019\n",
      "2   DZA             2.0         2019\n",
      "3   AND             3.0         2019\n",
      "4   AGO             2.0         2019\n",
      "5   ATG             1.0         2019\n",
      "6   ARG             2.0         2019\n",
      "7   ARM             5.0         2019\n",
      "8   AUS             5.0         2019\n",
      "9   AUT             5.0         2019\n",
      "10  AZE             5.0         2019\n",
      "11  BHS             1.0         2019\n",
      "12  BHR             2.0         2019\n",
      "13  BGD             1.0         2019\n",
      "14  BRB             1.0         2019\n",
      "15  BLR             5.0         2019\n",
      "16  BEL             5.0         2019\n",
      "17  BLZ             1.0         2019\n",
      "18  BEN             2.0         2019\n",
      "19  BTN             2.0         2019\n",
      "20  BOL             2.0         2019\n",
      "21  BIH             2.0         2019\n",
      "22  BWA             1.0         2019\n",
      "23  BRA             2.0         2019\n",
      "24  BRN             1.0         2019\n",
      "25  BGR             5.0         2019\n",
      "26  BFA             1.0         2019\n",
      "27  BDI             2.0         2019\n",
      "28  KHM             1.0         2019\n",
      "29  CMR             1.0         2019\n",
      "There was an issue with source S-67\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-67 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-67 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 2.  1.  3.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-68 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  breastfeed_duration  TIME_PERIOD\n",
      "0   AFG                  5.0         2019\n",
      "1   ALB                  5.0         2019\n",
      "2   DZA                  1.0         2019\n",
      "3   AND                  5.0         2019\n",
      "4   AGO                  5.0         2019\n",
      "5   ATG                  1.0         2019\n",
      "6   ARG                  5.0         2019\n",
      "7   ARM                  5.0         2019\n",
      "8   AUS                  1.0         2019\n",
      "9   AUT                  5.0         2019\n",
      "10  AZE                  5.0         2019\n",
      "11  BHS                  1.0         2019\n",
      "12  BHR                  5.0         2019\n",
      "13  BGD                  1.0         2019\n",
      "14  BRB                  1.0         2019\n",
      "15  BLR                  5.0         2019\n",
      "16  BEL                  5.0         2019\n",
      "17  BLZ                  1.0         2019\n",
      "18  BEN                  5.0         2019\n",
      "19  BTN                  2.0         2019\n",
      "20  BOL                  5.0         2019\n",
      "21  BIH                  5.0         2019\n",
      "22  BWA                  5.0         2019\n",
      "23  BRA                  5.0         2019\n",
      "24  BRN                  1.0         2019\n",
      "25  BGR                  5.0         2019\n",
      "26  BFA                  5.0         2019\n",
      "27  BDI                  5.0         2019\n",
      "28  KHM                  5.0         2019\n",
      "29  CMR                  5.0         2019\n",
      "There was an issue with source S-68\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-68 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-68 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 5.  1.  2.  4. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-231 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  day_of_rest  TIME_PERIOD\n",
      "0   AFG          3.0         2019\n",
      "1   ALB          3.0         2019\n",
      "2   DZA          3.0         2019\n",
      "3   AND          3.0         2019\n",
      "4   AGO          3.0         2019\n",
      "5   ATG          3.0         2019\n",
      "6   ARG          4.0         2019\n",
      "7   ARM          4.0         2019\n",
      "8   AUS          1.0         2019\n",
      "9   AUT          4.0         2019\n",
      "10  AZE          5.0         2019\n",
      "11  BHS          3.0         2019\n",
      "12  BHR          3.0         2019\n",
      "13  BGD          3.0         2019\n",
      "14  BRB          1.0         2019\n",
      "15  BLR          5.0         2019\n",
      "16  BEL          3.0         2019\n",
      "17  BLZ          3.0         2019\n",
      "18  BEN          3.0         2019\n",
      "19  BTN          3.0         2019\n",
      "20  BOL          3.0         2019\n",
      "21  BIH          3.0         2019\n",
      "22  BWA          3.0         2019\n",
      "23  BRA          3.0         2019\n",
      "24  BRN          3.0         2019\n",
      "25  BGR          4.0         2019\n",
      "26  BFA          3.0         2019\n",
      "27  BDI          1.0         2019\n",
      "28  KHM          3.0         2019\n",
      "29  CMR          3.0         2019\n",
      "There was an issue with source S-231\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-231 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 3.  4.  1.  5. nan]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-232 \n",
      "\n",
      "\n",
      " Extracting data and store it as raw data\n",
      "   iso3  night_premium  TIME_PERIOD\n",
      "0   AFG            4.0         2019\n",
      "1   ALB            5.0         2019\n",
      "2   DZA            1.0         2019\n",
      "3   AND            2.0         2019\n",
      "4   AGO            2.0         2019\n",
      "5   ATG            1.0         2019\n",
      "6   ARG            2.0         2019\n",
      "7   ARM            5.0         2019\n",
      "8   AUS            1.0         2019\n",
      "9   AUT            1.0         2019\n",
      "10  AZE            NaN         2019\n",
      "11  BHS            1.0         2019\n",
      "12  BHR            5.0         2019\n",
      "13  BGD            1.0         2019\n",
      "14  BRB            1.0         2019\n",
      "15  BLR            4.0         2019\n",
      "16  BEL            1.0         2019\n",
      "17  BLZ            1.0         2019\n",
      "18  BEN            1.0         2019\n",
      "19  BTN            1.0         2019\n",
      "20  BOL            4.0         2019\n",
      "21  BIH            3.0         2019\n",
      "22  BWA            1.0         2019\n",
      "23  BRA            2.0         2019\n",
      "24  BRN            1.0         2019\n",
      "25  BGR            3.0         2019\n",
      "26  BFA            1.0         2019\n",
      "27  BDI            2.0         2019\n",
      "28  KHM            5.0         2019\n",
      "29  CMR            1.0         2019\n",
      "There was an issue with source S-232\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " - - - - - \n",
      " Cleansing source S-232 \n",
      "\n",
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "[ 4.  5.  1.  2. nan  3.]\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n",
      "\n",
      " Calling function 'encode_categorical_variables'...\n",
      "Cleansing done. This is some basic information about the data: \n",
      " \n",
      " There are 195 rows in the dataframe and 0.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " \n",
      " This is the summary of the column 'TIME_PERIOD': count     195.000000\n",
      "mean     2019.010256\n",
      "std         0.101013\n",
      "min      2019.000000\n",
      "25%      2019.000000\n",
      "50%      2019.000000\n",
      "75%      2019.000000\n",
      "max      2020.000000\n",
      "Name: TIME_PERIOD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a flat file of all WPA sources\n",
    "# Read and join all world policy analysis centre data\n",
    "wpa_child_labor = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_8, S_9' / 'WORLD_child_labor.xls'\n",
    ")\n",
    "\n",
    "wpa_childhood = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_10, S_13, S_36, S_45, S_49' / 'WORLD_Dataset_Childhood_4.16.15.xls'\n",
    ")\n",
    "\n",
    "wpa_adult_labor = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_40, S_41, S_63, S_64, S_65, S_66, S_67, S_68' / 'WORLD_Dataset_Adult_Labor_9.17.2018.xls'\n",
    ")\n",
    "\n",
    "wpa_discrimination = pd.read_excel(\n",
    "    io = data_in / 'data_raw_manually_extracted' / 'S_42, S_43, S_44' / 'WORLD_discrimination_at_work.xls'\n",
    ")\n",
    "\n",
    "# Create list to write a loop\n",
    "wpa_combined_list=[\n",
    "    wpa_childhood,\n",
    "    wpa_adult_labor,\n",
    "    wpa_discrimination\n",
    " ]\n",
    "\n",
    "# Loop to join all dataframes\n",
    "wpa_combined = wpa_child_labor\n",
    "\n",
    "for df in wpa_combined_list:\n",
    "    wpa_combined = wpa_combined.merge(\n",
    "        right=df,\n",
    "        on=['iso2', 'iso3']\n",
    "    )\n",
    "\n",
    "# 2. Loop\n",
    "wpa_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_BODY\"] == \"World Policy Analysis Centre\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # \n",
    "# combined_cleansed_csv = pd.DataFrame()\n",
    "# combined_normalized_csv = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in wpa_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    #try:\n",
    "    # Extract data \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n Extracting data and store it as raw data\")\n",
    "\n",
    "    dataframe = wpa_combined[['iso3', row['WPA_OBS_RAW_COL']]] \n",
    "    dataframe['TIME_PERIOD'] = row['WPA_YEAR_COL'] \n",
    "\n",
    "    print(dataframe.head(30))\n",
    "\n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(\n",
    "        data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"),\n",
    "        sep = \";\")\n",
    "    #except:\n",
    "    print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing \n",
    "    print(\"\\n - - - - - \\n Cleansing source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "        raw_data=dataframe,\n",
    "        mapping_dictionary=mapping_dict,\n",
    "        final_sdmx_col_list=sdmx_df_columns_all\n",
    "    )\n",
    "\n",
    "    print(dataframe['RAW_OBS_VALUE'].unique())\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "        grouped_data=dataframe,\n",
    "        crba_country_list=country_crba_list,\n",
    "        country_list_full = country_full_list\n",
    "    )\n",
    "\n",
    "    dataframe = cleanse.Cleanser().add_cols_fill_cells(\n",
    "        grouped_data_iso_filt=dataframe,\n",
    "        dim_cols=sdmx_df_columns_dims,\n",
    "        time_cols=sdmx_df_columns_time,\n",
    "        indicator_name_string=row[\"INDICATOR_NAME_x\"],\n",
    "        index_name_string=row[\"INDEX\"],\n",
    "        issue_name_string=row[\"ISSUE\"],\n",
    "        category_name_string=row[\"CATEGORY\"],\n",
    "        indicator_code_string=row[\"INDICATOR_CODE\"],\n",
    "        indicator_source_string=row[\"ADDRESS\"],\n",
    "        indicator_source_body_string=row[\"SOURCE_BODY\"],\n",
    "        indicator_description_string=row[\"INDICATOR_DESCRIPTION\"],\n",
    "        indicator_explanation_string=row[\"INDICATOR_EXPLANATION\"],\n",
    "        indicator_data_extraction_methodology_string=row[\"EXTRACTION_METHODOLOGY\"],\n",
    "        source_title_string=row[\"SOURCE_TITLE\"],\n",
    "        source_api_link_string=row[\"ENDPOINT_URL\"]\n",
    "    )\n",
    "\n",
    "    dataframe_cleansed = cleanse.Cleanser().encode_categorical_variables(\n",
    "        dataframe = dataframe,\n",
    "        encoding_string = row[\"VALUE_ENCODING\"],\n",
    "        encoding_labels = row[\"VALUE_LABELS\"]\n",
    "    )\n",
    "\n",
    "    cleanse.Cleanser().create_log_report(\n",
    "        cleansed_data=dataframe_cleansed\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Save cleansed data\n",
    "    dataframe_cleansed.to_csv(\n",
    "        data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Normalizing\n",
    "    dataframe_normalized = scaler.normalizer(\n",
    "        cleansed_data = dataframe_cleansed,\n",
    "        sql_subset_query_string=row[\"DIMENSION_VALUES_NORMALIZATION\"],\n",
    "        # dim_cols=sdmx_df_columns_dims,\n",
    "        variable_type = row[\"VALUE_LABELS\"],\n",
    "        is_inverted = row[\"INVERT_NORMALIZATION\"],\n",
    "        whisker_factor=1.5,\n",
    "        raw_data_col=\"RAW_OBS_VALUE\",\n",
    "        scaled_data_col_name=\"SCALED_OBS_VALUE\",\n",
    "        maximum_score=10,\n",
    "        )\n",
    "\n",
    "    dataframe_normalized.to_csv(\n",
    "        data_sources_normalized / str(row[\"SOURCE_ID\"] + \"_normalized.csv\"),\n",
    "        sep = \";\")\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_normalized_csv = combined_normalized_csv.append(\n",
    "        other = dataframe_normalized\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export concatented dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # CLEANSED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_cleansed_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_cleansed_csv[available_dim_cols] = combined_cleansed_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_cleansed_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_cleansed.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# # # # # NORMALIZED DATA\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_normalized_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_normalized_csv[available_dim_cols] = combined_normalized_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# S-101 has one duplicate row for country TON, drop that\n",
    "# This command should commented out when checking for other duplicat\n",
    "combined_normalized_csv = combined_normalized_csv.drop_duplicates()\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_normalized_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "### Some Exploratory data analysis on final dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1243, 41)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 390.429545 248.518125\" width=\"390.429545pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-13T12:39:02.894121</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 390.429545 248.518125 \nL 390.429545 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \nL 374.45 7.2 \nL 39.65 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 54.868182 224.64 \nL 65.013636 224.64 \nL 65.013636 224.603165 \nL 54.868182 224.603165 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 65.013636 224.64 \nL 75.159091 224.64 \nL 75.159091 224.64 \nL 65.013636 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 75.159091 224.64 \nL 85.304545 224.64 \nL 85.304545 224.64 \nL 75.159091 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 85.304545 224.64 \nL 95.45 224.64 \nL 95.45 224.529495 \nL 85.304545 224.529495 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 95.45 224.64 \nL 105.595455 224.64 \nL 105.595455 224.56633 \nL 95.45 224.56633 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 105.595455 224.64 \nL 115.740909 224.64 \nL 115.740909 224.529495 \nL 105.595455 224.529495 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 115.740909 224.64 \nL 125.886364 224.64 \nL 125.886364 224.455826 \nL 115.740909 224.455826 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 125.886364 224.64 \nL 136.031818 224.64 \nL 136.031818 224.234816 \nL 125.886364 224.234816 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 136.031818 224.64 \nL 146.177273 224.64 \nL 146.177273 224.050642 \nL 136.031818 224.050642 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 146.177273 224.64 \nL 156.322727 224.64 \nL 156.322727 224.64 \nL 146.177273 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 156.322727 224.64 \nL 166.468182 224.64 \nL 166.468182 224.308486 \nL 156.322727 224.308486 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 166.468182 224.64 \nL 176.613636 224.64 \nL 176.613636 221.877384 \nL 166.468182 221.877384 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 176.613636 224.64 \nL 186.759091 224.64 \nL 186.759091 223.0561 \nL 176.613636 223.0561 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 186.759091 224.64 \nL 196.904545 224.64 \nL 196.904545 222.429907 \nL 186.759091 222.429907 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 196.904545 224.64 \nL 207.05 224.64 \nL 207.05 222.245733 \nL 196.904545 222.245733 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 207.05 224.64 \nL 217.195455 224.64 \nL 217.195455 203.496777 \nL 207.05 203.496777 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 217.195455 224.64 \nL 227.340909 224.64 \nL 227.340909 220.735502 \nL 217.195455 220.735502 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 227.340909 224.64 \nL 237.486364 224.64 \nL 237.486364 221.693209 \nL 227.340909 221.693209 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 237.486364 224.64 \nL 247.631818 224.64 \nL 247.631818 218.193895 \nL 237.486364 218.193895 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 247.631818 224.64 \nL 257.777273 224.64 \nL 257.777273 224.64 \nL 247.631818 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 257.777273 224.64 \nL 267.922727 224.64 \nL 267.922727 208.764165 \nL 257.777273 208.764165 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 267.922727 224.64 \nL 278.068182 224.64 \nL 278.068182 214.289398 \nL 267.922727 214.289398 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 278.068182 224.64 \nL 288.213636 224.64 \nL 288.213636 210.163891 \nL 278.068182 210.163891 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 288.213636 224.64 \nL 298.359091 224.64 \nL 298.359091 192.777826 \nL 288.213636 192.777826 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 298.359091 224.64 \nL 308.504545 224.64 \nL 308.504545 103.895252 \nL 298.359091 103.895252 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 308.504545 224.64 \nL 318.65 224.64 \nL 318.65 195.098424 \nL 308.504545 195.098424 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 318.65 224.64 \nL 328.795455 224.64 \nL 328.795455 17.554286 \nL 318.65 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 328.795455 224.64 \nL 338.940909 224.64 \nL 338.940909 169.27717 \nL 328.795455 169.27717 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 338.940909 224.64 \nL 349.086364 224.64 \nL 349.086364 144.671468 \nL 338.940909 144.671468 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path clip-path=\"url(#p24850146a1)\" d=\"M 349.086364 224.64 \nL 359.231818 224.64 \nL 359.231818 29.267779 \nL 349.086364 29.267779 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 88.686364 224.64 \nL 88.686364 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7ef56a6a2d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.686364\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1995 -->\n      <g transform=\"translate(75.961364 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 145.05 224.64 \nL 145.05 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"145.05\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(132.325 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 201.413636 224.64 \nL 201.413636 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.413636\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2005 -->\n      <g transform=\"translate(188.688636 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 257.777273 224.64 \nL 257.777273 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"257.777273\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2010 -->\n      <g transform=\"translate(245.052273 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 314.140909 224.64 \nL 314.140909 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.140909\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2015 -->\n      <g transform=\"translate(301.415909 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 370.504545 224.64 \nL 370.504545 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.504545\" xlink:href=\"#m7ef56a6a2d\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2020 -->\n      <g transform=\"translate(357.779545 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 224.64 \nL 374.45 224.64 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1961d7a887\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(26.2875 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 187.805117 \nL 374.45 187.805117 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"187.805117\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1000 -->\n      <g transform=\"translate(7.2 191.604335)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 150.970233 \nL 374.45 150.970233 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"150.970233\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2000 -->\n      <g transform=\"translate(7.2 154.769452)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 114.13535 \nL 374.45 114.13535 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"114.13535\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3000 -->\n      <g transform=\"translate(7.2 117.934569)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 77.300467 \nL 374.45 77.300467 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"77.300467\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4000 -->\n      <g transform=\"translate(7.2 81.099685)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p24850146a1)\" d=\"M 39.65 40.465583 \nL 374.45 40.465583 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m1961d7a887\" y=\"40.465583\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5000 -->\n      <g transform=\"translate(7.2 44.264802)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 39.65 224.64 \nL 39.65 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 374.45 224.64 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 39.65 224.64 \nL 374.45 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 39.65 7.2 \nL 374.45 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p24850146a1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"39.65\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Print number of observations older than 2010\n",
    "old_data = combined_normalized_csv[combined_normalized_csv['TIME_PERIOD']<2010] \n",
    "print(old_data.shape)\n",
    "\n",
    "# Visualize distribution of age of observations\n",
    "combined_normalized_csv.loc[(combined_normalized_csv['TIME_PERIOD']>1990) & (combined_normalized_csv['TIME_PERIOD']<2020), 'TIME_PERIOD'].hist(bins = 30)\n",
    "\n",
    "# Number of observations older than 2010\n",
    "old_data_grouped = old_data.groupby('INDICATOR_NAME').count()\n",
    "\n",
    "# Retrieve total number of observations\n",
    "combined_normalized_csv_grouped = combined_normalized_csv.groupby('INDICATOR_NAME').count()\n",
    "\n",
    "# Compare the number of rows older 2010 and total number of rows per indicators\n",
    "old_data_analysis = old_data_grouped[['COUNTRY_ISO_3']].merge(\n",
    "    right = combined_normalized_csv_grouped[['COUNTRY_ISO_3']],\n",
    "    on = 'INDICATOR_NAME'\n",
    ")\n",
    "\n",
    "# Add column indicating % of obs older\n",
    "old_data_analysis['OBS_PERCENT_OLDER_2010'] = round((old_data_analysis[\"COUNTRY_ISO_3_x\"] / old_data_analysis[\"COUNTRY_ISO_3_y\"]) * 100, 1) \n",
    "\n",
    "\n",
    "old_data_analysis.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'percentage_old_data_per_indicator.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "## Create aggregated scores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined dataframe\n",
    "combined_normalized_csv = pd.read_csv(\n",
    "    cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# # # # # # # \n",
    "# Index score\n",
    "index_score = combined_normalized_csv.loc[:, ['INDICATOR_INDEX','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_INDEX','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column \n",
    "index_score = index_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_INDEX_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "index_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=index_score,\n",
    "    on=['INDICATOR_INDEX','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# # # # # # # \n",
    "# Issue score\n",
    "issue_score = combined_normalized_csv.loc[:, ['INDICATOR_ISSUE','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_ISSUE','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column\n",
    "issue_score = issue_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_ISSUE_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "issue_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'issue_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=issue_score,\n",
    "    on=['INDICATOR_ISSUE','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# # # # # # # # \n",
    "# Caregory score\n",
    "category_score = combined_normalized_csv.loc[:, ['INDICATOR_CATEGORY','COUNTRY_ISO_3', 'SCALED_OBS_VALUE']].groupby(by = ['INDICATOR_CATEGORY','COUNTRY_ISO_3']).mean()\n",
    "\n",
    "# Rename column\n",
    "category_score = category_score.rename(columns={'SCALED_OBS_VALUE' : 'ATTR_CATEGORY_SCORE'})\n",
    "\n",
    "# Temp: Save dataframe\n",
    "category_score.to_csv(    \n",
    "    path_or_buf = cwd / 'data_out' / 'category_scores.csv',\n",
    "    sep = \";\")\n",
    "\n",
    "# Join back to add column to original dataframe\n",
    "combined_normalized_csv = combined_normalized_csv.merge(\n",
    "    right=category_score,\n",
    "    on=['INDICATOR_CATEGORY','COUNTRY_ISO_3']\n",
    ")\n",
    "\n",
    "# Save combined dataframe \n",
    "combined_normalized_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_normalized.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "### Temp to export the results "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined dataframe\n",
    "index_score_csv = pd.read_csv(\n",
    "    cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "index_score_csv = index_score_csv.merge(\n",
    "    right=country_crba_list,\n",
    "    how='left',\n",
    "    on='COUNTRY_ISO_3'\n",
    ")\n",
    "\n",
    "index_score_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'index_scores.csv',\n",
    "    sep = \";\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEVELOPMENT AND TRASH AREA"
   ]
  },
  {
   "source": [
    "### UNCTAD sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Country             Title of Legislation/Draft Legislation  \\\n",
       "72       Iraq              Draft Data Protection and Privacy Law   \n",
       "111  Pakistan  Electronic Data Protection Act 2005 - Draft (i...   \n",
       "159  Zimbabwe                    Draft Data Protection Bill 2016   \n",
       "\n",
       "                                         Links to Laws RAW_OBS_VALUE  \n",
       "72                                                 NaN             2  \n",
       "111  http://media.mofo.com/docs/mofoprivacy/PAKISTA...             2  \n",
       "159  http://www.techzim.co.zw/wp-content/uploads/20...             2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Title of Legislation/Draft Legislation</th>\n      <th>Links to Laws</th>\n      <th>RAW_OBS_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72</th>\n      <td>Iraq</td>\n      <td>Draft Data Protection and Privacy Law</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>111</th>\n      <td>Pakistan</td>\n      <td>Electronic Data Protection Act 2005 - Draft (i...</td>\n      <td>http://media.mofo.com/docs/mofoprivacy/PAKISTA...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>Zimbabwe</td>\n      <td>Draft Data Protection Bill 2016</td>\n      <td>http://www.techzim.co.zw/wp-content/uploads/20...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "s_121 = pd.read_excel(    \n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-121_CC.xlsx\")\n",
    "\n",
    "s_121['RAW_OBS_VALUE'] = s_121['Title of Legislation/Draft Legislation'].apply(lambda x: '2' if re.search('Draft', x) else '3')\n",
    "\n",
    "# re.search(\"Draft\", s_121.iloc[242, 1])\n",
    "\n",
    "s_121[s_121['RAW_OBS_VALUE'] == '2']\n",
    "\n",
    "\n",
    "# # # # # # \n",
    "\n",
    "s_122 = pd.read_excel(    \n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-122_DP.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s_122['RAW_OBS_VALUE'] = s_122['Title of Legislation/Draft Legislation'].apply(lambda x: '2' if re.search('Draft', x) else '3')\n",
    "\n",
    "# re.search(\"Draft\", s_121.iloc[242, 1])\n",
    "\n",
    "s_122[s_122['RAW_OBS_VALUE'] == '2']\n",
    "\n",
    "# s_122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# S-11: Legal framework\\ns_11_raw = S_11_S120_s_124_s_134[[\\'Score.2\\', \\'Unnamed: 29\\']]\\n\\n# Rename columns\\ns_11_raw = s_11_raw.rename(\\n    columns = {\\n        \\'Score.2\\': \\'RAW_OBS_VALUE\\',\\n        \\'Unnamed: 29\\': \\'COUNTRY_NAME\\'\\n    }\\n)\\n\\n# Add year column\\ns_11_raw[\\'TIME_PERIOD\\'] = 2019\\n\\n# Save\\ns_11_raw.to_csv(data_sources_staged_raw / \"S-11_staged_raw.csv\", sep=\";\")\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "### IDMC\n",
    "S_180_S181_s_189 = pd.read_excel(\n",
    "    data_in\n",
    "    / \"data_raw_manually_extracted\"\n",
    "    / \"S-180, S-181, S-189 idmc_displacement_all_dataset.xlsx\",\n",
    ")\n",
    "\n",
    "# Define list to extract the relevant columns and save them as raw data csv\n",
    "eit_list = [\n",
    "    [\"S-11_staged_raw.csv\", [\n",
    "        'Score.2',\n",
    "        'Unnamed: 29'\n",
    "        ]\n",
    "    ],\n",
    "    [\"S-124_staged_raw.csv\", [\n",
    "        'Score.1',\n",
    "        'Unnamed: 20'\n",
    "        ]\n",
    "    ],\n",
    "    [\"S-134_staged_raw.csv\", [\n",
    "        'Score.3',\n",
    "        'Unnamed: 38'\n",
    "        ]\n",
    "    ], # To do: Currently waiting to hear back from Alex concerning soure S-120\n",
    "    [\"S-11_staged_raw.csv\", [\n",
    "        'Score.2',\n",
    "        'Unnamed: 29'\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Loop through list\n",
    "for element in eit_list:\n",
    "    # Extract right columns\n",
    "    dataframe = S_11_S120_s_124_s_134[element[1]]\n",
    "\n",
    "    # Rename clumns\n",
    "    dataframe = dataframe.rename(\n",
    "        columns = {\n",
    "            element[1][0]: 'RAW_OBS_VALUE',\n",
    "            element[1][1]: 'COUNTRY_NAME'\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Add year column\n",
    "    dataframe['TIME_PERIOD'] = 2019\n",
    "\n",
    "    # Save data\n",
    "    dataframe.to_csv(data_sources_staged_raw / element[0], sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract selenium sources --> This code is stable as of 06.11.20, TO DO is to put this into a loop (which must be done in container, so I can only do it once James has looked at the issue with Chrome driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\anaconda3\\envs\\unicef-test\\lib\\site-packages\\ipykernel_launcher.py:32: DeprecationWarning: use options instead of chrome_options\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Calling function 'rename_and_discard_columns'...\n",
      "\n",
      " Calling function 'add_and_discard_countries'...\n",
      "\n",
      " Calling function 'add_cols_fill_cells'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "      <th>ATTR_TREATY_STATUS</th>\n",
       "      <th>ATTR_FOOTNOTE_OF_SOURCE</th>\n",
       "      <th>COUNTRY_ISO_2</th>\n",
       "      <th>COUNTRY_ISO_3</th>\n",
       "      <th>_merge</th>\n",
       "      <th>RAW_OBS_VALUE</th>\n",
       "      <th>ATTR_ENCODING_LABELS</th>\n",
       "      <th>SCALED_OBS_VALUE</th>\n",
       "      <th>OBS_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>In Force</td>\n",
       "      <td>Excluding Article 11 by virtue of the ratifica...</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALB</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>DZ</td>\n",
       "      <td>DZA</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>In Force</td>\n",
       "      <td></td>\n",
       "      <td>AR</td>\n",
       "      <td>ARG</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>In Force</td>\n",
       "      <td>Excluding Article 11 by virtue of the ratifica...</td>\n",
       "      <td>AM</td>\n",
       "      <td>ARM</td>\n",
       "      <td>both</td>\n",
       "      <td>2</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UZB</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VUT</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VNM</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>right_only</td>\n",
       "      <td>1</td>\n",
       "      <td>2=Yes, 1=No; as answer to the following questi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    COUNTRY_NAME ATTR_TREATY_STATUS  \\\n",
       "0    Afghanistan           In Force   \n",
       "1        Albania           In Force   \n",
       "2        Algeria           In Force   \n",
       "3      Argentina           In Force   \n",
       "4        Armenia           In Force   \n",
       "..           ...                ...   \n",
       "192          NaN                NaN   \n",
       "193          NaN                NaN   \n",
       "194          NaN                NaN   \n",
       "195          NaN                NaN   \n",
       "196          NaN                NaN   \n",
       "\n",
       "                               ATTR_FOOTNOTE_OF_SOURCE COUNTRY_ISO_2  \\\n",
       "0                                                                 AF   \n",
       "1    Excluding Article 11 by virtue of the ratifica...            AL   \n",
       "2                                                                 DZ   \n",
       "3                                                                 AR   \n",
       "4    Excluding Article 11 by virtue of the ratifica...            AM   \n",
       "..                                                 ...           ...   \n",
       "192                                                NaN           NaN   \n",
       "193                                                NaN           NaN   \n",
       "194                                                NaN           NaN   \n",
       "195                                                NaN           NaN   \n",
       "196                                                NaN           NaN   \n",
       "\n",
       "    COUNTRY_ISO_3      _merge RAW_OBS_VALUE  \\\n",
       "0             AFG        both             2   \n",
       "1             ALB        both             2   \n",
       "2             DZA        both             2   \n",
       "3             ARG        both             2   \n",
       "4             ARM        both             2   \n",
       "..            ...         ...           ...   \n",
       "192           USA  right_only             1   \n",
       "193           UZB  right_only             1   \n",
       "194           VUT  right_only             1   \n",
       "195           VNM  right_only             1   \n",
       "196           ZWE  right_only             1   \n",
       "\n",
       "                                  ATTR_ENCODING_LABELS  SCALED_OBS_VALUE  \\\n",
       "0    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "1    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "2    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "3    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "4    2=Yes, 1=No; as answer to the following questi...              10.0   \n",
       "..                                                 ...               ...   \n",
       "192  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "193  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "194  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "195  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "196  2=Yes, 1=No; as answer to the following questi...               0.0   \n",
       "\n",
       "    OBS_STATUS  \n",
       "0          nan  \n",
       "1          nan  \n",
       "2          nan  \n",
       "3          nan  \n",
       "4          nan  \n",
       "..         ...  \n",
       "192        nan  \n",
       "193        nan  \n",
       "194        nan  \n",
       "195        nan  \n",
       "196        nan  \n",
       "\n",
       "[197 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# Specify location of chromedriver\n",
    "cwd = os.getcwd()\n",
    "driver_location = cwd + '\\\\chromedriver.exe'\n",
    "\n",
    "# Add option to make it headless (so that it doesn't open an actual chrome window)\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome(driver_location, chrome_options=options)\n",
    "\n",
    "# Get HTTP response\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312256:NO\")\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO::P11300_INSTRUMENT_ID:312283\")\n",
    "# response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312328:NO\")\n",
    "response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312240:NO\")\n",
    "\n",
    "# Get response\n",
    "# response = driver.get(html_url)\n",
    "\n",
    "# Retrieve the actual html\n",
    "html = driver.page_source\n",
    "\n",
    "# Soupify\n",
    "soup = bs.BeautifulSoup(html)\n",
    "\n",
    "# Extract the target table as attribute\n",
    "target_table = str(\n",
    "    soup.find_all(\"table\", {\"cellspacing\": \"0\", \"class\": \"horizontalLine\"})\n",
    ")\n",
    "\n",
    "# Create dataframe with the data\n",
    "raw_data = pd.read_html(io=target_table, header=0)[\n",
    "    0\n",
    "]  # return is a list of DFs, specify [0] to get actual DF\n",
    "\n",
    "# Cleansing\n",
    "dataframe = cleanse.Cleanser().rename_and_discard_columns(\n",
    "    raw_data=raw_data,\n",
    "    mapping_dictionary=mapping_dict,\n",
    "    final_sdmx_col_list=sdmx_df_columns_all\n",
    ")\n",
    "\n",
    "dataframe = cleanse.Cleanser().decompose_country_footnote_ilo_normlex(\n",
    "    dataframe = dataframe,\n",
    "    country_name_list = country_full_list.COUNTRY_NAME\n",
    ")\n",
    "\n",
    "dataframe = cleanse.Cleanser().add_and_discard_countries(\n",
    "    grouped_data=dataframe,\n",
    "    crba_country_list=country_crba_list,\n",
    "    country_list_full = country_full_list\n",
    ")\n",
    "\n",
    "dataframe_cleansed = cleanse.Cleanser().encode_ilo_un_treaty_data(\n",
    "    dataframe = dataframe,\n",
    "    treaty_source_body='ILO NORMLEX'\n",
    ")\n",
    "\n",
    "# Normalizing section\n",
    "dataframe_normalized = scaler.normalizer(\n",
    "    cleansed_data = dataframe_cleansed,\n",
    "    sql_subset_query_string=None\n",
    ")\n",
    "\n",
    "dataframe_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"][5]\n",
    "       \n",
    "# Speifically for ILO NORMLEX - extract country name if additonal info is given\n",
    "#dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"] = dataframe[\"COUNTRY_NAME\"]\n",
    "#dataframe[\"COUNTRY_NAME\"] = dataframe[\"COUNTRY_NAME\"].apply(extract_country_name)\n",
    "#dataframe[\"ATTR_FOOTNOTE_OF_SOURCE\"] = dataframe.apply(lambda x: re.sub(x['COUNTRY_NAME'], \"\", x[\"ATTR_FOOTNOTE_OF_SOURCE\"]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import os\n",
    "from pathlib import Path\n",
    "from selenium import webdriver\n",
    "\n",
    "# cwd = Path('.')\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Current working directory\n",
    "driver_location = cwd + '\\\\geckodriver.exe'\n",
    "\n",
    "print(driver_location)\n",
    "\n",
    "# Open the targete html. Must be done with selenium, because it doesnt work with normal URL request\n",
    "#driver = webdriver.Firefox(executable_path=\"D:/Documents/2020/28_UNICEF/10_working_repo/data-etl/geckodriver.exe\")\n",
    "driver = webdriver.Firefox(executable_path=driver_location)\n",
    "\n",
    "# Get HTTP response\n",
    "response = driver.get(\"https://www.ilo.org/dyn/normlex/en/f?p=NORMLEXPUB:11300:0::NO:11300:P11300_INSTRUMENT_ID:312256:NO\")\n"
   ]
  },
  {
   "source": [
    "## GHG\n",
    "\n",
    "problem: \n",
    "\n",
    "* Cannot use pd_json_normalize --> It won't unnest it becaust he years and actual values are given in [] rather than {}\n",
    "* Stopped here: Must replace the character (but for that it is necessary to convert json to string and back)\n",
    "* Next challnge: Get all data (and not only page 1) --> Main problem is that the API is not working, i.e. can't specify paramters\n",
    "\n",
    "Stopped here 10.11.20 --> Need to get rid of \"[]\" signgs for "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_json = requests.get(\"https://www.climatewatchdata.org/api/v1/data/historical_emissions\").text\n",
    "\n",
    "dataframe_json_cleansed = dataframe_json.replace('[', '{').replace(']','}')\n",
    "json_file = json.dumps(dataframe_json_cleansed)\n",
    "# some_var = json.loads(dataframe_json_cleansed)\n",
    "# type(some_var)\n",
    "# pd.json_normalize(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'indicator': {'id': 'RL.EST', 'value': 'Rule of Law: Estimate'}, 'country': {'id': 'AF', 'value': 'Afghanistan'}, 'countryiso3code': 'AFG', 'date': '2017', 'value': -1.569692, 'unit': '', 'obs_status': '', 'decimal': 0}\n"
     ]
    }
   ],
   "source": [
    "temp = pd.json_normalize(requests.get(\"https://api.worldbank.org/v2/country/all/indicator/EL.EST?format=json&per_page=10000\").json()[1])\n",
    "\n",
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_pos in len(range(dataframe_json['data'])):\n",
    "    for         \n",
    "    dataframe_json['data'][index_pos]['emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36mConvert\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-27f3224cdbad>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_dct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emissions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "def Convert(lst):\n",
    "    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}\n",
    "    return res_dct\n",
    "\n",
    "print(Convert(dataframe_json['data'][3]['emissions']))\n",
    "\n",
    "dataframe_json['data'][3]['emissions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # TEMP DELETE THIS\n",
    "# temp = extract.JSONExtractor.extract(url = \"https://api.worldbank.org/v2/country/all/indicator/VA.EST?format=json&per_page=10000\")\n",
    "\n",
    "temp = pd.json_normalize(requests.get(\"https://api.worldbank.org/v2/country/all/indicator/EL.EST?format=json&per_page=10000\").json()[1])\n",
    "\n",
    "\n",
    "# https://api.worldbank.org/v2/country/all/indicator/UIS.XPUBP.0?format=json&per_page=10000\n",
    "\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    year  value\n",
       "0   1990    NaN\n",
       "1   1991    NaN\n",
       "2   1992    NaN\n",
       "3   1993    NaN\n",
       "4   1994    NaN\n",
       "5   1995    NaN\n",
       "6   1996    NaN\n",
       "7   1997    NaN\n",
       "8   1998    NaN\n",
       "9   1999    NaN\n",
       "10  2000    NaN\n",
       "11  2001    NaN\n",
       "12  2002    NaN\n",
       "13  2003    NaN\n",
       "14  2004    NaN\n",
       "15  2005  15.11\n",
       "16  2006    NaN\n",
       "17  2007    NaN\n",
       "18  2008    NaN\n",
       "19  2009    NaN\n",
       "20  2010    NaN\n",
       "21  2011    NaN\n",
       "22  2012    NaN\n",
       "23  2013  32.74\n",
       "24  2014    NaN\n",
       "25  2015    NaN\n",
       "26  2016    NaN\n",
       "27  2017    NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1990</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1991</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1992</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1993</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1994</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1995</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1996</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1997</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1998</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1999</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2000</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2001</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2002</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2003</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2004</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2005</td>\n      <td>15.11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2006</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2007</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2008</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2009</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2010</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2011</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2012</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2013</td>\n      <td>32.74</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2014</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2015</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2016</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2017</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "#dataframe = extract.CSVExtractor.extract(url = \"https://www.climatewatchdata.org/api/v1/data/historical_emissions\")\n",
    "\n",
    "dataframe_json = requests.get(\"https://www.climatewatchdata.org/api/v1/data/historical_emissions\").json()\n",
    "\n",
    "cleaned_json = dataframe_json['data']# .replace('[', '{').replace\n",
    "print(type(cleaned_json))\n",
    "\"\"\"\n",
    "# with open(dataframe_json, 'r') as file:\n",
    "    content = file.read()\n",
    "    clean = content.replace(']', '}')  # cleanup here\n",
    "    json_data = json.loads(clean)\n",
    "\"\"\"\n",
    "\n",
    "# dataframe_2 = pd.json_normalize(dataframe_json['data'], max_level=5)\n",
    "\n",
    "# dataframe_3 = pd.json_normalize(dataframe_json['data)\n",
    "\n",
    "\n",
    "#dataframe_3\n",
    "\n",
    "df = pd.json_normalize(cleaned_json)\n",
    "df_2 = pd.json_normalize(df.loc[5, 'emissions'])\n",
    "\n",
    "df_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}