{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "source": [
    "# Preliminaries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Required standard libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import selenium\n",
    "import html5lib\n",
    "import nltk\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "# Extractors (cluster specific)\n",
    "import extract\n",
    "# from extract.unesco_extractor import extract_unesco_api_data\n",
    "# from extract.ilo_extractor import extract_ilo_api_data\n",
    "# from extract.sdg_extractor import extract_sdg_api_data\n",
    "# from extract.who_extractor import extract_who_api_data\n",
    "# from extract.un_treaty_extractor import extract_un_treaties_data\n",
    "# from extract.ilo_normlex_extractor import extract_ilo_normlex_data\n",
    "\n",
    "# from extract import save_raw_data\n",
    "\n",
    "# Cleansers (cluster specific)\n",
    "import cleanse\n",
    "# from cleanse.unesco_cleanser import cleanse_unesco_api_data\n",
    "# from cleanse.ilo_cleanser import cleanse_ilo_api_data\n",
    "# from cleanse.sdg_cleanser import cleanse_sdg_api_data\n",
    "# from cleanse.who_cleanser import cleanse_who_api_num_data\n",
    "# from cleanse.un_treaty_cleanser import cleanse_un_treaty_data\n",
    "# from cleanse.wpac_cleanser import cleanse_wpac_data\n",
    "\n",
    "# from cleanse.save_cleansed_data import save_cleansed_data \n",
    "\n",
    "# Normalizer (generalised across all clusters)\n",
    "from normalize import scaler\n",
    "# from normalize import save_normalized_data\n",
    "\n",
    "# Utils\n",
    "from utils import utils"
   ]
  },
  {
   "source": [
    "## Define filepaths"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export path for all data exports\n",
    "from pathlib import Path\n",
    "\n",
    "# CUrrent working directory\n",
    "cwd = Path('.')\n",
    "\n",
    "# Folder with data-in artifacts, quired to run this script\n",
    "data_in = cwd / 'data_in'\n",
    "\n",
    "# Folder to export raw data\n",
    "data_sources_raw = cwd / 'data_out' / 'data_raw'\n",
    "data_sources_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export cleansed data\n",
    "data_sources_cleansed = cwd / 'data_out' / 'data_cleansed'\n",
    "data_sources_cleansed.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Folder to export normalized data\n",
    "data_sources_normalized = cwd / 'data_out' / 'data_normalized'\n",
    "data_sources_normalized.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "source": [
    "## Load country list and mapping dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of countries which contains all different variations of country names \n",
    "country_full_list = pd.read_excel(\n",
    "    data_in / 'all_countrynames_list.xlsx',\n",
    "    keep_default_na = False).drop_duplicates()\n",
    "\n",
    "# Create a version of the list with unique ISO2 and ISO3 codes\n",
    "country_iso_list = country_full_list.drop_duplicates(subset = 'COUNTRY_ISO_2')\n",
    "\n",
    "# Country CRBA list, this is the list of the countries that should be in the final CRBA indicator list\n",
    "country_crba_list = pd.read_excel(\n",
    "    data_in / 'crba_country_list.xlsx',\n",
    "    header = None,\n",
    "    usecols = [0, 1], \n",
    "    names = ['COUNTRY_ISO_3', 'COUNTRY_NAME']).merge(\n",
    "        right = country_iso_list[['COUNTRY_ISO_2', 'COUNTRY_ISO_3']],\n",
    "        how = 'left',\n",
    "        on='COUNTRY_ISO_3',\n",
    "        validate = 'one_to_one')\n",
    "\n",
    "# Run the column mapper script to load the mapping dictionary\n",
    "with open(data_in / 'mapping_dictionary.py') as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "source": [
    "## Read data dictionary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources sheet\n",
    "crba_data_dictionary_source = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Source\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# snapshot sheet\n",
    "crba_data_dictionary_snapshot = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Snapshot\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# indicator sheet\n",
    "crba_data_dictionary_indicator = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Indicator\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Input lists\n",
    "crba_data_dictionary_input_list = pd.read_excel(\n",
    "    data_in / 'indicator_dictionary_CRBA.xlsx',\n",
    "    sheet_name = \"Input_Lists\",\n",
    "    keep_default_na = False\n",
    ")\n",
    "\n",
    "# Add 2-digit shortcodes of index, issue and category to indicators sheet\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.merge(\n",
    "    right=crba_data_dictionary_input_list[['INDEX', 'INDEX_CODE']],\n",
    "    left_on='INDEX',\n",
    "    right_on='INDEX',\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['ISSUE', 'ISSUE_CODE']],\n",
    "    left_on='ISSUE',\n",
    "    right_on='ISSUE',\n",
    ").merge(\n",
    "    right=crba_data_dictionary_input_list[['CATEGORY', 'CATEGORY_CODE']],\n",
    "    left_on='CATEGORY',\n",
    "    right_on='CATEGORY',\n",
    ")\n",
    "\n",
    "# Create indicator code prefix (INDEX-ISSUE_CAEGORY CODE)\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE_PREFIX = crba_data_dictionary_indicator.INDEX_CODE +\n",
    "    \"_\" +\n",
    "    crba_data_dictionary_indicator.ISSUE_CODE+\n",
    "    \"_\"+\n",
    "    crba_data_dictionary_indicator.CATEGORY_CODE+\n",
    "    \"_\")\n",
    "\n",
    "# Create indicator code\n",
    "crba_data_dictionary_indicator = crba_data_dictionary_indicator.assign(\n",
    "    INDICATOR_CODE = crba_data_dictionary_indicator.INDICATOR_CODE_PREFIX + crba_data_dictionary_indicator.INDICATOR_NAME.apply(\n",
    "    lambda x: utils.create_ind_code(x)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib, inspect\n",
    "\n",
    "extractors = { \n",
    "    cls.type: cls for name, cls in inspect.getmembers(\n",
    "        importlib.import_module(\"extract\"), \n",
    "        inspect.isclass\n",
    "    ) if hasattr(cls, 'type')\n",
    "}"
   ]
  },
  {
   "source": [
    "# Extract\n",
    "## API sources\n",
    "### CSV API sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-51 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column COLLECTION has 1 unique values.\n",
      "The column REF_AREA has 110 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column MEASURE has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 754 unique values.\n",
      "The column OBS_STATUS has 2 unique values.\n",
      "The column UNIT_MEASURE_TYPE has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column SOURCE_NOTE has 43 unique values.\n",
      "The column INDICATOR_NOTE has 52 unique values.\n",
      "The column CLASSIFICATION_NOTE has 1 unique values.\n",
      "The column CURRENCY_NOTE has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The column UPPER_BOUND has 1 unique values.\n",
      "The column LOWER_BOUND has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-51 \n",
      "\n",
      "Cleansing done. There are 409 rows in the dataframe and 21.52% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-52 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 2 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column EDU_FIELD has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column TEACH_EXPERIENCE has 1 unique values.\n",
      "The column CONTRACT_TYPE has 1 unique values.\n",
      "The column COUNTRY_ORIGIN has 1 unique values.\n",
      "The column REGION_DEST has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 339 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 10277 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-52 \n",
      "\n",
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\n",
      "Cleansing done. There are 1051 rows in the dataframe and 1.52% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-53 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column DATAFLOW has 1 unique values.\n",
      "The column COLLECTION has 1 unique values.\n",
      "The column REF_AREA has 169 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column MEASURE has 1 unique values.\n",
      "The column OCU has 2 unique values.\n",
      "The column TIME_PERIOD has 10 unique values.\n",
      "The column OBS_VALUE has 1276 unique values.\n",
      "The column OBS_STATUS has 1 unique values.\n",
      "The column UNIT_MEASURE_TYPE has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column SOURCE_NOTE has 91 unique values.\n",
      "The column INDICATOR_NOTE has 7 unique values.\n",
      "The column CLASSIFICATION_NOTE has 1 unique values.\n",
      "The column CURRENCY_NOTE has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The column UPPER_BOUND has 1 unique values.\n",
      "The column LOWER_BOUND has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-53 \n",
      "\n",
      "Cleansing done. There are 296 rows in the dataframe and 13.18% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-55 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 3 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 326 unique values.\n",
      "The column TIME_PERIOD has 14 unique values.\n",
      "The column OBS_VALUE has 26627 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-55 \n",
      "\n",
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\n",
      "Cleansing done. There are 1470 rows in the dataframe and 1.9% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-88 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 3 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 6 unique values.\n",
      "The column Numeric has 1 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 5 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-88 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 1.54% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-97 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 10 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 161 unique values.\n",
      "The column SEX has 2 unique values.\n",
      "The column Display Value has 240 unique values.\n",
      "The column Numeric has 2 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-97 \n",
      "\n",
      "Cleansing done. There are 354 rows in the dataframe and 10.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-103 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 42 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 196 unique values.\n",
      "The column AGEGROUP has 3 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column Display Value has 51011 unique values.\n",
      "The column Numeric has 683 unique values.\n",
      "The column Low has 573 unique values.\n",
      "The column High has 778 unique values.\n",
      "The column Comments has 2 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-103 \n",
      "\n",
      "Cleansing done. There are 1731 rows in the dataframe and 0.17% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-104 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 36 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column COUNTRY has 154 unique values.\n",
      "The column Display Value has 370 unique values.\n",
      "The column Numeric has 476 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 6 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-104 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 21.03% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-112 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 11 unique values.\n",
      "The column REGION has 7 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 6 unique values.\n",
      "The column COUNTRY has 194 unique values.\n",
      "The column Display Value has 35 unique values.\n",
      "The column Numeric has 35 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-112 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 2.05% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-157 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 6 unique values.\n",
      "The column WORLDBANKINCOMEGROUP has 2 unique values.\n",
      "The column COUNTRY has 173 unique values.\n",
      "The column Display Value has 90 unique values.\n",
      "The column Numeric has 157 unique values.\n",
      "The column Low has 1 unique values.\n",
      "The column High has 1 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-157 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 11.28% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-158 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column GHO has 1 unique values.\n",
      "The column PUBLISHSTATE has 1 unique values.\n",
      "The column YEAR has 1 unique values.\n",
      "The column REGION has 8 unique values.\n",
      "The column UNREGION has 26 unique values.\n",
      "The column COUNTRY has 195 unique values.\n",
      "The column RESIDENCEAREATYPE has 3 unique values.\n",
      "The column Display Value has 618 unique values.\n",
      "The column Numeric has 628 unique values.\n",
      "The column Low has 570 unique values.\n",
      "The column High has 570 unique values.\n",
      "The column Comments has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-158 \n",
      "\n",
      "Cleansing done. There are 577 rows in the dataframe and 0.52% have a NA-value in the column 'OBS_RAW_VALUE\n"
     ]
    }
   ],
   "source": [
    "# CSV sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (ILO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (UNESCO)\") | \n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (WHO)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# define emty dataframe\n",
    "combined_cleansed_csv = pd.DataFrame()\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    # Log\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Extraction section\n",
    "    try:\n",
    "        dataframe = extract.CSVExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        dataframe.to_csv(data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"))\n",
    "    except:\n",
    "       print(\"There was an issue with extraction of source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleasning source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing section \n",
    "    try:\n",
    "        dataframe_cleansed = cleanse.Cleanser().cleanse(\n",
    "            raw_data = dataframe,\n",
    "            mapping_dictionary = mapping_dict,\n",
    "            final_sdmx_col_list = sdmx_df_columns_all,\n",
    "            dim_cols = sdmx_df_columns_dims,\n",
    "            country_cols = sdmx_df_columns_country,\n",
    "            time_cols = sdmx_df_columns_time,\n",
    "            country_list_full = country_full_list,\n",
    "            crba_country_list = country_crba_list\n",
    "            )\n",
    "        dataframe_cleansed.to_csv(data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"))\n",
    "    except:\n",
    "       print(\"There was an issue with cleansing of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Add additional columns\n",
    "\n",
    "    # Indicator name\n",
    "    dataframe_cleansed[\"INDICATOR_NAME\"] = row[\"INDICATOR_NAME_x\"]\n",
    "\n",
    "    # Index name\n",
    "    dataframe_cleansed[\"INDICATOR_INDEX\"] = row[\"INDEX\"]\n",
    "\n",
    "    # Issue name\n",
    "    dataframe_cleansed[\"INDICATOR_ISSUE\"] = row[\"ISSUE\"]\n",
    "\n",
    "    # Category name\n",
    "    dataframe_cleansed[\"INDICATOR_CATEGORY\"] = row[\"CATEGORY\"]\n",
    "\n",
    "    # YEAR_CRBA_RELEASE with current year\n",
    "    dataframe_cleansed[\"CRBA_RELEASE_YEAR\"] = datetime.datetime.now().year\n",
    "\n",
    "    # Create column indicator code\n",
    "    dataframe_cleansed[\"INDICATOR_CODE\"] = row[\"INDICATOR_CODE\"]\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "### JSON API sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " - - - - - \n",
      " Extracting source S-71 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 113 unique values.\n",
      "The column geoAreaName has 113 unique values.\n",
      "The column timePeriodStart has 4 unique values.\n",
      "The column value has 66 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 2 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Sex has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-71 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 60.0% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-125 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 58 unique values.\n",
      "The column geoAreaName has 58 unique values.\n",
      "The column timePeriodStart has 14 unique values.\n",
      "The column value has 62 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 13 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 17 unique values.\n",
      "The column attributes.Nature has 3 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Age has 2 unique values.\n",
      "The column dimensions.Sex has 2 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-125 \n",
      "\n",
      "Cleansing done. There are 206 rows in the dataframe and 69.42% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-160 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 1 unique values.\n",
      "The column target has 1 unique values.\n",
      "The column indicator has 1 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 211 unique values.\n",
      "The column geoAreaName has 211 unique values.\n",
      "The column timePeriodStart has 1 unique values.\n",
      "The column value has 107 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-160 \n",
      "\n",
      "Cleansing done. There are 195 rows in the dataframe and 6.15% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-183 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 82 unique values.\n",
      "The column geoAreaName has 82 unique values.\n",
      "The column timePeriodStart has 5 unique values.\n",
      "The column value has 90 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 1 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-183 \n",
      "\n",
      "Cleansing done. There are 359 rows in the dataframe and 31.48% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-184 \n",
      "\n",
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column goal has 3 unique values.\n",
      "The column target has 3 unique values.\n",
      "The column indicator has 3 unique values.\n",
      "The column series has 1 unique values.\n",
      "The column seriesDescription has 1 unique values.\n",
      "The column seriesCount has 1 unique values.\n",
      "The column geoAreaCode has 141 unique values.\n",
      "The column geoAreaName has 141 unique values.\n",
      "The column timePeriodStart has 15 unique values.\n",
      "The column value has 1193 unique values.\n",
      "The column valueType has 1 unique values.\n",
      "The column time_detail has 1 unique values.\n",
      "The column timeCoverage has 1 unique values.\n",
      "The column upperBound has 1 unique values.\n",
      "The column lowerBound has 1 unique values.\n",
      "The column basePeriod has 1 unique values.\n",
      "The column source has 1 unique values.\n",
      "The column geoInfoUrl has 1 unique values.\n",
      "The column footnotes has 2 unique values.\n",
      "The column attributes.Nature has 1 unique values.\n",
      "The column attributes.Units has 1 unique values.\n",
      "The column dimensions.Reporting Type has 1 unique values.\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-184 \n",
      "\n",
      "Cleansing done. There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-185 \n",
      "\n",
      "There was an issue with source S-185\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-185 \n",
      "\n",
      "Cleansing done. There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-186 \n",
      "\n",
      "There was an issue with source S-186\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-186 \n",
      "\n",
      "Cleansing done. There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-187 \n",
      "\n",
      "There was an issue with source S-187\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-187 \n",
      "\n",
      "Cleansing done. There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n",
      "\n",
      " - - - - - \n",
      " Extracting source S-188 \n",
      "\n",
      "There was an issue with source S-188\n",
      "\n",
      " - - - - - \n",
      " Cleasning source S-188 \n",
      "\n",
      "Cleansing done. There are 469 rows in the dataframe and 12.37% have a NA-value in the column 'OBS_RAW_VALUE\n"
     ]
    }
   ],
   "source": [
    "# JSON sources\n",
    "api_sources = crba_data_dictionary_source[\n",
    "    (crba_data_dictionary_source[\"SOURCE_TYPE\"] == \"API (SDG)\")\n",
    "].merge(\n",
    "    right = crba_data_dictionary_snapshot,\n",
    "    on = \"SOURCE_ID\"\n",
    ").merge(\n",
    "    right = crba_data_dictionary_indicator,\n",
    "    on = 'INDICATOR_ID'\n",
    ")\n",
    "\n",
    "# Loop to extract data from API sources\n",
    "for index, row in api_sources.iterrows():\n",
    "    print(\"\\n - - - - - \\n Extracting source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Exraction section\n",
    "    try:\n",
    "        dataframe = extract.JSONExtractor.extract(url = row[\"ENDPOINT_URL\"])\n",
    "        dataframe.to_csv(data_sources_raw / str(row[\"SOURCE_ID\"] + \"_raw.csv\"))\n",
    "    except:\n",
    "        print(\"There was an issue with source {}\".format(row[\"SOURCE_ID\"]))\n",
    "\n",
    "    # Log that we are entering cleasning\n",
    "    print(\"\\n - - - - - \\n Cleasning source {} \\n\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Cleansing section \n",
    "    try:\n",
    "        dataframe_cleansed = cleanse.Cleanser().cleanse(\n",
    "            raw_data = dataframe,\n",
    "            mapping_dictionary = mapping_dict,\n",
    "            final_sdmx_col_list = sdmx_df_columns_all,\n",
    "            dim_cols = sdmx_df_columns_dims,\n",
    "            country_cols = sdmx_df_columns_country,\n",
    "            time_cols = sdmx_df_columns_time,\n",
    "            country_list_full = country_full_list,\n",
    "            crba_country_list = country_crba_list\n",
    "            )\n",
    "        dataframe_cleansed.to_csv(data_sources_cleansed / str(row[\"SOURCE_ID\"] + \"_cleansed.csv\"))\n",
    "    except:\n",
    "       print(\"There was an issue with cleansing of source {}\".format(row[\"SOURCE_ID\"]))\n",
    "    \n",
    "    # Add additional columns\n",
    "\n",
    "    # Indicator name\n",
    "    dataframe_cleansed[\"INDICATOR_NAME\"] = row[\"INDICATOR_NAME_x\"]\n",
    "\n",
    "    # Index name\n",
    "    dataframe_cleansed[\"INDICATOR_INDEX\"] = row[\"INDEX\"]\n",
    "\n",
    "    # Issue name\n",
    "    dataframe_cleansed[\"INDICATOR_ISSUE\"] = row[\"ISSUE\"]\n",
    "\n",
    "    # Category name\n",
    "    dataframe_cleansed[\"INDICATOR_CATEGORY\"] = row[\"CATEGORY\"]\n",
    "\n",
    "    # YEAR_CRBA_RELEASE with current year\n",
    "    dataframe_cleansed[\"CRBA_RELEASE_YEAR\"] = datetime.datetime.now().year\n",
    "\n",
    "    # Create column indicator code\n",
    "    dataframe_cleansed[\"INDICATOR_CODE\"] = row[\"INDICATOR_CODE\"]\n",
    "\n",
    "\n",
    "    # Append dataframe to combined dataframe\n",
    "    combined_cleansed_csv = combined_cleansed_csv.append(\n",
    "        other = dataframe_cleansed\n",
    "    )\n",
    "\n",
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_cleansed_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_cleansed_csv[available_dim_cols] = combined_cleansed_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_cleansed_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_cleansed.csv',\n",
    "    sep = \";\"\n",
    ")\n",
    "\n",
    "# TO DO: Also include JSON and HTML as extractor --> No other way to put it into the loop than eval()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idenify all dimension columns in combined dataframe\n",
    "available_dim_cols = []\n",
    "for col in combined_cleansed_csv.columns:\n",
    "    dim_col = re.findall(\"DIM_.+\", col)\n",
    "    # print(dim_col)\n",
    "    if len(dim_col) == 1:\n",
    "        available_dim_cols += dim_col\n",
    "\n",
    "# Fill _T for all NA values of dimension columns\n",
    "# 5b Fill in current year for time variable\n",
    "combined_cleansed_csv[available_dim_cols] = combined_cleansed_csv[\n",
    "    available_dim_cols\n",
    "].fillna(value=\"_T\")\n",
    "\n",
    "# Export combined cleansed dataframe as a sample\n",
    "combined_cleansed_csv.to_csv(\n",
    "    path_or_buf = cwd / 'data_out' / 'combined_cleansed.csv',\n",
    "    sep = \";\"\n",
    ")"
   ]
  },
  {
   "source": [
    "# DEVELOPMENT AND TRASH AREA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following columns are present in the datasets, and this is the number of unique values they have. \n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 3 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column REF_AREA has 326 unique values.\n",
      "The column TIME_PERIOD has 14 unique values.\n",
      "The column OBS_VALUE has 26627 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column OBS_STATUS has 3 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n"
     ]
    }
   ],
   "source": [
    "# Extract data\n",
    "s55_raw = extract.CSVExtractor.extract(url =\n",
    "    'https://api.uis.unesco.org/sdmx/data/UNESCO,SDG4,2.0/ROFST.PT.L2+L2_3+L3._T._T+F+M.SCH_AGE_GROUP._T.INST_T._Z._T._Z._Z._Z._T._T._Z._Z._Z.?startPeriod=2005&endPeriod=2018&format=csv-sdmx&locale=en&subscription-key=460ab272abdd43c892bb59c218c22c09'\n",
    ")\n",
    "\n",
    "# s55_raw.to_csv(data_sources_raw / \"S_55_raw.csv\")"
   ]
  },
  {
   "source": [
    "# Cleansing\n",
    "\n",
    "\n",
    "< STOPPED HERE , the below code runs (but have to define tha mapping_dict first) --> Next step is to Bring this thing into a loop and take care of the exceptions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleansing done. There are 195 rows in the dataframe and 26.15% have a non-NA value in the column 'OBS_RAW_VALUE\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   DIM_SDG_GOAL                     ATTR_SDG_INDICATOR_DESCRIPTION  \\\n",
       "0         ['2']  Proportion of children moderately or severely ...   \n",
       "1         ['2']  Proportion of children moderately or severely ...   \n",
       "2            _T                                                NaN   \n",
       "3         ['2']  Proportion of children moderately or severely ...   \n",
       "4         ['2']  Proportion of children moderately or severely ...   \n",
       "5            _T                                                NaN   \n",
       "6         ['2']  Proportion of children moderately or severely ...   \n",
       "7         ['2']  Proportion of children moderately or severely ...   \n",
       "8         ['2']  Proportion of children moderately or severely ...   \n",
       "9            _T                                                NaN   \n",
       "10        ['2']  Proportion of children moderately or severely ...   \n",
       "11           _T                                                NaN   \n",
       "12           _T                                                NaN   \n",
       "13        ['2']  Proportion of children moderately or severely ...   \n",
       "14        ['2']  Proportion of children moderately or severely ...   \n",
       "15        ['2']  Proportion of children moderately or severely ...   \n",
       "16           _T                                                NaN   \n",
       "17        ['2']  Proportion of children moderately or severely ...   \n",
       "18        ['2']  Proportion of children moderately or severely ...   \n",
       "19        ['2']  Proportion of children moderately or severely ...   \n",
       "20        ['2']  Proportion of children moderately or severely ...   \n",
       "21        ['2']  Proportion of children moderately or severely ...   \n",
       "22        ['2']  Proportion of children moderately or severely ...   \n",
       "23        ['2']  Proportion of children moderately or severely ...   \n",
       "24        ['2']  Proportion of children moderately or severely ...   \n",
       "25        ['2']  Proportion of children moderately or severely ...   \n",
       "26        ['2']  Proportion of children moderately or severely ...   \n",
       "27        ['2']  Proportion of children moderately or severely ...   \n",
       "28           _T                                                NaN   \n",
       "29        ['2']  Proportion of children moderately or severely ...   \n",
       "\n",
       "                        COUNTRY_NAME  TIME_PERIOD  RAW_OBS_VALUE  \\\n",
       "0                        Afghanistan       2018.0            4.1   \n",
       "1                            Albania       2017.0           16.4   \n",
       "2                                NaN       2020.0            NaN   \n",
       "3                            Algeria       2012.0           12.4   \n",
       "4                             Angola       2015.0            3.4   \n",
       "5                                NaN       2020.0            NaN   \n",
       "6                          Argentina       2019.0           10.0   \n",
       "7                            Armenia       2016.0           13.7   \n",
       "8                          Australia       2017.0           22.0   \n",
       "9                                NaN       2020.0            NaN   \n",
       "10                        Azerbaijan       2013.0           14.1   \n",
       "11                               NaN       2020.0            NaN   \n",
       "12                               NaN       2020.0            NaN   \n",
       "13                        Bangladesh       2018.0            2.2   \n",
       "14                          Barbados       2012.0           12.2   \n",
       "15                           Belarus       2005.0            9.7   \n",
       "16                               NaN       2020.0            NaN   \n",
       "17                            Belize       2015.0            7.3   \n",
       "18                             Benin       2018.0            1.9   \n",
       "19                            Bhutan       2010.0            7.6   \n",
       "20  Bolivia (Plurinational State of)       2016.0           10.1   \n",
       "21            Bosnia and Herzegovina       2012.0           17.4   \n",
       "22                          Botswana       2007.0           10.0   \n",
       "23                            Brazil       2007.0            6.4   \n",
       "24                 Brunei Darussalam       2009.0            8.3   \n",
       "25                          Bulgaria       2014.0            6.9   \n",
       "26                      Burkina Faso       2018.0            1.0   \n",
       "27                           Burundi       2016.0            1.4   \n",
       "28                               NaN       2020.0            NaN   \n",
       "29                          Cambodia       2014.0            2.2   \n",
       "\n",
       "                                ATTR_SOURCE_OF_SOURCE  \\\n",
       "0                      Afghanistan Health Survey 2018   \n",
       "1   Albania Demographic and Health Survey 2017-18....   \n",
       "2                                                 NaN   \n",
       "3   République Algérienne Démocratiqe et Populaire...   \n",
       "4   Inquérito de Indicadores Múltiplos e de Saúde ...   \n",
       "5                                                 NaN   \n",
       "6   Segunda Encuesta Nacional de Nutricion y Salud...   \n",
       "7   Armenia Demographic and Health Survey 2015-16....   \n",
       "8            Australia National Health Survey 2017-18   \n",
       "9                                                 NaN   \n",
       "10  Azerbaijan nutrition survey  (AzNS), 2013. Bak...   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  Bangladesh Demographic and Health Survey 2017-...   \n",
       "14  Barbados multiple indicator cluster survey 201...   \n",
       "15  Belarus multiple indicator cluster survey 2005...   \n",
       "16                                                NaN   \n",
       "17  Belize Multiple Indicator Cluster Survey, 2015...   \n",
       "18  Enquête Démographique et de Santé au Bénin, 20...   \n",
       "19  Bhutan multiple indicator cluster survey (BMIS...   \n",
       "20  Bolivia Encuesta de Demografia y Salud - EDSA ...   \n",
       "21  Institute for Public Health [Federation of Bos...   \n",
       "22  2007 Botswana family health survey IV report. ...   \n",
       "23  Pesquisa nacional de demografia e saúde da cri...   \n",
       "24  2nd National health and nutritional status sur...   \n",
       "25  National Survey of Nutrition Factor for Health...   \n",
       "26  Enquete Nutritionnelle Nationale, Burkina Faso...   \n",
       "27  Troisième Enquête Démographique et de Santé. B...   \n",
       "28                                                NaN   \n",
       "29  Cambodia Demographic and Health Survey 2014. P...   \n",
       "\n",
       "                      ATTR_FOOTNOTE_OF_SOURCE ATTR_UNIT_MEASURE DIM_AGE  \\\n",
       "0                                        ['']        PER_POP_U5     <5Y   \n",
       "1                                        ['']        PER_POP_U5     <5Y   \n",
       "2                                         NaN               NaN      _T   \n",
       "3                                        ['']        PER_POP_U5     <5Y   \n",
       "4                                        ['']        PER_POP_U5     <5Y   \n",
       "5                                         NaN               NaN      _T   \n",
       "6   ['overweight using BMI-for-age z-scores']        PER_POP_U5     <5Y   \n",
       "7                                        ['']        PER_POP_U5     <5Y   \n",
       "8                           ['Age-adjusted;']        PER_POP_U5     <5Y   \n",
       "9                                         NaN               NaN      _T   \n",
       "10                                       ['']        PER_POP_U5     <5Y   \n",
       "11                                        NaN               NaN      _T   \n",
       "12                                        NaN               NaN      _T   \n",
       "13                                       ['']        PER_POP_U5     <5Y   \n",
       "14                                       ['']        PER_POP_U5     <5Y   \n",
       "15                                       ['']        PER_POP_U5     <5Y   \n",
       "16                                        NaN               NaN      _T   \n",
       "17                                       ['']        PER_POP_U5     <5Y   \n",
       "18                                       ['']        PER_POP_U5     <5Y   \n",
       "19                                       ['']        PER_POP_U5     <5Y   \n",
       "20                                       ['']        PER_POP_U5     <5Y   \n",
       "21                                       ['']        PER_POP_U5     <5Y   \n",
       "22                                       ['']        PER_POP_U5     <5Y   \n",
       "23                                       ['']        PER_POP_U5     <5Y   \n",
       "24                                       ['']        PER_POP_U5     <5Y   \n",
       "25          ['Age interval 1-5; unadjusted;']        PER_POP_U5     <5Y   \n",
       "26                                       ['']        PER_POP_U5     <5Y   \n",
       "27                                       ['']        PER_POP_U5     <5Y   \n",
       "28                                        NaN               NaN      _T   \n",
       "29                                       ['']        PER_POP_U5     <5Y   \n",
       "\n",
       "   DIM_REP_TYPE COUNTRY_ISO_2 COUNTRY_ISO_3      _merge  \n",
       "0             G            AF           AFG        both  \n",
       "1             G            AL           ALB        both  \n",
       "2            _T           NaN           AND  right_only  \n",
       "3             G            DZ           DZA        both  \n",
       "4             G            AO           AGO        both  \n",
       "5            _T           NaN           ATG  right_only  \n",
       "6             G            AR           ARG        both  \n",
       "7             G            AM           ARM        both  \n",
       "8             G            AU           AUS        both  \n",
       "9            _T           NaN           AUT  right_only  \n",
       "10            G            AZ           AZE        both  \n",
       "11           _T           NaN           BHS  right_only  \n",
       "12           _T           NaN           BHR  right_only  \n",
       "13            G            BD           BGD        both  \n",
       "14            G            BB           BRB        both  \n",
       "15            G            BY           BLR        both  \n",
       "16           _T           NaN           BEL  right_only  \n",
       "17            G            BZ           BLZ        both  \n",
       "18            G            BJ           BEN        both  \n",
       "19            G            BT           BTN        both  \n",
       "20            G            BO           BOL        both  \n",
       "21            G            BA           BIH        both  \n",
       "22            G            BW           BWA        both  \n",
       "23            G            BR           BRA        both  \n",
       "24            G            BN           BRN        both  \n",
       "25            G            BG           BGR        both  \n",
       "26            G            BF           BFA        both  \n",
       "27            G            BI           BDI        both  \n",
       "28           _T           NaN           CPV  right_only  \n",
       "29            G            KH           KHM        both  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DIM_SDG_GOAL</th>\n      <th>ATTR_SDG_INDICATOR_DESCRIPTION</th>\n      <th>COUNTRY_NAME</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OF_SOURCE</th>\n      <th>ATTR_FOOTNOTE_OF_SOURCE</th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_AGE</th>\n      <th>DIM_REP_TYPE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>COUNTRY_ISO_3</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Afghanistan</td>\n      <td>2018.0</td>\n      <td>4.1</td>\n      <td>Afghanistan Health Survey 2018</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AF</td>\n      <td>AFG</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Albania</td>\n      <td>2017.0</td>\n      <td>16.4</td>\n      <td>Albania Demographic and Health Survey 2017-18....</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AL</td>\n      <td>ALB</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>AND</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Algeria</td>\n      <td>2012.0</td>\n      <td>12.4</td>\n      <td>République Algérienne Démocratiqe et Populaire...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>DZ</td>\n      <td>DZA</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Angola</td>\n      <td>2015.0</td>\n      <td>3.4</td>\n      <td>Inquérito de Indicadores Múltiplos e de Saúde ...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AO</td>\n      <td>AGO</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>ATG</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Argentina</td>\n      <td>2019.0</td>\n      <td>10.0</td>\n      <td>Segunda Encuesta Nacional de Nutricion y Salud...</td>\n      <td>['overweight using BMI-for-age z-scores']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AR</td>\n      <td>ARG</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Armenia</td>\n      <td>2016.0</td>\n      <td>13.7</td>\n      <td>Armenia Demographic and Health Survey 2015-16....</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AM</td>\n      <td>ARM</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Australia</td>\n      <td>2017.0</td>\n      <td>22.0</td>\n      <td>Australia National Health Survey 2017-18</td>\n      <td>['Age-adjusted;']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AU</td>\n      <td>AUS</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>AUT</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Azerbaijan</td>\n      <td>2013.0</td>\n      <td>14.1</td>\n      <td>Azerbaijan nutrition survey  (AzNS), 2013. Bak...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>AZ</td>\n      <td>AZE</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>BHS</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>BHR</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Bangladesh</td>\n      <td>2018.0</td>\n      <td>2.2</td>\n      <td>Bangladesh Demographic and Health Survey 2017-...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BD</td>\n      <td>BGD</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Barbados</td>\n      <td>2012.0</td>\n      <td>12.2</td>\n      <td>Barbados multiple indicator cluster survey 201...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BB</td>\n      <td>BRB</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Belarus</td>\n      <td>2005.0</td>\n      <td>9.7</td>\n      <td>Belarus multiple indicator cluster survey 2005...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BY</td>\n      <td>BLR</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>BEL</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Belize</td>\n      <td>2015.0</td>\n      <td>7.3</td>\n      <td>Belize Multiple Indicator Cluster Survey, 2015...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BZ</td>\n      <td>BLZ</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Benin</td>\n      <td>2018.0</td>\n      <td>1.9</td>\n      <td>Enquête Démographique et de Santé au Bénin, 20...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BJ</td>\n      <td>BEN</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Bhutan</td>\n      <td>2010.0</td>\n      <td>7.6</td>\n      <td>Bhutan multiple indicator cluster survey (BMIS...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BT</td>\n      <td>BTN</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Bolivia (Plurinational State of)</td>\n      <td>2016.0</td>\n      <td>10.1</td>\n      <td>Bolivia Encuesta de Demografia y Salud - EDSA ...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BO</td>\n      <td>BOL</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Bosnia and Herzegovina</td>\n      <td>2012.0</td>\n      <td>17.4</td>\n      <td>Institute for Public Health [Federation of Bos...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BA</td>\n      <td>BIH</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Botswana</td>\n      <td>2007.0</td>\n      <td>10.0</td>\n      <td>2007 Botswana family health survey IV report. ...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BW</td>\n      <td>BWA</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Brazil</td>\n      <td>2007.0</td>\n      <td>6.4</td>\n      <td>Pesquisa nacional de demografia e saúde da cri...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BR</td>\n      <td>BRA</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Brunei Darussalam</td>\n      <td>2009.0</td>\n      <td>8.3</td>\n      <td>2nd National health and nutritional status sur...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BN</td>\n      <td>BRN</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Bulgaria</td>\n      <td>2014.0</td>\n      <td>6.9</td>\n      <td>National Survey of Nutrition Factor for Health...</td>\n      <td>['Age interval 1-5; unadjusted;']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BG</td>\n      <td>BGR</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Burkina Faso</td>\n      <td>2018.0</td>\n      <td>1.0</td>\n      <td>Enquete Nutritionnelle Nationale, Burkina Faso...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BF</td>\n      <td>BFA</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Burundi</td>\n      <td>2016.0</td>\n      <td>1.4</td>\n      <td>Troisième Enquête Démographique et de Santé. B...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>BI</td>\n      <td>BDI</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>NaN</td>\n      <td>CPV</td>\n      <td>right_only</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>['2']</td>\n      <td>Proportion of children moderately or severely ...</td>\n      <td>Cambodia</td>\n      <td>2014.0</td>\n      <td>2.2</td>\n      <td>Cambodia Demographic and Health Survey 2014. P...</td>\n      <td>['']</td>\n      <td>PER_POP_U5</td>\n      <td>&lt;5Y</td>\n      <td>G</td>\n      <td>KH</td>\n      <td>KHM</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import cleanse\n",
    "import pandas as pd\n",
    "\n",
    "s102_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-102_raw.csv\"\n",
    ")\n",
    "\n",
    "s102_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s102_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    ")\n",
    "\n",
    "# s102_cleansed[\"REF_AREA\"].apply(lambda x: mean(len(x)))\n",
    "s102_cleansed.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The column REF_AREA has been renamed into COUNTRY_ISO_3, but should be COUNTRY_ISO_2. Now renaming it into COUNTRY_ISO_2\nCOUNTRY_ISO_2\n2\nCleansing done. There are 1051 rows in the dataframe and 1.52% have a NA-value in the column 'OBS_RAW_VALUE\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ATTR_UNIT_MEASURE DIM_EDU_LEVEL DIM_SEX DIM_AGE COUNTRY_ISO_2  \\\n",
       "0                   PT           L01      _T      _T            AF   \n",
       "1                   PT           L01       F      _T            AF   \n",
       "2                   PT           L01       M      _T            AF   \n",
       "3                   PT           L01      _T      _T            AL   \n",
       "4                   PT           L01       F      _T            AL   \n",
       "...                ...           ...     ...     ...           ...   \n",
       "1046                PT           L01       F      _T            ZW   \n",
       "1047                PT           L01       M      _T            ZW   \n",
       "1048                PT           L02      _T      _T            ZW   \n",
       "1049                PT           L02       F      _T            ZW   \n",
       "1050                PT           L02       M      _T            ZW   \n",
       "\n",
       "      TIME_PERIOD  RAW_OBS_VALUE ATTR_SOURCE_OBS_STATUS _merge  \n",
       "0          2018.0        0.00000                      Z   both  \n",
       "1          2018.0        0.00000                      Z   both  \n",
       "2          2018.0        0.00000                      Z   both  \n",
       "3          2012.0        0.00000                      Z   both  \n",
       "4          2012.0        0.00000                      Z   both  \n",
       "...           ...            ...                    ...    ...  \n",
       "1046       2013.0        0.00000                      Z   both  \n",
       "1047       2013.0        0.00000                      Z   both  \n",
       "1048       2013.0       46.95562                      A   both  \n",
       "1049       2013.0       47.51739                      A   both  \n",
       "1050       2013.0       46.39818                      A   both  \n",
       "\n",
       "[1051 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ATTR_UNIT_MEASURE</th>\n      <th>DIM_EDU_LEVEL</th>\n      <th>DIM_SEX</th>\n      <th>DIM_AGE</th>\n      <th>COUNTRY_ISO_2</th>\n      <th>TIME_PERIOD</th>\n      <th>RAW_OBS_VALUE</th>\n      <th>ATTR_SOURCE_OBS_STATUS</th>\n      <th>_merge</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>AF</td>\n      <td>2018.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>AL</td>\n      <td>2012.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>AL</td>\n      <td>2012.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1046</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1047</th>\n      <td>PT</td>\n      <td>L01</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>0.00000</td>\n      <td>Z</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1048</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>46.95562</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1049</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>F</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>47.51739</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n    <tr>\n      <th>1050</th>\n      <td>PT</td>\n      <td>L02</td>\n      <td>M</td>\n      <td>_T</td>\n      <td>ZW</td>\n      <td>2013.0</td>\n      <td>46.39818</td>\n      <td>A</td>\n      <td>both</td>\n    </tr>\n  </tbody>\n</table>\n<p>1051 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import cleanse\n",
    "import pandas as pd\n",
    "\n",
    "s52_raw = pd.read_csv(\n",
    "    filepath_or_buffer = data_sources_raw / \"S-52_raw.csv\"\n",
    ")\n",
    "\n",
    "s52_cleansed = cleanse.Cleanser().cleanse(\n",
    "    raw_data = s52_raw,\n",
    "    mapping_dictionary = mapping_dict,\n",
    "    final_sdmx_col_list = sdmx_df_columns_all,\n",
    "    dim_cols = sdmx_df_columns_dims,\n",
    "    country_cols = sdmx_df_columns_country,\n",
    "    time_cols = sdmx_df_columns_time,\n",
    "    country_list_full = country_full_list,\n",
    "    crba_country_list = country_crba_list\n",
    ")\n",
    "\n",
    "# s102_cleansed[\"REF_AREA\"].apply(lambda x: mean(len(x)))\n",
    "s52_cleansed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import mapping_dictionary\n",
    "# %run utils.mapping_dictionary.py\n",
    "\n",
    "# %run \"D:\\Documents\\2020\\28_UNICEF\\10_working_repo\\data-etl\\utils\\mapping_dictionary.py\"\n",
    "\n",
    "country_tuple = (\"REF_AREA\", \"COUNTRY\")\n",
    "country_mapper = {key: \"REF_AREA\" for key in country_tuple}\n",
    "\n",
    "\n",
    "year_tuple = (\n",
    "    \"TIME_PERIOD\",\n",
    "    \"YEAR\",\n",
    ")\n",
    "year_mapper = {key: \"TIME_PERIOD\" for key in year_tuple}\n",
    "\n",
    "\n",
    "obs_value_tuple = (\"OBS_VALUE\", \"Display Value\")\n",
    "obs_value_mapper = {key: \"OBS_VALUE\" for key in obs_value_tuple}\n",
    "\n",
    "\n",
    "dim_sex_tuple = \"SEX\"\n",
    "dim_sex_mapper = {key: \"OBS_VALUE\" for key in obs_value_tuple}\n",
    "\n",
    "\"\"\"\n",
    "dim_edu_tuple = (\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "dim_age_tuple = (\n",
    "    \"SEX\"\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Create list of all mapper dictionaries\n",
    "mapper_tuple_list = [country_mapper, year_mapper, obs_value_mapper, dim_sex_mapper]\n",
    "\n",
    "# Define the mapping dictionary\n",
    "mapping_dict = {}\n",
    "\n",
    "for mapper_tuple in mapper_tuple_list:\n",
    "    mapping_dict.update(mapper_tuple)\n",
    "\n",
    "with open(\"mapping_dict.json\", \"w\") as fp:\n",
    "    json.dump(mapping_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'REF_AREA': 'xxx', 'COUNTRY': 'xxx', 'TIME_PERIOD': 'yyy', 'YEAR': 'yyy'}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "year_tuple = (\n",
    "    \"TIME_PERIOD\",\n",
    "    \"YEAR\", \n",
    ")\n",
    "\n",
    "x = {key: \"xxx\" for key in country_tuple}\n",
    "y = {key: \"yyy\" for key in year_tuple}\n",
    "\n",
    "x.update(y)\n",
    "x}\n",
    "y = {key: \"yyy\" for key in year_tuple}\n",
    "\n",
    "x.update(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s55_cleansed = cleanse.Cleanser.cleanse(\n",
    "    raw_data = s55_raw,\n",
    "    raw_data_iso_2_col = 'REF_AREA',\n",
    "    country_df = country_crba_list,\n",
    "    country_df_iso2_col = 'COUNTRY_ISO_2',\n",
    "    non_dim_cols = ['OBS_VALUE', 'TIME_PERIOD', 'OBS_STATUS']\n",
    ")\n",
    "\n",
    "s55_cleansed.to_csv(data_sources_raw / \"S_55_cleansed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You have a selected a few columns, which will not be regarded as dimensions.These are the remaining columns in the dataset, along with the number of values they take in the dataset.\n",
      "The column Dataflow has 1 unique values.\n",
      "The column STAT_UNIT has 1 unique values.\n",
      "The column UNIT_MEASURE has 1 unique values.\n",
      "The column EDU_LEVEL has 3 unique values.\n",
      "The column EDU_CAT has 1 unique values.\n",
      "The column SEX has 3 unique values.\n",
      "The column AGE has 1 unique values.\n",
      "The column GRADE has 1 unique values.\n",
      "The column SECTOR_EDU has 1 unique values.\n",
      "The column EDU_ATTAIN has 1 unique values.\n",
      "The column SUBJECT has 1 unique values.\n",
      "The column WEALTH_QUINTILE has 1 unique values.\n",
      "The column INFRASTR has 1 unique values.\n",
      "The column LOCATION has 1 unique values.\n",
      "The column EDU_TYPE has 1 unique values.\n",
      "The column SE_BKGRD has 1 unique values.\n",
      "The column SOURCE_FUND has 1 unique values.\n",
      "The column FUND_FLOW has 1 unique values.\n",
      "The column IMM_STATUS has 1 unique values.\n",
      "The column UNIT_MULT has 1 unique values.\n",
      "The column FREQ has 1 unique values.\n",
      "The column DECIMALS has 1 unique values.\n",
      "The total number of subgroups in the dataset is therefore: 9\n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #1, which has these defining values: \n",
      " \n",
      " Empty DataFrame\n",
      "Columns: [Dataflow, STAT_UNIT, UNIT_MEASURE, EDU_LEVEL, EDU_CAT, SEX, AGE, GRADE, SECTOR_EDU, EDU_ATTAIN, SUBJECT, WEALTH_QUINTILE, INFRASTR, LOCATION, EDU_TYPE, SE_BKGRD, SOURCE_FUND, FUND_FLOW, IMM_STATUS, UNIT_MULT, FREQ, DECIMALS]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (0, 30) \n",
      " \n",
      " \n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #1. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #2, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1387  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1387  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1387       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1387        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (163, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 43.630325000000006 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.00589. This value corresponds to country: 739    Lithuania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #2. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #3, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1395  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1395  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1395       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1395        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (160, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 83.84053. This value corresponds to country: 1317    Tanzania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.67013. This value corresponds to country: 128    Belgium\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #3. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #4, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1394  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1394  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1394       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1394        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (160, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 89.7091. This value corresponds to country: 255    Central African Republic\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.07972. This value corresponds to country: 941    New Zealand\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #4. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #5, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1393  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1393  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1393       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1393        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (165, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the upper end. The maximum value used for the normalisation is the maximum value in the dataset, which is 86.14805. This value corresponds to country: 958    Niger\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06444. This value corresponds to country: 931    Netherlands\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " The shape of the dataframe should be 195 x X. It is:  (195, 35) \n",
      " \n",
      " \n",
      " This is the end of loop #5. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #6, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1392  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1392  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1392       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1392        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (161, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 65.25736 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.08982000000000001. This value corresponds to country: 1193    Singapore\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #6. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #7, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1391  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1391  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1391       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1391        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (161, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 66.091475 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06039. This value corresponds to country: 616    Ireland\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #7. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #8, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1390  UNESCO:SDG4(2.0)     ROFST           PT      L2_3      _T  _T   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1390  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1390       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1390        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (162, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 69.8756925 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.07741. This value corresponds to country: 1191    Singapore\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #8. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #9, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1389  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T   M   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1389  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1389       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1389        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (155, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 43.3836 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.06477999999999999. This value corresponds to country: 656    Kazakhstan\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #9. \n",
      " - \n",
      " \n",
      "\n",
      " - \n",
      "\n",
      "In the loop we are currently dealing with the subset #10, which has these defining values: \n",
      " \n",
      "               Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT SEX  \\\n",
      "1388  UNESCO:SDG4(2.0)     ROFST           PT        L2      _T   F   \n",
      "\n",
      "                AGE GRADE SECTOR_EDU EDU_ATTAIN  ... INFRASTR LOCATION  \\\n",
      "1388  SCH_AGE_GROUP    _T     INST_T         _Z  ...       _Z       _Z   \n",
      "\n",
      "     EDU_TYPE SE_BKGRD SOURCE_FUND FUND_FLOW IMM_STATUS UNIT_MULT FREQ  \\\n",
      "1388       _T       _T          _Z        _Z         _Z         0    A   \n",
      "\n",
      "     DECIMALS  \n",
      "1388        5  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "\n",
      " The shape of the subset in the cleansed dataset is: (155, 30) \n",
      " \n",
      " \n",
      "The distribution of the raw data values this subgroup contains outliers or is too skewed on the upper end. The maximum value to be used for the normalisation is: 3rd quartile or distribution + 1.5 * IQR. It is: 45.940870000000004 \n",
      " See histogram printed below for info. \n",
      "\n",
      "The distribution of the raw data for this subgroup does not contain outliers or is too skewed on the lower end. The minimum value used for the normalisation is the minimum value in the dataset, which is 0.09435. This value corresponds to country: 740    Lithuania\n",
      "Name: COUNTRY_NAME, dtype: object \n",
      "\n",
      "\n",
      " This is the distribution of the raw data of the indicator.\n",
      "Dataframe is empty. There are no values to append.\n",
      " \n",
      " This is the end of loop #10. \n",
      " - \n",
      " \n",
      "The number of rows of the final dataframe (before the conversion from wide to long format is) is divisible by 195. It is: (585, 38)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Dataflow STAT_UNIT UNIT_MEASURE EDU_LEVEL EDU_CAT  SEX  \\\n",
       "0    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "1    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "2                 NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "3                 NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "4    UNESCO:SDG4(2.0)     ROFST           PT        L3      _T    M   \n",
       "..                ...       ...          ...       ...     ...  ...   \n",
       "190  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "191               NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "192  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "193               NaN       NaN          NaN       NaN     NaN  NaN   \n",
       "194  UNESCO:SDG4(2.0)     ROFST           PT        L3      _T   _T   \n",
       "\n",
       "               AGE GRADE SECTOR_EDU EDU_ATTAIN  ... COUNTRY_ISO_3_y  \\\n",
       "0    SCH_AGE_GROUP    _T     INST_T         _Z  ...             AFG   \n",
       "1    SCH_AGE_GROUP    _T     INST_T         _Z  ...             ALB   \n",
       "2              NaN   NaN        NaN        NaN  ...             AND   \n",
       "3              NaN   NaN        NaN        NaN  ...             DZA   \n",
       "4    SCH_AGE_GROUP    _T     INST_T         _Z  ...             AGO   \n",
       "..             ...   ...        ...        ...  ...             ...   \n",
       "190  SCH_AGE_GROUP    _T     INST_T         _Z  ...             VEN   \n",
       "191            NaN   NaN        NaN        NaN  ...             VNM   \n",
       "192  SCH_AGE_GROUP    _T     INST_T         _Z  ...             YEM   \n",
       "193            NaN   NaN        NaN        NaN  ...             ZMB   \n",
       "194  SCH_AGE_GROUP    _T     INST_T         _Z  ...             ZWE   \n",
       "\n",
       "    COUNTRY_NAME_y COUNTRY_ISO_2_y RJ_CRBA_FULL_LIST  \\\n",
       "0      Afghanistan              AF              both   \n",
       "1          Albania              AL              both   \n",
       "2          Andorra              AD        right_only   \n",
       "3          Algeria              DZ        right_only   \n",
       "4           Angola              AO              both   \n",
       "..             ...             ...               ...   \n",
       "190      Venezuela              VE              both   \n",
       "191        Vietnam              VN        right_only   \n",
       "192          Yemen              YE              both   \n",
       "193         Zambia              ZM        right_only   \n",
       "194       Zimbabwe              ZW              both   \n",
       "\n",
       "                                  INDICATOR_NAME INDICATOR_INDEX  \\\n",
       "0    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "1    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "2    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "3    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "4    Out-of-school adolescents (lower secondary)       Workplace   \n",
       "..                                           ...             ...   \n",
       "190  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "191  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "192  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "193  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "194  Out-of-school adolescents (lower secondary)       Workplace   \n",
       "\n",
       "               INDICATOR_ISSUE INDICATOR_CATEGORY CRBA_RELEASE_YEAR  \\\n",
       "0    Decent working conditions            Outcome              2020   \n",
       "1    Decent working conditions            Outcome              2020   \n",
       "2    Decent working conditions            Outcome              2020   \n",
       "3    Decent working conditions            Outcome              2020   \n",
       "4    Decent working conditions            Outcome              2020   \n",
       "..                         ...                ...               ...   \n",
       "190  Decent working conditions            Outcome              2020   \n",
       "191  Decent working conditions            Outcome              2020   \n",
       "192  Decent working conditions            Outcome              2020   \n",
       "193  Decent working conditions            Outcome              2020   \n",
       "194  Decent working conditions            Outcome              2020   \n",
       "\n",
       "      INDICATOR_CODE  \n",
       "0    WP_DW_OC_FREASS  \n",
       "1    WP_DW_OC_FREASS  \n",
       "2    WP_DW_OC_FREASS  \n",
       "3    WP_DW_OC_FREASS  \n",
       "4    WP_DW_OC_FREASS  \n",
       "..               ...  \n",
       "190  WP_DW_OC_FREASS  \n",
       "191  WP_DW_OC_FREASS  \n",
       "192  WP_DW_OC_FREASS  \n",
       "193  WP_DW_OC_FREASS  \n",
       "194  WP_DW_OC_FREASS  \n",
       "\n",
       "[585 rows x 44 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataflow</th>\n      <th>STAT_UNIT</th>\n      <th>UNIT_MEASURE</th>\n      <th>EDU_LEVEL</th>\n      <th>EDU_CAT</th>\n      <th>SEX</th>\n      <th>AGE</th>\n      <th>GRADE</th>\n      <th>SECTOR_EDU</th>\n      <th>EDU_ATTAIN</th>\n      <th>...</th>\n      <th>COUNTRY_ISO_3_y</th>\n      <th>COUNTRY_NAME_y</th>\n      <th>COUNTRY_ISO_2_y</th>\n      <th>RJ_CRBA_FULL_LIST</th>\n      <th>INDICATOR_NAME</th>\n      <th>INDICATOR_INDEX</th>\n      <th>INDICATOR_ISSUE</th>\n      <th>INDICATOR_CATEGORY</th>\n      <th>CRBA_RELEASE_YEAR</th>\n      <th>INDICATOR_CODE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>AFG</td>\n      <td>Afghanistan</td>\n      <td>AF</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>ALB</td>\n      <td>Albania</td>\n      <td>AL</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>AND</td>\n      <td>Andorra</td>\n      <td>AD</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>DZA</td>\n      <td>Algeria</td>\n      <td>DZ</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>M</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>AGO</td>\n      <td>Angola</td>\n      <td>AO</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>VEN</td>\n      <td>Venezuela</td>\n      <td>VE</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>VNM</td>\n      <td>Vietnam</td>\n      <td>VN</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>YEM</td>\n      <td>Yemen</td>\n      <td>YE</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>ZMB</td>\n      <td>Zambia</td>\n      <td>ZM</td>\n      <td>right_only</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>UNESCO:SDG4(2.0)</td>\n      <td>ROFST</td>\n      <td>PT</td>\n      <td>L3</td>\n      <td>_T</td>\n      <td>_T</td>\n      <td>SCH_AGE_GROUP</td>\n      <td>_T</td>\n      <td>INST_T</td>\n      <td>_Z</td>\n      <td>...</td>\n      <td>ZWE</td>\n      <td>Zimbabwe</td>\n      <td>ZW</td>\n      <td>both</td>\n      <td>Out-of-school adolescents (lower secondary)</td>\n      <td>Workplace</td>\n      <td>Decent working conditions</td>\n      <td>Outcome</td>\n      <td>2020</td>\n      <td>WP_DW_OC_FREASS</td>\n    </tr>\n  </tbody>\n</table>\n<p>585 rows × 44 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from normalize.scaler import normalizer\n",
    "\n",
    "s55_normalized = normalizer(\n",
    "    cleansed_data = s55_cleansed,\n",
    "    indicator_raw_value = 'OBS_VALUE',\n",
    "    indicator_code = 'WP_DW_OC_FREASS',\n",
    "    indicator_name = 'Out-of-school adolescents (lower secondary)',\n",
    "    indicator_index = 'Workplace',\n",
    "    indicator_issue = 'Decent working conditions',\n",
    "    indicator_category = 'Outcome',\n",
    "    cleansed_df_iso2_col = 'REF_AREA',\n",
    "    crba_final_country_list = country_crba_list,\n",
    "    crba_final_country_list_iso_col = 'COUNTRY_ISO_2',\n",
    "    inverted = True,\n",
    "    non_dim_cols = [\n",
    "        'TIME_PERIOD', \n",
    "        'REF_AREA', \n",
    "        'OBS_VALUE', \n",
    "        'OBS_STATUS', \n",
    "        'COUNTRY_ISO_3', \n",
    "        'COUNTRY_NAME', \n",
    "        'COUNTRY_ISO_2', \n",
    "        '_merge'\n",
    "    ])\n",
    "\n",
    "s55_normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}