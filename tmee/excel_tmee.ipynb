{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains code used to populate data dictionary\n",
    "It is in development state and not cleaned at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beto\\anaconda3\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import wb\n",
    "from data_dictionary.append_df_to_excel import append_df_to_excel\n",
    "# from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the excel tmee database\n",
    "path_file = './populate_data_dictionary/TM Indicators Flow Revised Database - 2020306 SP ED ECD -working file v-6 Aug 2020_beto.xlsx'\n",
    "indicators = pd.read_excel(path_file, sheet_name='TM Revised database', header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter indicators that are new or retained from excel tmee data base\n",
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "# filter logic_not_removed that are not boolean\n",
    "logic_not_null = logic_not_removed.notnull()\n",
    "# and operator from logic above\n",
    "logic_not_removed_null = logic_not_removed & logic_not_null\n",
    "not_removed_indicators = indicators[logic_not_removed_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with helix: or helix code: in excel tmee data base\n",
    "logic_helix = not_removed_indicators['Data Source'].str.lower().str.contains('helix:|helix code:')\n",
    "# filter logic_helix that are not boolean\n",
    "logic_not_null = logic_helix.notnull()\n",
    "# and operator from logic above\n",
    "logic_helix_not_null = logic_helix & logic_not_null\n",
    "not_removed_indicators['Code'] = not_removed_indicators[logic_helix_not_null]['Data Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the code for API requests\n",
    "not_removed_indicators['Code'] = not_removed_indicators['Code'].str.replace('Helix: ','')\\\n",
    ".str.replace('Helix code: ','').str.replace('/', '').str.replace('\\\\', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a function from stackoverflow to append data dictionary\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,[2,105]], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 4, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize helix Api names as Helix for source names\n",
    "not_removed_indicators['Source Name'] = 'Helix: ' + not_removed_indicators[logic_helix_not_null]['Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place list of helix api's in source\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.loc[logic_helix_not_null,'Source Name'].iloc[2:],\n",
    "                   sheet_name='Source', startrow=6,\n",
    "                   startcol = 2, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.loc[logic_helix_not_null,'Source Name'].iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.loc[logic_helix_not_null,'Code'].iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_removed_indicators.iloc[21:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the code for API requests\n",
    "not_removed_indicators['Code'].str.replace('Helix: ','').str.replace('Helix code: ','').str.replace('/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a function from stackoverflow\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,-1], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 5, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(helix_source_indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I want to plug correctly the codes in the populated Excel data dictionary\n",
    "# should I join these two tables on name?\n",
    "not_removed_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the indicator names of these into Excel (ideally to populate our dictionary)\n",
    "# this solution does not properly work (creates a new spreadsheet)\n",
    "\n",
    "# path to existing excel file\n",
    "# I know before hand which indicators I want to add and the startrow and starcol parameters\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "with pd.ExcelWriter(path_file, mode='a', engine=\"openpyxl\") as writer:\n",
    "    indicators[logic_not_removed_null].iloc[21:,2].to_excel(writer, sheet_name='Indicator',\n",
    "                                                                       header = False, index = False,\n",
    "                                                                       startrow = 22, startcol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the codes from helix API based indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get info from new or retained indicators\n",
    "indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from stackoverflow by MaxU\n",
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "    try:\n",
    "        FileNotFoundError\n",
    "    except NameError:\n",
    "        FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "\n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "\n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dev section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test append df to excel function\n",
    "path_file = './populate_data_dictionary/test.xlsx'\n",
    "append_df_to_excel(path_file, not_removed_indicators.iloc[21:,[2,105]], sheet_name='Indicator', startrow=22,\n",
    "                   startcol = 4, header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking forward to get more sources that could be extracted as API\n",
    "not_removed_indicators['Data Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wb.search('health.*expenditure.*gdp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.download(indicator='SH.XPD.CHEX.GD.ZS', country=['AL', 'AM', 'TR', 'TM', 'BA'], start=1960, end=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter indicators that are new or retained from excel tmee data base\n",
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "# filter logic_not_removed that are not boolean\n",
    "logic_not_null = logic_not_removed.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indicators[logic_not_removed & logic_not_null])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing excel file\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "# book = load_workbook(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open excel writer\n",
    "writer = pd.ExcelWriter(path_file, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open existing excel file\n",
    "path_file = './populate_data_dictionary/indicator_dictionary_TM_v1.xlsx'\n",
    "with pd.ExcelWriter(path_file, mode='a', engine=\"openpyxl\") as writer:\n",
    "    indicators[logic_not_removed & logic_not_null].iloc[21:,2].to_excel(writer, sheet_name='Indicator',\n",
    "                                                                       header = False, index = False,\n",
    "                                                                       startrow = 22, startcol = 4)\n",
    "# df.to_excel(writer, sheet_name='Sheet3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with data source not null\n",
    "logic_not_null = indicators.iloc[:,5].notnull()\n",
    "# get those that contains 'helix' in data source\n",
    "logic_helix = indicators[logic_not_null]['Data Source'].str.lower().str.contains('helix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point to indicators with helix: or helix code: in excel tmee data base\n",
    "logic_helix = indicators['Data Source'].str.lower().str.contains('helix:|helix code:')\n",
    "# filter logic_helix that are not boolean\n",
    "logic_not_null = logic_helix.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators[logic_helix & logic_not_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators[logic_not_removed_null].iloc[21:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['Data Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators['Status in the new `db'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_not_removed = indicators['Status in the new `db'].str.lower().str.contains('new|retained')\n",
    "indicators[logic_not_removed.isnull()].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(indicators['Status in the new `db'].unique()).str.lower().str.contains('new|retained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
